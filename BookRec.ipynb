{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sorennelson/MediaRecommendation/blob/v2-recsys/BookRec.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Current Model: A 4 layer MLP with learned User/Movie Embeddings with an Embedding Cluster approach described below. This is just an initial implementation to get the ball rolling. \\\\\n",
        "In Progress: Genre embeddings and other Book features."
      ],
      "metadata": {
        "id": "TlqUR5oDe4fR"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JgWk0W7yaceM"
      },
      "outputs": [],
      "source": [
        "!pip install nvtabular\n",
        "!pip install merlin"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oEVEjAaHanzM"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import time\n",
        "import json\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "import nvtabular as nvt\n",
        "from nvtabular.loader.torch import TorchAsyncItr, DLDataLoader\n",
        "from merlin.schema.tags import Tags"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nUWV8JWVaptE"
      },
      "outputs": [],
      "source": [
        "DATA_PATH = \"/content/drive/MyDrive/Colab Notebooks/Personal/MediaRec/book_data\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JMBtGEl9Ggvx"
      },
      "source": [
        "# Data Analysis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-bW4gxHaGtOi"
      },
      "source": [
        "## Rating distribution per user and per book"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IaqvOMFncKpq"
      },
      "outputs": [],
      "source": [
        "def gather_userbook_rating_counts(popular_workflow:bool = True):\n",
        "    '''\n",
        "    Loads in the ratings dataframe and adjusts if using popular workflows.\n",
        "\n",
        "    TODO: Needs to be updated later on but want a bias toward more popular media to start.\n",
        "\n",
        "    Args:\n",
        "      popular_workflow: Remove users with < 5 and > 1000 ratings and books with < 10 ratings\n",
        "    '''\n",
        "    BATCH_SIZE = 1000000\n",
        "    user_counts, book_counts, n_total_ratings = None, None, 0\n",
        "\n",
        "    with pd.read_csv(os.path.join(DATA_PATH, 'goodreads_interactions-clean.csv'), chunksize=BATCH_SIZE) as reader:\n",
        "        for chunk in reader:\n",
        "            n_total_ratings += len(chunk)\n",
        "            if user_counts is None:\n",
        "                user_counts = chunk.groupby('user_id')['book_id'].nunique()\n",
        "                book_counts = chunk.groupby('book_id')['user_id'].nunique()\n",
        "            else:\n",
        "                new_user_counts = chunk.groupby('user_id')['book_id'].nunique()\n",
        "                notin_user_counts = new_user_counts[~new_user_counts.index.isin(user_counts.index)]\n",
        "                in_user_counts = new_user_counts[new_user_counts.index.isin(user_counts.index)]\n",
        "                user_counts = user_counts.append(notin_user_counts)\n",
        "                user_counts.loc[user_counts.index.isin(in_user_counts.index)] += in_user_counts\n",
        "\n",
        "                new_book_counts = chunk.groupby('book_id')['user_id'].nunique()\n",
        "                notin_book_counts = new_book_counts[~new_book_counts.index.isin(book_counts.index)]\n",
        "                in_book_counts = new_book_counts[new_book_counts.index.isin(book_counts.index)]\n",
        "                book_counts = book_counts.append(notin_book_counts)\n",
        "                book_counts.loc[book_counts.index.isin(in_book_counts.index)] += in_book_counts\n",
        "\n",
        "    if popular_workflow:\n",
        "        user_counts = user_counts[user_counts>=5][user_counts<=1000]\n",
        "        book_counts = book_counts[book_counts>=10]\n",
        "\n",
        "    return user_counts, book_counts, n_total_ratings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5WyhuIacIZFP"
      },
      "outputs": [],
      "source": [
        "user_counts, book_counts, n_total_ratings = gather_userbook_rating_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cv0au5XM5W0n",
        "outputId": "1a5fe58f-dac1-4cda-ffeb-8b3f3b0a0006"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "876145\n",
            "835090\n",
            "812035\n",
            "Full: (array([874733,   1057,    198,     62,     32,     20,     12,      8,\n",
            "            4,      5,      4,      3,      3,      2,      0,      0,\n",
            "            1,      0,      0,      1]), array([1.000000e+00, 5.989800e+03, 1.197860e+04, 1.796740e+04,\n",
            "       2.395620e+04, 2.994500e+04, 3.593380e+04, 4.192260e+04,\n",
            "       4.791140e+04, 5.390020e+04, 5.988900e+04, 6.587780e+04,\n",
            "       7.186660e+04, 7.785540e+04, 8.384420e+04, 8.983300e+04,\n",
            "       9.582180e+04, 1.018106e+05, 1.077994e+05, 1.137882e+05,\n",
            "       1.197770e+05]))\n",
            "< 500: (array([184743, 109663,  82109,  63344,  51435,  42695,  35544,  30010,\n",
            "        24729,  20717,  19004,  16618,  14869,  13073,  11929,  10733,\n",
            "         9639,   8789,   8012,   7268]), array([  1. ,  25.9,  50.8,  75.7, 100.6, 125.5, 150.4, 175.3, 200.2,\n",
            "       225.1, 250. , 274.9, 299.8, 324.7, 349.6, 374.5, 399.4, 424.3,\n",
            "       449.2, 474.1, 499. ]))\n",
            "< 25: (array([26404, 15898, 12039,  9769,  9936,  8372,  7560,  6940,  6497,\n",
            "        6013,  5714,  5377,  5018,  4935,  4739,  4624,  4435,  4365,\n",
            "        4302,  5348,  5286,  5281, 10699]), array([ 1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10., 11., 12., 13.,\n",
            "       14., 15., 16., 17., 18., 19., 20., 21., 22., 23., 24.]))\n",
            "\n",
            " Popular and outliers removed: (array([245136, 139692,  91189,  62628,  45435,  34931,  26972,  22392,\n",
            "        18200,  14784,  12516,  10614,   9096,   7658,   6775,   5942,\n",
            "         5048,   4535,   3957,   3480]), array([  5. ,  54.7, 104.4, 154.1, 203.8, 253.5, 303.2, 352.9, 402.6,\n",
            "       452.3, 502. , 551.7, 601.4, 651.1, 700.8, 750.5, 800.2, 849.9,\n",
            "       899.6, 949.3, 999. ]))\n"
          ]
        }
      ],
      "source": [
        "# Look at the raw distribution of user ratings\n",
        "print(len(user_counts))\n",
        "print(len(user_counts[user_counts<1000]))\n",
        "print(len(user_counts[user_counts>4]))\n",
        "print('Full:', np.histogram(user_counts, bins=20))\n",
        "print('< 500:', np.histogram(user_counts[user_counts < 500], bins=20))\n",
        "print('< 25:', np.histogram(user_counts[user_counts < 25], bins=23))\n",
        "\n",
        "print('\\n Popular and outliers removed:', np.histogram(user_counts[user_counts>4][user_counts<1000], bins=20))\n",
        "# TODO: Remove users with more than 1000 and more than 4 "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "JrMz7GqFh1XB",
        "outputId": "e406ffe4-dc07-4a5a-e16e-15fc85a797ac"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "plt.hist(user_counts[user_counts>4][user_counts<1000], bins=20)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KLFQVFAr6cfv",
        "outputId": "074deec5-2883-4bf8-ade4-b3704a17cefc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2360650\n",
            "960327\n",
            "Full: (array([2359461,     747,     196,     102,      50,      23,      18,\n",
            "             9,      14,       8,       3,       2,      10,       2,\n",
            "             1,       0,       2,       0,       0,       2]), array([1.000000e+00, 1.573520e+04, 3.146940e+04, 4.720360e+04,\n",
            "       6.293780e+04, 7.867200e+04, 9.440620e+04, 1.101404e+05,\n",
            "       1.258746e+05, 1.416088e+05, 1.573430e+05, 1.730772e+05,\n",
            "       1.888114e+05, 2.045456e+05, 2.202798e+05, 2.360140e+05,\n",
            "       2.517482e+05, 2.674824e+05, 2.832166e+05, 2.989508e+05,\n",
            "       3.146850e+05]))\n",
            "< 25: (array([303590, 208068, 157201, 124533, 103510,  87777,  75528,  66017,\n",
            "        58111,  52080,  46880,  42446,  38946,  35636,  32362,  30144,\n",
            "        27707,  25909,  24286,  22662,  21074,  20017,  36229]), array([ 1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10., 11., 12., 13.,\n",
            "       14., 15., 16., 17., 18., 19., 20., 21., 22., 23., 24.]))\n"
          ]
        }
      ],
      "source": [
        "# Look at the raw distribution of book ratings\n",
        "print(len(book_counts))\n",
        "# print(len(user_counts[user_counts<1000]))\n",
        "print(len(book_counts[book_counts>14]))\n",
        "print('Full:', np.histogram(book_counts, bins=20))\n",
        "print('< 25:', np.histogram(book_counts[book_counts < 25], bins=23))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "5v7dMTf5mqfe",
        "outputId": "0a3f14f3-8b42-4ead-c246-846d1c1cdc4e"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "plt.hist(book_counts[book_counts>50][book_counts < 1000], bins=20)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OLtHmHfkoSig",
        "outputId": "ac3c951f-feaf-4691-f7a0-ba9cd741c81d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "book_id\n",
            "0          895\n",
            "1          215\n",
            "2          128\n",
            "5          326\n",
            "6          252\n",
            "          ... \n",
            "1839603     56\n",
            "1854807     79\n",
            "1983592     55\n",
            "1985003     51\n",
            "2016570     52\n",
            "Name: user_id, Length: 428309, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "print(book_counts)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0KNz-gxFGnB1"
      },
      "source": [
        "# Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MLSYpmjZG6-x"
      },
      "outputs": [],
      "source": [
        "# Split into train/val/test \n",
        "\n",
        "def split_train_val_test():\n",
        "    '''\n",
        "    Takes ~10-15 minutes.\n",
        "    '''\n",
        "    if os.path.exists(os.path.join(DATA_PATH, 'goodreads_interactions-clean-train.csv')):\n",
        "        print('Already Split')\n",
        "        return\n",
        "\n",
        "    user_counts, book_counts, n_total_ratings = gather_userbook_rating_counts(popular_workflow=True)\n",
        "    print('{} users, {} books'.format(len(user_counts), len(book_counts)))\n",
        "\n",
        "    BATCH_SIZE = 1000000\n",
        "    output_path_train = os.path.join(DATA_PATH, 'goodreads_interactions-clean-train.csv')\n",
        "    output_path_val = os.path.join(DATA_PATH, 'goodreads_interactions-clean-val.csv')\n",
        "    output_path_test = os.path.join(DATA_PATH, 'goodreads_interactions-clean-test.csv')\n",
        "    output_path_clean_val = os.path.join(DATA_PATH, 'goodreads_interactions-clean-val_clean.csv')\n",
        "    output_path_clean_test = os.path.join(DATA_PATH, 'goodreads_interactions-clean-test_clean.csv')\n",
        "\n",
        "    # In val/test we want clean (untrained on) users and unclean (trained on but not those ratings) users \n",
        "    # clean percentages are out of users\n",
        "    # unclean percentages are out of ratings\n",
        "    p_test, p_test_clean = 0.075, 0.005\n",
        "    p_val, p_val_clean = 0.075, 0.005\n",
        "\n",
        "    val_clean_userids = user_counts[-int(len(user_counts)*p_val_clean):]\n",
        "    test_clean_userids = user_counts[-int(len(user_counts)*(p_test_clean+p_val_clean)) \\\n",
        "                                    :-int(len(user_counts)*p_val_clean)]\n",
        "    unclean_userids = user_counts[:-int(len(user_counts)*(p_test_clean+p_val_clean))]\n",
        "\n",
        "    print('Train user count: {}, val clean: {}, test clean: {}'.format(\n",
        "        len(unclean_userids), len(val_clean_userids), len(test_clean_userids))\n",
        "    )\n",
        "\n",
        "    n_total_ratings, n_train, n_val = 0, 0, 0\n",
        "    with pd.read_csv(os.path.join(DATA_PATH, 'goodreads_interactions-clean.csv'), \n",
        "                    chunksize=BATCH_SIZE\n",
        "                    ) as reader:\n",
        "        for chunk in reader:\n",
        "\n",
        "            df_clean_val = chunk[chunk['user_id'].isin(val_clean_userids.index)]\n",
        "            df_clean_test = chunk[chunk['user_id'].isin(test_clean_userids.index)]\n",
        "            df_unclean = chunk[chunk['user_id'].isin(unclean_userids.index)]\n",
        "\n",
        "            # Grab unclean user indexes\n",
        "            unclean_rating_idxs = np.random.permutation(len(df_unclean))\n",
        "            unclean_rating_idxs_train = unclean_rating_idxs[:-int((p_test+p_val)*len(unclean_rating_idxs))]\n",
        "            unclean_rating_idxs_val = unclean_rating_idxs[-int(p_val*len(unclean_rating_idxs)):]\n",
        "            unclean_rating_idxs_test = unclean_rating_idxs[-int((p_test+p_val)*len(unclean_rating_idxs)): \n",
        "                                                        -int(p_val*len(unclean_rating_idxs))]\n",
        "\n",
        "            df_train = df_unclean.iloc[unclean_rating_idxs_train]\n",
        "            # Shuffle Train set\n",
        "            df_train = df_train.sample(frac=1).reset_index(drop=True)\n",
        "            df_val = df_unclean.iloc[unclean_rating_idxs_val]\n",
        "            df_test = df_unclean.iloc[unclean_rating_idxs_test]\n",
        "            \n",
        "            # Output to CSV\n",
        "            output_name_df = [(output_path_clean_val, df_clean_val), (output_path_clean_test, df_clean_test), \n",
        "                    (output_path_train, df_train), (output_path_val, df_val), (output_path_test, df_test)]\n",
        "            for output_name, df in output_name_df:\n",
        "                df.to_csv(output_name, mode='a', header=not os.path.exists(output_name))\n",
        "\n",
        "            n_total_ratings += len(chunk)\n",
        "            n_train += len(df_train)\n",
        "            n_val += len(df_val)\n",
        "\n",
        "    print('Total ratings: {}, Train: {}, Val: {}'.format(\n",
        "        n_total_ratings, \n",
        "        n_train, \n",
        "        n_val))\n",
        "\n",
        "\n",
        "def split_train():\n",
        "    ''' Splits train into local csv splits of 2M examples each.\n",
        "    Takes ~5-10 minutes.\n",
        "    '''\n",
        "    BATCH_SIZE = 2000000\n",
        "    with pd.read_csv(os.path.join(DATA_PATH, 'goodreads_interactions-clean-train.csv'), \n",
        "                    chunksize=BATCH_SIZE\n",
        "                    ) as reader:\n",
        "        for i, chunk in enumerate(reader):\n",
        "            chunk.to_csv('train_split_{}.csv'.format(i))\n",
        "    return i + 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5z1DMleLASKq"
      },
      "outputs": [],
      "source": [
        "def get_workflow(load_path:str = None) -> nvt.Workflow:\n",
        "    ''' Loads the Workflow or creates a new one if load_path is None.'''\n",
        "    if load_path:\n",
        "        print('Loading Workflow')\n",
        "        workflow = nvt.Workflow.load(load_path)\n",
        "\n",
        "    else:\n",
        "        print('Creating Workflow')\n",
        "        # map from ratings id to goodreads id\n",
        "        joined = [\"user_id\", \"book_id\"] >> nvt.ops.JoinExternal(df_idmap, on=\"book_id\")\n",
        "        output = joined['user_id', 'goodreads_id'] >> nvt.ops.Categorify()\n",
        "        output += nvt.ColumnGroup([\"rating\"]) >> nvt.ops.NormalizeMinMax()\n",
        "        workflow = nvt.Workflow(output)\n",
        "\n",
        "    return workflow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Hsa17IAJ_nxY"
      },
      "outputs": [],
      "source": [
        "def partition_fit_and_transform(workflow: nvt.Workflow):\n",
        "    ''' Fits the workflow on splits of the train dataset\n",
        "        then transforms the train/val/test datasets.\n",
        "    '''\n",
        "    if os.path.exists(os.path.join(DATA_PATH, 'goodreads_interactions-clean-train')):\n",
        "        print('Already fit')\n",
        "        return\n",
        "\n",
        "    print('Splitting ...')\n",
        "    n_splits = split_train()\n",
        "    print('Fitting ...')\n",
        "    ds = nvt.Dataset(['train_split_{}.csv'.format(i) for i in range(n_splits)])\n",
        "    workflow.fit(ds)\n",
        "    print('Transforming ...')\n",
        "    path = os.path.join(DATA_PATH, 'goodreads_interactions-clean-train')\n",
        "    workflow.transform(ds).to_parquet(path, preserve_files=True)\n",
        "\n",
        "    # Transform val/test\n",
        "    workflow.transform(\n",
        "        nvt.Dataset(os.path.join(DATA_PATH, 'goodreads_interactions-clean-val.csv'))\n",
        "        ).to_parquet(os.path.join(DATA_PATH, 'goodreads_interactions-clean-val'))\n",
        "    workflow.transform(\n",
        "        nvt.Dataset(os.path.join(DATA_PATH, 'goodreads_interactions-clean-test.csv'))\n",
        "        ).to_parquet(os.path.join(DATA_PATH, 'goodreads_interactions-clean-test'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5_eOaM0UT7Zu",
        "outputId": "cc25cfb2-5ae4-4130-a9c9-da20d65d05e6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "750823 users, 606690 books\n",
            "Train user count: 743315, val clean: 3754, test clean: 3754\n",
            "Total ratings: 168957291, Train: 97264497, Val: 8582074\n"
          ]
        }
      ],
      "source": [
        "# Note: total ratings are before filtering with popular workflow whereas train/val counts are after\n",
        "split_train_val_test()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sVt4uNdPeTg3",
        "outputId": "737a3427-aabc-42ff-d2b0-6cafe1d29726"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading Workflow\n",
            "Already fit\n"
          ]
        }
      ],
      "source": [
        "df_idmap = pd.read_csv(os.path.join(DATA_PATH, 'book_id_map-dedup-v1.csv'))\n",
        "df_idmap = df_idmap.drop(columns=['Unnamed: 0'])\n",
        "df_idmap = df_idmap.rename(columns={'book_id': 'goodreads_id'})\n",
        "df_idmap = df_idmap.rename(columns={'book_id_csv': 'book_id'})\n",
        "\n",
        "# Load in or create Workflow\n",
        "workflow_path = os.path.join(DATA_PATH, 'book_workflow_popular-v1')\n",
        "exists = os.path.exists(workflow_path)\n",
        "workflow = get_workflow(workflow_path if exists else None)\n",
        "\n",
        "# Transform dataset if needed\n",
        "partition_fit_and_transform(workflow)\n",
        "\n",
        "# Save workflow if needed\n",
        "if not exists:\n",
        "    print('Saving Workflow')\n",
        "    workflow.save(workflow_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 162
        },
        "id": "DepYitYKpv5B",
        "outputId": "b9976ee2-3fc3-4152-bef5-cd1cfc8e3b25"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>name</th>\n",
              "      <th>tags</th>\n",
              "      <th>dtype</th>\n",
              "      <th>is_list</th>\n",
              "      <th>is_ragged</th>\n",
              "      <th>properties.num_buckets</th>\n",
              "      <th>properties.freq_threshold</th>\n",
              "      <th>properties.max_size</th>\n",
              "      <th>properties.start_index</th>\n",
              "      <th>properties.cat_path</th>\n",
              "      <th>properties.domain.min</th>\n",
              "      <th>properties.domain.max</th>\n",
              "      <th>properties.domain.name</th>\n",
              "      <th>properties.embedding_sizes.cardinality</th>\n",
              "      <th>properties.embedding_sizes.dimension</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>user_id</td>\n",
              "      <td>(Tags.CATEGORICAL)</td>\n",
              "      <td>int64</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>.//categories/unique.user_id.parquet</td>\n",
              "      <td>0.0</td>\n",
              "      <td>743312.0</td>\n",
              "      <td>user_id</td>\n",
              "      <td>743313.0</td>\n",
              "      <td>512.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>goodreads_id</td>\n",
              "      <td>(Tags.CATEGORICAL)</td>\n",
              "      <td>int64</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>.//categories/unique.goodreads_id.parquet</td>\n",
              "      <td>0.0</td>\n",
              "      <td>827097.0</td>\n",
              "      <td>goodreads_id</td>\n",
              "      <td>827098.0</td>\n",
              "      <td>512.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>rating</td>\n",
              "      <td>(Tags.CONTINUOUS)</td>\n",
              "      <td>float64</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "[{'name': 'user_id', 'tags': {<Tags.CATEGORICAL: 'categorical'>}, 'properties': {'num_buckets': None, 'freq_threshold': 0, 'max_size': 0, 'start_index': 0, 'cat_path': './/categories/unique.user_id.parquet', 'domain': {'min': 0, 'max': 743312, 'name': 'user_id'}, 'embedding_sizes': {'cardinality': 743313, 'dimension': 512}}, 'dtype': dtype('int64'), 'is_list': False, 'is_ragged': False}, {'name': 'goodreads_id', 'tags': {<Tags.CATEGORICAL: 'categorical'>}, 'properties': {'num_buckets': None, 'freq_threshold': 0, 'max_size': 0, 'start_index': 0, 'cat_path': './/categories/unique.goodreads_id.parquet', 'domain': {'min': 0, 'max': 827097, 'name': 'goodreads_id'}, 'embedding_sizes': {'cardinality': 827098, 'dimension': 512}}, 'dtype': dtype('int64'), 'is_list': False, 'is_ragged': False}, {'name': 'rating', 'tags': {<Tags.CONTINUOUS: 'continuous'>}, 'properties': {}, 'dtype': dtype('float64'), 'is_list': False, 'is_ragged': False}]"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "workflow.output_schema"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IjBMZVhG_eBn"
      },
      "source": [
        "# Data Loading"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IrzpHN3DABDE"
      },
      "outputs": [],
      "source": [
        "def load_dls(batch_size):\n",
        "    ''' Load in the transformed datasets and convert to torch-ready\n",
        "    '''\n",
        "    train_path = os.path.join(DATA_PATH, 'goodreads_interactions-clean-train')\n",
        "    train_paths = [os.path.join(train_path, x) for x in os.listdir(train_path) \\\n",
        "                   if '.parquet' in x]\n",
        "\n",
        "    train_torch = TorchAsyncItr(\n",
        "        nvt.Dataset(train_paths, engine='parquet'),\n",
        "        batch_size=batch_size,\n",
        "        cats=['user_id', 'goodreads_id'],\n",
        "        conts=[\"rating\"], \n",
        "        shuffle=True\n",
        "    )\n",
        "    train_dl = DLDataLoader(\n",
        "        train_torch, batch_size=None, pin_memory=False, num_workers=0\n",
        "    )\n",
        "\n",
        "    val_path = os.path.join(DATA_PATH, 'goodreads_interactions-clean-val')\n",
        "    val_torch = TorchAsyncItr(\n",
        "        nvt.Dataset(val_path, engine='parquet'),\n",
        "        batch_size=batch_size,\n",
        "        cats=['user_id', 'goodreads_id'],\n",
        "        conts=[\"rating\"], \n",
        "    )\n",
        "    val_dl = DLDataLoader(\n",
        "        val_torch, batch_size=None, pin_memory=False, num_workers=0\n",
        "    )\n",
        "    \n",
        "    test_path = os.path.join(DATA_PATH, 'goodreads_interactions-clean-test')\n",
        "    test_torch = TorchAsyncItr(\n",
        "        nvt.Dataset(test_path, engine='parquet'),\n",
        "        batch_size=batch_size,\n",
        "        cats=['user_id', 'goodreads_id'],\n",
        "        conts=[\"rating\"], \n",
        "    )\n",
        "    test_dl = DLDataLoader(\n",
        "        test_torch, batch_size=None, pin_memory=False, num_workers=0\n",
        "    )\n",
        "    return train_dl, val_dl, test_dl"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wZa_4bQSAWus"
      },
      "source": [
        "# Models and Training Loops"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zvaUSR3HunLa"
      },
      "source": [
        "## Models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hMkd18yQAaSV"
      },
      "outputs": [],
      "source": [
        "class MLP(nn.Module):\n",
        "    def __init__(self, emb_size, hidden_dim, n_users, n_media, dropout_rate=0.0):\n",
        "        super().__init__()\n",
        "        self.user_emb = nn.Embedding(n_users, emb_size)\n",
        "        self.media_emb = nn.Embedding(n_media, emb_size)\n",
        "        self.emb_dropout = nn.Dropout(p=dropout_rate)\n",
        "\n",
        "        self.mlp = nn.Sequential(nn.Linear(emb_size*2, hidden_dim),\n",
        "                                  nn.LayerNorm(hidden_dim),\n",
        "                                  nn.ReLU(inplace=True),\n",
        "                                  nn.Dropout(p=dropout_rate),\n",
        "                                  nn.Linear(hidden_dim, hidden_dim),\n",
        "                                  nn.LayerNorm(hidden_dim),\n",
        "                                  nn.ReLU(inplace=True),\n",
        "                                  nn.Dropout(p=dropout_rate),\n",
        "                                  nn.Linear(hidden_dim, hidden_dim),\n",
        "                                  nn.LayerNorm(hidden_dim),\n",
        "                                  nn.ReLU(inplace=True),\n",
        "                                  nn.Dropout(p=dropout_rate),\n",
        "                                  nn.Linear(hidden_dim, hidden_dim),\n",
        "                                  nn.LayerNorm(hidden_dim),\n",
        "                                  nn.ReLU(inplace=True),\n",
        "                                  nn.Linear(hidden_dim, 1))\n",
        "\n",
        "    def forward(self, user, media):\n",
        "        x = torch.cat([self.user_emb(user).transpose(1, 2), \n",
        "                       self.media_emb(media).transpose(1, 2)], axis=1).squeeze()\n",
        "        x = self.emb_dropout(x)\n",
        "        return torch.sigmoid(self.mlp(x))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S1blQYRzuqD8"
      },
      "source": [
        "## Training Loop"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TChvr3u-AfoD"
      },
      "outputs": [],
      "source": [
        "def train_model(train_dl, val_dl, test_dl, model, loss_fn, opt):\n",
        "    metrics = []\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        start = time.time()\n",
        "\n",
        "        mse, rmse = train(train_dl, model, loss_fn, opt, epoch+1)\n",
        "        val_mse, val_rmse = validate(val_dl, model, loss_fn, epoch+1)\n",
        "\n",
        "        metrics.append([mse, rmse, val_mse, val_rmse])\n",
        "        print('Epoch {}/{} - completed {}M - est. remaining {}H {}M \\n'.format(\n",
        "                                                            epoch+1, epochs, \n",
        "                                                            int((time.time()-start) // 60), \n",
        "                                                            int((time.time()-start) // 60 * (epochs - epoch-1) // 60),\n",
        "                                                            int((time.time()-start) // 60 * (epochs - epoch-1) % 60)\n",
        "                                                            ))\n",
        "    \n",
        "    return metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PuPnIJFfAk9P"
      },
      "outputs": [],
      "source": [
        "def train(train_dl, model, loss_fn, opt, epoch):\n",
        "    losses = []\n",
        "    n_examples = 0\n",
        "    model.cuda()\n",
        "    \n",
        "    model.train()\n",
        "\n",
        "    # for i, train_dl in enumerate(train_dls):\n",
        "    for i, (x, _) in enumerate(train_dl):\n",
        "        user = x['user_id'].to('cuda')\n",
        "        media = x['goodreads_id'].to('cuda')\n",
        "        y = x['rating'].to('cuda').to(torch.float32)\n",
        "\n",
        "        pred = model(user, media)\n",
        "        pred = pred.squeeze()\n",
        "\n",
        "        loss = loss_fn(pred, y)\n",
        "        \n",
        "        opt.zero_grad()\n",
        "        loss.backward()\n",
        "        opt.step()\n",
        "\n",
        "        losses += [loss.detach()*len(y)]\n",
        "        n_examples += len(y)\n",
        "\n",
        "        if (i+1) % (30000000//8192) == 0:\n",
        "            print('Train: Epoch {} - {} - loss {:.3f} - rmse {:.3f}'.format(\n",
        "                                                                    epoch, n_examples,\n",
        "                                                                    torch.tensor(losses).sum()/n_examples, \n",
        "                                                                    (torch.tensor(losses).sum()/n_examples).sqrt()))\n",
        "\n",
        "    return torch.tensor(losses).sum()/n_examples, (torch.tensor(losses).sum()/n_examples).sqrt()\n",
        "\n",
        "\n",
        "def validate(val_dl, model, loss_fn, epoch):\n",
        "    losses = []\n",
        "    n_examples = 0\n",
        "    model.cuda()\n",
        "    model.eval()\n",
        "\n",
        "    for i, (x, _) in enumerate(val_dl):\n",
        "        user = x['user_id'].to('cuda')\n",
        "        media = x['goodreads_id'].to('cuda')\n",
        "        y = x['rating'].to('cuda').to(torch.float32)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            pred = model(user, media)\n",
        "            pred = pred.squeeze()\n",
        "\n",
        "            loss = loss_fn(pred, y)\n",
        "\n",
        "        losses += [loss*len(y)]\n",
        "        n_examples += len(y)\n",
        "\n",
        "    print('Eval: Epoch {} - loss {:.3f} - rmse {:.3f}'.format(\n",
        "                                                      epoch,\n",
        "                                                      torch.tensor(losses).sum()/n_examples, \n",
        "                                                      (torch.tensor(losses).sum()/n_examples).sqrt()))\n",
        "\n",
        "    return torch.tensor(losses).sum()/n_examples, (torch.tensor(losses).sum()/n_examples).sqrt()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aD5DJE1KCKA4"
      },
      "source": [
        "# Experiments"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OyU2393qzvgO"
      },
      "outputs": [],
      "source": [
        "batch_size = 8192\n",
        "train_dl, val_dl, test_dl = load_dls(batch_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M5rT5UonCLzV",
        "outputId": "ac90fb20-f2d5-4e08-9fd7-074f5da689f7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train: Epoch 1 - 29999104 - loss 0.126 - rmse 0.354\n",
            "Train: Epoch 1 - 59998208 - loss 0.122 - rmse 0.349\n",
            "Train: Epoch 1 - 89997312 - loss 0.121 - rmse 0.347\n",
            "Eval: Epoch 1 - loss 0.122 - rmse 0.349\n",
            "Epoch 1/3 - completed 5M - est. remaining 0H 10M \n",
            "\n",
            "Train: Epoch 2 - 29999104 - loss 0.114 - rmse 0.338\n",
            "Train: Epoch 2 - 59998208 - loss 0.113 - rmse 0.336\n",
            "Train: Epoch 2 - 89997312 - loss 0.112 - rmse 0.335\n",
            "Eval: Epoch 2 - loss 0.119 - rmse 0.345\n",
            "Epoch 2/3 - completed 5M - est. remaining 0H 5M \n",
            "\n",
            "Train: Epoch 3 - 29999104 - loss 0.111 - rmse 0.333\n",
            "Train: Epoch 3 - 59998208 - loss 0.110 - rmse 0.331\n",
            "Train: Epoch 3 - 89997312 - loss 0.109 - rmse 0.329\n",
            "Eval: Epoch 3 - loss 0.120 - rmse 0.346\n",
            "Epoch 3/3 - completed 5M - est. remaining 0H 0M \n",
            "\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[[tensor(0.1216), tensor(0.3486), tensor(0.1221), tensor(0.3495)],\n",
              " [tensor(0.1125), tensor(0.3355), tensor(0.1190), tensor(0.3450)],\n",
              " [tensor(0.1086), tensor(0.3295), tensor(0.1198), tensor(0.3462)]]"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Normalize + sigmoid + Popular workflow\n",
        "emb_size, hidden_dim = 32, 128\n",
        "cat_emb_shape = nvt.ops.get_embedding_sizes(workflow)\n",
        "model = MLP(emb_size, hidden_dim,\n",
        "            n_users=cat_emb_shape['user_id'][0], \n",
        "            n_media=cat_emb_shape['goodreads_id'][0],\n",
        "            dropout_rate=0.)\n",
        "\n",
        "loss_fn = nn.MSELoss()\n",
        "lr = 1e-2\n",
        "decay = 0\n",
        "opt = torch.optim.Adam(model.parameters(), lr, weight_decay=decay)\n",
        "\n",
        "epochs = 3\n",
        "train_model(train_dl, val_dl, test_dl, model, loss_fn, opt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H6dRGmwMrIgz"
      },
      "outputs": [],
      "source": [
        "trace_model(model, os.path.join(DATA_PATH, 'mlp_4l_32emb_128h_1e-2lradam_0d_3e--02_20_23.pt'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 647
        },
        "id": "2ugAQ34y9X-3",
        "outputId": "92fc352c-bf9f-4771-8204-7dd0a2b70c3e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train: Epoch 1 - 29999104 - loss 0.123 - rmse 0.351\n",
            "Train: Epoch 1 - 59998208 - loss 0.121 - rmse 0.348\n",
            "Train: Epoch 1 - 89997312 - loss 0.120 - rmse 0.346\n",
            "Eval: Epoch 1 - loss 0.127 - rmse 0.357\n",
            "Epoch 1/10 - completed 4M - est. remaining 0H 36M \n",
            "\n",
            "Train: Epoch 2 - 29999104 - loss 0.114 - rmse 0.338\n",
            "Train: Epoch 2 - 59998208 - loss 0.113 - rmse 0.336\n",
            "Train: Epoch 2 - 89997312 - loss 0.112 - rmse 0.335\n",
            "Eval: Epoch 2 - loss 0.123 - rmse 0.350\n",
            "Epoch 2/10 - completed 4M - est. remaining 0H 32M \n",
            "\n",
            "Train: Epoch 3 - 29999104 - loss 0.111 - rmse 0.333\n",
            "Train: Epoch 3 - 59998208 - loss 0.109 - rmse 0.331\n",
            "Train: Epoch 3 - 89997312 - loss 0.108 - rmse 0.329\n",
            "Eval: Epoch 3 - loss 0.124 - rmse 0.352\n",
            "Epoch 3/10 - completed 4M - est. remaining 0H 28M \n",
            "\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-53-1ea0ab0aef94>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_dl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_dl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-12-9f28f2f4fb3e>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(train_dl, val_dl, test_dl, model, loss_fn, opt)\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m         \u001b[0mmse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrmse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m         \u001b[0mval_mse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_rmse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalidate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_dl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-13-94f2128efd55>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(train_dl, model, loss_fn, opt, epoch)\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m         \u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    486\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    487\u001b[0m             )\n\u001b[0;32m--> 488\u001b[0;31m         torch.autograd.backward(\n\u001b[0m\u001b[1;32m    489\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    490\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    195\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    196\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 197\u001b[0;31m     Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    198\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m         allow_unreachable=True, accumulate_grad=True)  # Calls into the C++ engine to run the backward pass\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "# Normalize + sigmoid + Popular workflow + short model\n",
        "emb_size, hidden_dim = 32, 128\n",
        "cat_emb_shape = nvt.ops.get_embedding_sizes(workflow)\n",
        "model = MLP(emb_size, hidden_dim,\n",
        "            n_users=cat_emb_shape['user_id'][0], \n",
        "            n_media=cat_emb_shape['goodreads_id'][0],\n",
        "            dropout_rate=0.)\n",
        "\n",
        "loss_fn = nn.MSELoss()\n",
        "lr = 1e-2\n",
        "decay = 0\n",
        "opt = torch.optim.Adam(model.parameters(), lr, weight_decay=decay)\n",
        "\n",
        "epochs = 10\n",
        "train_model(train_dl, val_dl, test_dl, model, loss_fn, opt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 579
        },
        "id": "xLHZ1ILmMn5u",
        "outputId": "b2886bdb-68dd-445d-9229-a200449f2156"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train: Epoch 1 - 29999104 - loss 0.128 - rmse 0.357\n",
            "Train: Epoch 1 - 59998208 - loss 0.124 - rmse 0.353\n",
            "Train: Epoch 1 - 89997312 - loss 0.123 - rmse 0.351\n",
            "Eval: Epoch 1 - loss 0.121 - rmse 0.348\n",
            "Epoch 1/10 - completed 5M - est. remaining 0H 45M \n",
            "\n",
            "Train: Epoch 2 - 29999104 - loss 0.117 - rmse 0.342\n",
            "Train: Epoch 2 - 59998208 - loss 0.116 - rmse 0.341\n",
            "Train: Epoch 2 - 89997312 - loss 0.115 - rmse 0.340\n",
            "Eval: Epoch 2 - loss 0.119 - rmse 0.345\n",
            "Epoch 2/10 - completed 5M - est. remaining 0H 40M \n",
            "\n",
            "Train: Epoch 3 - 29999104 - loss 0.115 - rmse 0.339\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-59-8ec2202b5530>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_dl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_dl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-12-9f28f2f4fb3e>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(train_dl, val_dl, test_dl, model, loss_fn, opt)\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m         \u001b[0mmse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrmse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m         \u001b[0mval_mse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_rmse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalidate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_dl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-13-94f2128efd55>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(train_dl, model, loss_fn, opt, epoch)\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m         \u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0mlosses\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    138\u001b[0m                 \u001b[0mprofile_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"Optimizer.step#{}.step\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofiler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecord_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprofile_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 140\u001b[0;31m                     \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    141\u001b[0m                     \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_optimizer_step_code\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\u001b[0m in \u001b[0;36m_use_grad\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m             \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_grad_enabled\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdefaults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'differentiable'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m             \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m             \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_grad_enabled\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprev_grad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure, grad_scaler)\u001b[0m\n\u001b[1;32m    232\u001b[0m                     \u001b[0mstate_steps\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'step'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 234\u001b[0;31m             adam(params_with_grad,\n\u001b[0m\u001b[1;32m    235\u001b[0m                  \u001b[0mgrads\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m                  \u001b[0mexp_avgs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\u001b[0m in \u001b[0;36madam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, foreach, capturable, differentiable, fused, grad_scale, found_inf, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize)\u001b[0m\n\u001b[1;32m    298\u001b[0m         \u001b[0mfunc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_single_tensor_adam\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    299\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 300\u001b[0;31m     func(params,\n\u001b[0m\u001b[1;32m    301\u001b[0m          \u001b[0mgrads\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    302\u001b[0m          \u001b[0mexp_avgs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\u001b[0m in \u001b[0;36m_single_tensor_adam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, grad_scale, found_inf, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize, capturable, differentiable)\u001b[0m\n\u001b[1;32m    349\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    350\u001b[0m         \u001b[0;31m# update step\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 351\u001b[0;31m         \u001b[0mstep_t\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    352\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    353\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mweight_decay\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "# Normalize + sigmoid + Popular workflow + Dropout\n",
        "emb_size, hidden_dim = 32, 128\n",
        "cat_emb_shape = nvt.ops.get_embedding_sizes(workflow)\n",
        "model = MLP(emb_size, hidden_dim,\n",
        "            n_users=cat_emb_shape['user_id'][0], \n",
        "            n_media=cat_emb_shape['goodreads_id'][0],\n",
        "            dropout_rate=0.2)\n",
        "\n",
        "loss_fn = nn.MSELoss()\n",
        "lr = 1e-2\n",
        "decay = 0\n",
        "opt = torch.optim.Adam(model.parameters(), lr, weight_decay=decay)\n",
        "\n",
        "epochs = 10\n",
        "train_model(train_dl, val_dl, test_dl, model, loss_fn, opt)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GF2TBInY0UlD"
      },
      "source": [
        "# Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JngErIO60Wgg",
        "outputId": "ab90d40b-82db-45f5-ad45-584be3ea4960"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/merlin/io/dataset.py:253: UserWarning: Initializing an NVTabular Dataset in CPU mode.This is an experimental feature with extremely limited support!\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "# TODO: Extract a user's ratings\n",
        "\n",
        "# Create DL to test specific user\n",
        "book_ids = np.unique(df_idmap['book_id'])\n",
        "user_df = pd.DataFrame({'user_id': [-1]*len(book_ids), 'book_id': book_ids, 'rating': [0]*len(book_ids)})\n",
        "\n",
        "# user_df = df_ratings[df_ratings['userId'] == 72315]\n",
        "user_ds = nvt.Dataset(user_df)\n",
        "\n",
        "torch_ds = TorchAsyncItr(\n",
        "    workflow.transform(user_ds),\n",
        "    batch_size=1024,\n",
        "    cats=['user_id', 'goodreads_id'],\n",
        "    conts=[\"rating\"], \n",
        ")\n",
        "dl = DLDataLoader(torch_ds, batch_size=None, pin_memory=False, num_workers=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-7A9OsEN0ali"
      },
      "outputs": [],
      "source": [
        "# Test most popular user\n",
        "loss_fn = nn.MSELoss()\n",
        "validate(dl, model, loss_fn, -1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X7_GtuWB0dgJ"
      },
      "outputs": [],
      "source": [
        "preds = []\n",
        "\n",
        "model.cuda()\n",
        "model.eval()\n",
        "for i, (x, _) in enumerate(dl):\n",
        "    user = x['userId'].to('cuda')\n",
        "    media = x['movieId'].to('cuda')\n",
        "    y = x['rating'].to('cuda')\n",
        "\n",
        "    with torch.no_grad():\n",
        "        pred = model(user, media)\n",
        "        pred = pred.squeeze().cpu()\n",
        "        preds.extend(pred)\n",
        "\n",
        "print(sorted(zip(preds, movie_ids), key=lambda x: x[0], reverse=True)[:2])\n",
        "\n",
        "sorted_preds = sorted(zip(preds, movie_ids), key=lambda x: x[0], reverse=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qfCjjFJ00_md",
        "outputId": "b938cc09-543f-46be-cfb0-a1fdfb13659a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[(tensor(0.9820), 7276), (tensor(0.9820), 92385), (tensor(0.9741), 68616), (tensor(0.9741), 1117756), (tensor(0.9734), 311399)]\n"
          ]
        }
      ],
      "source": [
        "# Test against default embedding\n",
        "default_user_emb = extract_prod_user_emb(model.user_emb.weight.detach(), None)\n",
        "test_model = prodMLP(model, default_user_emb, model.media_emb.weight.detach())\n",
        "\n",
        "preds = []\n",
        "\n",
        "test_model.cuda()\n",
        "test_model.eval()\n",
        "for i, (x, _) in enumerate(dl):\n",
        "    media = x['goodreads_id']\n",
        "    # Remove any media not in training data\n",
        "    idxs = (media>0).squeeze()\n",
        "    media = media[idxs].to('cuda')\n",
        "    user = x['user_id'][idxs].to('cuda')\n",
        "    # print(torch.max(user))\n",
        "    y = x['rating'][idxs].to('cuda')\n",
        "\n",
        "    with torch.no_grad():\n",
        "        pred = test_model(user, media)\n",
        "        pred = pred.squeeze().cpu()\n",
        "        preds.extend(pred)\n",
        "\n",
        "sorted_preds = sorted(zip(preds, book_ids), key=lambda x: x[0], reverse=True)\n",
        "print(sorted_preds[:5])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        },
        "id": "ZhFqq0rAxbUV",
        "outputId": "ff293a8b-eae4-4ede-8024-0c0a959c0852"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-7a9b1a62-c67c-4603-9b59-e2ff76b37b29\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>book_id</th>\n",
              "      <th>goodreads_id</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>48608</th>\n",
              "      <td>68616</td>\n",
              "      <td>375990</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7a9b1a62-c67c-4603-9b59-e2ff76b37b29')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-7a9b1a62-c67c-4603-9b59-e2ff76b37b29 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-7a9b1a62-c67c-4603-9b59-e2ff76b37b29');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "       book_id  goodreads_id\n",
              "48608    68616        375990"
            ]
          },
          "execution_count": 48,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_idmap[df_idmap['book_id']==68616]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S0a1hseW031A"
      },
      "source": [
        "# Production"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D0lgj5xO1C23"
      },
      "outputs": [],
      "source": [
        "def trace_model(model, path):\n",
        "    model.to('cpu')\n",
        "    model.eval()\n",
        "\n",
        "    inp = (torch.randint(1, 10000, (16,1)), \n",
        "        torch.randint(1, 10000, (16,1)))\n",
        "    traced_model = torch.jit.trace(model, inp)\n",
        "    traced_model.save(path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "atS0kGzI1Zq_"
      },
      "outputs": [],
      "source": [
        "# Production models from trained models/embeddings\n",
        "import copy\n",
        "\n",
        "def prodMLP(model, prod_user_emb, train_media_emb):\n",
        "    prod_model = copy.deepcopy(model)\n",
        "    prod_model.user_emb = nn.Embedding.from_pretrained(prod_user_emb, freeze=True)\n",
        "    prod_model.media_emb = nn.Embedding.from_pretrained(train_media_emb, freeze=True)\n",
        "    return prod_model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xzPA297D1fhD"
      },
      "outputs": [],
      "source": [
        "def extract_prod_user_emb(train_emb: torch.Tensor, start_idx: int, end_idx: int=None) -> torch.Tensor:\n",
        "    ''' Extracts the default user embedding and real user embedding for use in production.\n",
        "        The default embedding is taken as the average embedding of real and train users \n",
        "        (for the time being).\n",
        "    \n",
        "    Args:\n",
        "      train_emb: the embedding tensor from the trained model.\n",
        "      start_idx: the start idx in the train_emb of the real users. \n",
        "        If none then just extract default.\n",
        "      end_idx: the end idx in the train_emb of the real users.\n",
        "        If none then use up through last idx.\n",
        "\n",
        "    Returns:\n",
        "      The concatenated [default embedding, real user embedding]\n",
        "    '''\n",
        "    default_emb = torch.mean(train_emb, dim=0, keepdim=True)\n",
        "    if start_idx is None:\n",
        "      return default_emb\n",
        "    emb = train_emb[start_idx:end_idx+1] if end_idx is not None else train_emb[start_idx:]\n",
        "    return torch.cat([default_emb, emb], axis=0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gVP2h8cR310_"
      },
      "source": [
        "## Cluster Embeddings\n",
        "An efficient way to adjust to the user's preferences early on before we have enough training data for the user. \\\\\n",
        "We first cluster the user embeddings of the model. We then take the average ratings for each cluster and map \\\\\n",
        "the user to the closest cluster by their ratings. We use this cluster's embedding for the user. Each time the user  \\\\\n",
        "rates something new the embedding can be adjusted as needed without training."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yTbs5OP034G0"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from sklearn.cluster import MiniBatchKMeans\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4G6BTf2w4DoG"
      },
      "outputs": [],
      "source": [
        "model = torch.jit.load(\n",
        "    os.path.join(DATA_PATH, 'mlp_4l_32emb_128h_1e-2lradam_0d_3e--02_20_23.pt')\n",
        "    )\n",
        "user_embs = model.user_emb.weight.clone().detach().numpy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-_WOyx6J4H79",
        "outputId": "dcc24f86-ec4d-4afb-c650-3702d8d57c2e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(743313, 32)"
            ]
          },
          "execution_count": 51,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "user_embs.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aLLH6bKg4RVV"
      },
      "source": [
        "### Figure out K"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WFCSxK0n4Kkm",
        "outputId": "b4520eac-b0b8-473b-d53c-01ac10311741"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "10 30481936.0\n",
            "20 28808806.0\n",
            "50 26880458.0\n",
            "100 25652400.0\n",
            "150 24995686.0\n",
            "200 24548728.0\n",
            "500 23171704.0\n",
            "1000 22184494.0\n",
            "2000 21177758.0\n",
            "5000 19840266.0\n",
            "10000 22538924.0\n"
          ]
        }
      ],
      "source": [
        "ssd = []\n",
        "cluster_sizes = [10,20,50,100,150,200,500,1000,2000,5000,10000]\n",
        "for n_clusters in cluster_sizes:\n",
        "    kmeans = MiniBatchKMeans(n_clusters=n_clusters).fit(user_embs)\n",
        "    ssd.append(kmeans.inertia_)\n",
        "    print(n_clusters, kmeans.inertia_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 293
        },
        "id": "OblH_auZ4NCN",
        "outputId": "492854d3-5171-4482-c982-b9b1d2c226b6"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f0e0a993a60>]"
            ]
          },
          "execution_count": 53,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "plt.plot(cluster_sizes, ssd)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZjH4RZgi4fnP"
      },
      "source": [
        "### Final Clustering"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_6BX3INJ4QKp"
      },
      "outputs": [],
      "source": [
        "n_clusters = 500\n",
        "\n",
        "kmeans = MiniBatchKMeans(n_clusters=n_clusters).fit(user_embs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mJzmfgyPDJxq",
        "outputId": "424c11cf-7a7c-4a48-bdcb-b0cb0b74e49b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "23156248.0"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "kmeans.inertia_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wf5hipZN4aUF",
        "outputId": "e2e9afcb-b9bd-4388-8db4-a5ea745873df"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[140 258 125 ...   9 493 446]\n",
            "(array([41033, 38647, 36630, 36463, 36334, 38430, 41075, 36517, 38331,\n",
            "       36220, 36504, 35186, 40252, 40935, 36645, 32097, 39120, 36759,\n",
            "       34861, 31274]), array([  0.  ,  24.95,  49.9 ,  74.85,  99.8 , 124.75, 149.7 , 174.65,\n",
            "       199.6 , 224.55, 249.5 , 274.45, 299.4 , 324.35, 349.3 , 374.25,\n",
            "       399.2 , 424.15, 449.1 , 474.05, 499.  ]))\n"
          ]
        }
      ],
      "source": [
        "# Look at label distribution\n",
        "print(kmeans.labels_)\n",
        "print(np.histogram(kmeans.labels_, bins=20))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GfHF7kW34eyB",
        "outputId": "61dc2c1b-e1f9-4046-86a9-4a76ab203d07"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[ 1.5540259e+00 -4.4206059e-01 -1.4302121e-01 ...  1.4149971e+00\n",
            "   1.0822490e+00  3.0509502e-01]\n",
            " [ 2.7789828e-01 -3.1944099e-01  4.5839405e-01 ...  6.4129990e-01\n",
            "  -5.9602547e-02  6.8693841e-01]\n",
            " [-1.9379914e+00 -1.8769772e+00  2.1123948e+00 ...  1.3466828e+00\n",
            "   9.9314779e-01 -2.1987462e+00]\n",
            " ...\n",
            " [ 3.3640349e-01  1.1995438e-03  3.1560275e-01 ... -1.2306819e+00\n",
            "  -1.3515763e+00  1.2175084e-01]\n",
            " [-2.8880504e-01  9.0865850e-01  3.0839983e-01 ...  9.7966686e-02\n",
            "  -3.9981684e-01 -6.8123543e-01]\n",
            " [ 7.4281895e-01  1.0470992e+00 -1.4653597e+00 ... -1.0181879e-01\n",
            "   8.8746423e-01  3.8632560e-01]]\n",
            "(array([20, 60, 76, 64, 62, 45, 35, 32, 32, 17, 12, 18,  9,  5,  5,  1,  3,\n",
            "        0,  1,  3]), array([ 2.2860994,  2.8503304,  3.4145615,  3.9787924,  4.5430236,\n",
            "        5.1072545,  5.6714854,  6.2357163,  6.7999477,  7.3641787,\n",
            "        7.9284096,  8.4926405,  9.056871 ,  9.621102 , 10.185333 ,\n",
            "       10.749565 , 11.313796 , 11.878027 , 12.442258 , 13.006489 ,\n",
            "       13.57072  ], dtype=float32))\n"
          ]
        }
      ],
      "source": [
        "# Look at centroids\n",
        "print(kmeans.cluster_centers_)\n",
        "norm = torch.norm(torch.tensor(kmeans.cluster_centers_), dim=1)\n",
        "print(np.histogram(norm, bins=20))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9C8-nBYwz5S0"
      },
      "outputs": [],
      "source": [
        "np.save(os.path.join(DATA_PATH, 'book_cluster_centroids_500--02_20_23'), kmeans.cluster_centers_)\n",
        "np.save(os.path.join(DATA_PATH, 'book_cluster_labels_500--02_20_23'), kmeans.labels_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hB0R8HlpDgMK"
      },
      "outputs": [],
      "source": [
        "# Load train_dl\n",
        "batch_size = 1024\n",
        "train_path = os.path.join(DATA_PATH, 'goodreads_interactions-clean-train')\n",
        "train_paths = [os.path.join(train_path, x) for x in os.listdir(train_path) \\\n",
        "                if '.parquet' in x]\n",
        "\n",
        "train_torch = TorchAsyncItr(\n",
        "    nvt.Dataset(train_paths, engine='parquet'),\n",
        "    batch_size=batch_size,\n",
        "    cats=['user_id', 'goodreads_id'],\n",
        "    conts=[\"rating\"], \n",
        ")\n",
        "train_dl = DLDataLoader(\n",
        "    train_torch, batch_size=None, pin_memory=False, num_workers=0\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "guV6bwraNbjD"
      },
      "outputs": [],
      "source": [
        "cluster_labels = np.load(os.path.join(DATA_PATH, 'book_cluster_labels_500--02_20_23.npy'))\n",
        "n_clusters = 500"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FlHUZ4bJyj3-"
      },
      "outputs": [],
      "source": [
        "# Vector Version\n",
        "# cat_emb_shape = nvt.ops.get_embedding_sizes(workflow)\n",
        "# n_users = cat_emb_shape['user_id'][0]\n",
        "# n_media = cat_emb_shape['goodreads_id'][0]\n",
        "\n",
        "# ratings = np.zeros((n_clusters, n_media))\n",
        "# counts = np.zeros((n_clusters, n_media))\n",
        "\n",
        "# for x, _ in train_dl:\n",
        "#     user = x['user_id'].numpy().squeeze()\n",
        "#     cluster = cluster_labels[user]\n",
        "#     media = x['goodreads_id'].numpy().squeeze()\n",
        "#     y = x['rating'].numpy().squeeze()\n",
        "    \n",
        "#     for i in range(len(user)):\n",
        "#         if user[i] == 0: continue\n",
        "#         ratings[cluster[i], media[i]] += y[i]\n",
        "#         counts[cluster[i], media[i]] += 1.\n",
        "\n",
        "# ratings *= 5\n",
        "# # Only count ratings by majority \n",
        "# # ratings = ratings[counts >= 10]\n",
        "# ratings /= counts\n",
        "# ratings[np.isnan(ratings)] = 0.\n",
        "\n",
        "# np.save(os.path.join(DATA_PATH, 'book_cluster_ratings_500--02_20_23'), ratings)\n",
        "\n",
        "# Dict Version\n",
        "cat_emb_shape = nvt.ops.get_embedding_sizes(workflow)\n",
        "n_users = cat_emb_shape['user_id'][0]\n",
        "n_media = cat_emb_shape['goodreads_id'][0]\n",
        "\n",
        "ratings = {i:{} for i in range(n_clusters)} \n",
        "counts =  {i:{} for i in range(n_clusters)} \n",
        "\n",
        "for x, _ in train_dl:\n",
        "    user = x['user_id'].numpy().squeeze()\n",
        "    # cluster = kmeans.labels_[user]\n",
        "    cluster = cluster_labels[user]\n",
        "    media = x['goodreads_id'].numpy().squeeze()\n",
        "    y = x['rating'].numpy().squeeze()\n",
        "    \n",
        "    for i in range(len(user)):\n",
        "        if user[i] == 0: continue\n",
        "        if media[i] in ratings[cluster[i]]:\n",
        "            ratings[cluster[i]][media[i]] += y[i]\n",
        "            counts[cluster[i]][media[i]] += 1.\n",
        "        else:\n",
        "            ratings[cluster[i]][media[i]] = y[i]\n",
        "            counts[cluster[i]][media[i]] = 1.\n",
        "\n",
        "# Gather average rating\n",
        "del_ratings = []\n",
        "for i, cluster in ratings.items():\n",
        "    for media, rating in cluster.items():\n",
        "        # Only include ratings if 5 or more people in cluster have rated\n",
        "        if counts[i][media] < 5:\n",
        "            del_ratings.append((i,media))\n",
        "        else:\n",
        "            cluster[media] /= counts[i][media]\n",
        "            cluster[media] *= 5\n",
        "\n",
        "for i, media in del_ratings:\n",
        "    del ratings[i][media]\n",
        "\n",
        "\n",
        "cluster_ratings = {}\n",
        "for i, cluster in ratings.items():\n",
        "    cluster_ratings[i] = {}\n",
        "    for media, rating in cluster.items():\n",
        "        cluster_ratings[i][int(media)] = rating\n",
        "\n",
        "with open(os.path.join(DATA_PATH, 'book_cluster_ratings_500-nolt5--02_20_23.json'), 'w') as f: \n",
        "    json.dump(cluster_ratings, f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8Ds3SU6YJPqL",
        "outputId": "977a2804-c86e-445f-f6b1-c421be435587"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(27694647, 3390837)"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(del_ratings), sum([len(i) for i in cluster_ratings.values()])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3z7alPxxEJLE",
        "outputId": "e575bd06-520d-4e82-ff48-1aff1401914b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "execution_count": 31,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Can't reassign to torchscript models so load state dict from ts model into new model\n",
        "ts_model = model\n",
        "emb_size, hidden_dim = 32, 128\n",
        "cat_emb_shape = nvt.ops.get_embedding_sizes(workflow)\n",
        "model = MLP(emb_size, hidden_dim, \n",
        "            n_users=cat_emb_shape['user_id'][0],\n",
        "            n_media=cat_emb_shape['goodreads_id'][0])\n",
        "model.load_state_dict(ts_model.state_dict())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KvQ1bdWEEhGa"
      },
      "outputs": [],
      "source": [
        "# Concatenate default (avg) with clusters\n",
        "default_user_emb = extract_prod_user_emb(model.user_emb.weight.detach(), None)\n",
        "centroids = torch.tensor(np.load(os.path.join(DATA_PATH, 'book_cluster_centroids_500--02_20_23.npy')))\n",
        "# centroids = torch.tensor(kmeans.cluster_centers_)\n",
        "\n",
        "test_model = prodMLP(model, torch.cat([default_user_emb, centroids], axis=0), model.media_emb.weight.detach())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qBUl9l89Esoh"
      },
      "outputs": [],
      "source": [
        "test_model.to('cpu')\n",
        "test_model.eval()\n",
        "\n",
        "inp = (torch.zeros((1024,1), dtype=int), \n",
        "       torch.randint(1, 10000, (1024,1)))\n",
        "traced_model = torch.jit.trace(test_model, inp)\n",
        "\n",
        "traced_model.save(os.path.join(DATA_PATH, 'mlp_cluster500_4l_32emb_128h_1e-2lradam_0d_3e--book--02_20_23.pt'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DYuljABoGWUI",
        "outputId": "d15f02da-740f-4f5b-aa61-5b597ebdfa9d"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/merlin/io/dataset.py:253: UserWarning: Initializing an NVTabular Dataset in CPU mode.This is an experimental feature with extremely limited support!\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "# Create DL to test specific user\n",
        "book_ids = np.unique(df_idmap['book_id'])\n",
        "user_df = pd.DataFrame({'user_id': [-1]*len(book_ids), 'book_id': book_ids, 'rating': [0]*len(book_ids)})\n",
        "\n",
        "# user_df = df_ratings[df_ratings['userId'] == 72315]\n",
        "user_ds = nvt.Dataset(user_df)\n",
        "\n",
        "torch_ds = TorchAsyncItr(\n",
        "    workflow.transform(user_ds),\n",
        "    batch_size=1024,\n",
        "    cats=['user_id', 'goodreads_id'],\n",
        "    conts=[\"rating\"], \n",
        ")\n",
        "dl = DLDataLoader(torch_ds, batch_size=None, pin_memory=False, num_workers=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GyQixjrJGim3"
      },
      "outputs": [],
      "source": [
        "preds = []\n",
        "\n",
        "# test_model.cuda()\n",
        "test_model.eval()\n",
        "for i, (x, _) in enumerate(dl):\n",
        "    media = x['goodreads_id']\n",
        "    # Remove any media not in training data\n",
        "    idxs = (media>0).squeeze()\n",
        "    media = media[idxs] #.to('cuda')\n",
        "    user = x['user_id'][idxs] #.to('cuda')\n",
        "    y = x['rating'][idxs] #.to('cuda')\n",
        "\n",
        "    with torch.no_grad():\n",
        "        pred = test_model(user, media)\n",
        "        pred = pred.squeeze().cpu()\n",
        "        preds.extend(pred)\n",
        "\n",
        "sorted_preds = sorted(zip(preds, book_ids), key=lambda x: x[0], reverse=True)\n",
        "print(sorted_preds[:5])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 86,
      "metadata": {
        "id": "Odah2azDG3bG"
      },
      "outputs": [],
      "source": [
        "# def get_workflow_ratings_vector(user_ratings, n_media):\n",
        "#     ''' Computes the ratings vector from original ratings for use in clustering.\n",
        "\n",
        "#     Args:\n",
        "#       user_ratings: [{'bookId': int, 'rating': float}]\n",
        "#       n_media: int. Length of rating vectors in clusters\n",
        "#     '''\n",
        "#     ratings_vector = np.zeros(n_media)\n",
        "#     book_ids = [r['bookId'] for r in user_ratings]\n",
        "#     book_ratings = [r['rating'] for r in user_ratings]\n",
        "#     df = pd.DataFrame({'user_id': [-1]*len(book_ids), # Maps to 0\n",
        "#                         'book_id': book_ids,\n",
        "#                         'rating': book_ratings})\n",
        "#     # Throw away values for join\n",
        "#     df_idmap = pd.DataFrame({'book_id': book_ids, 'book_id_csv': book_ids})\n",
        "\n",
        "#     ds = nvt.Dataset(df)\n",
        "#     torch_ds = TorchAsyncItr(\n",
        "#         workflow.transform(ds),\n",
        "#         batch_size=1,\n",
        "#         cats=['user_id', 'goodreads_id'],\n",
        "#         conts=[\"rating\"], \n",
        "#     )\n",
        "#     dl = DLDataLoader(torch_ds, batch_size=None, pin_memory=False, num_workers=0)\n",
        "#     for x, _ in dl:\n",
        "#         media = x['goodreads_id']\n",
        "#         y = x['rating']\n",
        "#         ratings_vector[media] = y*5\n",
        "    \n",
        "#     return ratings_vector\n",
        "    \n",
        "\n",
        "# def find_closest_cluster(user_ratings, cluster_ratings):\n",
        "#     diff = np.linalg.norm(cluster_ratings*(user_ratings>0) - user_ratings, axis=1)\n",
        "#     cluster = np.argmin(diff)\n",
        "#     return cluster\n",
        "\n",
        "\n",
        "def get_workflow_ratings_vector(user_ratings):\n",
        "    ''' Computes the ratings vector from original ratings for use in clustering.\n",
        "\n",
        "    Args:\n",
        "      user_ratings: [{'bookId': int, 'rating': float}]\n",
        "    '''\n",
        "\n",
        "    df_idmap = pd.read_csv(os.path.join(DATA_PATH, 'book_id_map-dedup-v1.csv'))\n",
        "    df_idmap = df_idmap.drop(columns=['Unnamed: 0'])\n",
        "    df_idmap = df_idmap.rename(columns={'book_id': 'goodreads_id'})\n",
        "    df_idmap = df_idmap.rename(columns={'book_id_csv': 'book_id'})\n",
        "    \n",
        "    book_ids, goodreads_ids, book_ratings = [], [], []\n",
        "    for r in user_ratings:\n",
        "        bids = df_idmap[df_idmap['goodreads_id'] == r['bookId']]['book_id']\n",
        "        if len(bids) == 0:\n",
        "            continue\n",
        "        book_ids.append(bids.iloc[0])\n",
        "        goodreads_ids.append(r['bookId'])\n",
        "        book_ratings.append(int(r['rating']))\n",
        "\n",
        "    print(book_ids)\n",
        "    ratings_vector = np.array(book_ratings)\n",
        "    df = pd.DataFrame({'user_id': [-1]*len(book_ids),\n",
        "                        'book_id': book_ids,\n",
        "                        'rating': book_ratings})\n",
        "    # Throw away values for join\n",
        "    # df_idmap = pd.DataFrame({'book_id': book_ids, 'goodreads_id': goodreads_ids})\n",
        "\n",
        "    ds = nvt.Dataset(df)\n",
        "    torch_ds = TorchAsyncItr(\n",
        "        workflow.transform(ds),\n",
        "        batch_size=1,\n",
        "        cats=['user_id', 'goodreads_id'],\n",
        "        conts=[\"rating\"], \n",
        "    )\n",
        "    dl = DLDataLoader(torch_ds, batch_size=None, pin_memory=False, num_workers=0)\n",
        "\n",
        "    id_vector = np.array([x['goodreads_id'][0][0].numpy() for x, _ in dl])\n",
        "    print(id_vector)\n",
        "\n",
        "    return ratings_vector, id_vector\n",
        "    \n",
        "\n",
        "def find_closest_cluster(user_ratings, user_bookids, cluster_ratings):\n",
        "    # Extract cluster rating matrix to match user_rating vector\n",
        "    cluster_ratings_mat = np.zeros((len(cluster_ratings), len(user_ratings)))\n",
        "    for rating_idx, id in enumerate(user_bookids):\n",
        "        for i, cluster in cluster_ratings.items():\n",
        "            cluster_ratings_mat[int(i)][rating_idx] = cluster[str(id)] if str(id) in cluster else 0\n",
        "\n",
        "    diff = np.linalg.norm(cluster_ratings_mat - user_ratings, axis=1)\n",
        "    cluster = np.argmin(diff)\n",
        "    return cluster\n",
        "\n",
        "\n",
        "def load_cluster_ratings(path):\n",
        "    with open(path, 'r') as f:\n",
        "        data = json.load(f)\n",
        "    return data"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_idmap_real = pd.read_csv(os.path.join(DATA_PATH, 'book_id_map-dedup-v1.csv'))\n",
        "df_idmap_real = df_idmap_real.drop(columns=['Unnamed: 0'])\n",
        "df_idmap_real = df_idmap_real.rename(columns={'book_id': 'goodreads_id'})\n",
        "df_idmap_real = df_idmap_real.rename(columns={'book_id_csv': 'book_id'})\n",
        "df_idmap_real[df_idmap_real['goodreads_id'] == 22543496]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 142
        },
        "id": "woc570_wrp1v",
        "outputId": "5a0be197-9302-4313-d615-b4ca3f50e862"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        book_id  goodreads_id\n",
              "73          119      22543496\n",
              "21200     27626      22543496\n",
              "971592  2228619      22543496"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-daa49d2c-556f-480d-ab14-a55a0e68b960\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>book_id</th>\n",
              "      <th>goodreads_id</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>73</th>\n",
              "      <td>119</td>\n",
              "      <td>22543496</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21200</th>\n",
              "      <td>27626</td>\n",
              "      <td>22543496</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>971592</th>\n",
              "      <td>2228619</td>\n",
              "      <td>22543496</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-daa49d2c-556f-480d-ab14-a55a0e68b960')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-daa49d2c-556f-480d-ab14-a55a0e68b960 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-daa49d2c-556f-480d-ab14-a55a0e68b960');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 88,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-YniPgC7IBQO",
        "outputId": "2c75debd-91a2-42c0-f0a3-6de993f1cbce"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[21164, 8426, 619, 412, 387, 369, 1294, 8462, 365, 534, 119, 18151, 21041, 35047, 507, 17591, 29015, 17582, 32329, 228, 20514, 68, 171]\n",
            "[ 250  209  253  213  496  427  621  326 1207 2285 1430  722 1138 1816\n",
            " 2845 1391 1189 1381 1048 2182 1382 3713 2588]\n"
          ]
        }
      ],
      "source": [
        "cat_emb_shape = nvt.ops.get_embedding_sizes(workflow)\n",
        "n_media = cat_emb_shape['goodreads_id'][0]\n",
        "# Harry Potter's 1-3\n",
        "# r = [{'bookId': 5, 'rating': 5}, {'bookId': 15881, 'rating': 5}, \n",
        "#      {'bookId': 3, 'rating': 5}]\n",
        "\n",
        "# Nonfiction\n",
        "r = [\n",
        "    {'bookId': 11084145, 'rating': 5.0}, \n",
        "     {'bookId': 52036, 'rating': 5.0}, \n",
        "     {'bookId': 3228917, 'rating': 4.0}, \n",
        "     {'bookId': 8520610, 'rating': 4.0}, \n",
        "     {'bookId': 12609433, 'rating': 4.0}, \n",
        "     {'bookId': 11468377, 'rating': 4.0}, \n",
        "     {'bookId': 629, 'rating': 5.0}, \n",
        "     {'bookId': 10569, 'rating': 4.0}, \n",
        "     {'bookId': 6289283, 'rating': 4.0}, \n",
        "     {'bookId': 6732019, 'rating': 4.0}, \n",
        "     {'bookId': 22543496, 'rating': 4.0}, \n",
        "     {'bookId': 23692271, 'rating': 5.0}, \n",
        "     {'bookId': 22463, 'rating': 4.0}, \n",
        "     {'bookId': 615570, 'rating': 5.0}, \n",
        "     {'bookId': 1301, 'rating': 5.0}, \n",
        "     {'bookId': 38210, 'rating': 4.0}, \n",
        "     {'bookId': 28257707, 'rating': 3.0}, \n",
        "     {'bookId': 2195464, 'rating': 5.0}, \n",
        "     {'bookId': 12543, 'rating': 4.0}, \n",
        "     {'bookId': 18050143, 'rating': 4.0}, \n",
        "     {'bookId': 6346975, 'rating': 3.0}, \n",
        "     {'bookId': 6480781, 'rating': 5.0}, \n",
        "     {'bookId': 4866, 'rating': 4.0}\n",
        "     ]\n",
        "\n",
        "ratings_vector, id_vector = get_workflow_ratings_vector(r)\n",
        "cluster = find_closest_cluster(ratings_vector, id_vector,\n",
        "                               load_cluster_ratings(os.path.join(DATA_PATH, 'book_cluster_ratings_500-nolt5--02_20_23.json')))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sx86KHOi5M-p",
        "outputId": "eb41a4d8-6309-4555-a056-d28707ab6965"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[5 5 5] [54516 19158 10675]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "300"
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ],
      "source": [
        "print(ratings_vector, id_vector)\n",
        "cluster"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "curr_cluster_ratings = load_cluster_ratings(os.path.join(DATA_PATH, 'book_cluster_ratings_500-nolt5--02_20_23.json'))[str(cluster)]\n",
        "for x in id_vector:\n",
        "    if str(x) in curr_cluster_ratings:\n",
        "        print(x, curr_cluster_ratings[str(x)])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CsbpVNnn9qlY",
        "outputId": "4e86c410-db7a-4e56-a1bf-d4837a8fe74a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "19158 3.8750000670552254\n",
            "10675 4.166666691501935\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UCTw9pPJKVhE"
      },
      "outputs": [],
      "source": [
        "model = torch.jit.load(os.path.join(DATA_PATH, 'mlp_cluster500_4l_32emb_128h_1e-2lradam_0d_3e--book--02_20_23.pt'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o_p21OkCKrGv",
        "outputId": "decdd645-3985-4d28-c650-58b521ce8e46"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[(tensor(0.9732), 7665), (tensor(0.9698), 86758), (tensor(0.9687), 143955), (tensor(0.9680), 63973), (tensor(0.9669), 664269)]\n"
          ]
        }
      ],
      "source": [
        "preds = []\n",
        "\n",
        "# model.cuda()\n",
        "model.eval()\n",
        "for i, (x, _) in enumerate(dl):\n",
        "    media = x['goodreads_id']\n",
        "    # Remove any media not in training data\n",
        "    idxs = (media>0).squeeze()\n",
        "    media = media[idxs] #.to('cuda')\n",
        "    user = x['user_id'][idxs] + cluster + 1 #.to('cuda') # +1 for default embedding\n",
        "    y = x['rating'][idxs] #.to('cuda')\n",
        "\n",
        "    with torch.no_grad():\n",
        "        pred = model(user, media)\n",
        "        pred = pred.squeeze().cpu()\n",
        "        preds.extend(pred)\n",
        "\n",
        "sorted_preds = sorted(zip(preds, book_ids), key=lambda x: x[0], reverse=True)\n",
        "print(sorted_preds[:5])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        },
        "id": "NssSPRu7LmN5",
        "outputId": "8c057478-81d4-457a-d241-d6be9ef8988c"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-0dd8043a-7c71-4458-9caa-4361950e8ac1\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>book_id</th>\n",
              "      <th>goodreads_id</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>45153</th>\n",
              "      <td>63973</td>\n",
              "      <td>93220</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0dd8043a-7c71-4458-9caa-4361950e8ac1')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-0dd8043a-7c71-4458-9caa-4361950e8ac1 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-0dd8043a-7c71-4458-9caa-4361950e8ac1');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "       book_id  goodreads_id\n",
              "45153    63973         93220"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_idmap[df_idmap['book_id'] == 63973]"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "toc_visible": true,
      "provenance": [],
      "mount_file_id": "1Ze157xAR8ciNMC5D8Q4M42zT6BbBHFME",
      "authorship_tag": "ABX9TyNgVzLu3u7pxOhVedCkERg+",
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}