{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sorennelson/MediaRecommendation/blob/v2-recsys/MovieRec.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OEDWfaTtbTXQ"
      },
      "outputs": [],
      "source": [
        "# Data: MovieLens 25M Dataset - https://grouplens.org/datasets/movielens/25m/\n",
        "\n",
        "# Final Model:\n",
        "# Final Results\n",
        "\n",
        "# Resources: \n",
        "  # https://paperswithcode.com/dataset/movielens\n",
        "  # https://developer.nvidia.com/nvidia-merlin"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "S87zEcqDXToF",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "1b258e79-acda-4eb3-8b81-0875fc710c37"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting nvtabular\n",
            "  Downloading nvtabular-1.8.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (301 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m301.2/301.2 KB\u001b[0m \u001b[31m20.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting merlin-core>=0.2.0\n",
            "  Downloading merlin-core-0.10.0.tar.gz (112 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m112.1/112.1 KB\u001b[0m \u001b[31m14.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting merlin-dataloader>=0.0.2\n",
            "  Downloading merlin-dataloader-0.0.4.tar.gz (49 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.3/49.3 KB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.8/dist-packages (from nvtabular) (1.7.3)\n",
            "Requirement already satisfied: numba>=0.54 in /usr/local/lib/python3.8/dist-packages (from merlin-core>=0.2.0->nvtabular) (0.56.4)\n",
            "Collecting distributed>=2022.3.0\n",
            "  Downloading distributed-2023.1.1-py3-none-any.whl (934 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m934.1/934.1 KB\u001b[0m \u001b[31m64.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting dask>=2022.3.0\n",
            "  Downloading dask-2023.1.1-py3-none-any.whl (1.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m60.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: protobuf>=3.0.0 in /usr/local/lib/python3.8/dist-packages (from merlin-core>=0.2.0->nvtabular) (3.19.6)\n",
            "Collecting betterproto<2.0.0\n",
            "  Downloading betterproto-1.2.5.tar.gz (26 kB)\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.8/dist-packages (from merlin-core>=0.2.0->nvtabular) (23.0)\n",
            "Collecting fsspec==2022.5.0\n",
            "  Downloading fsspec-2022.5.0-py3-none-any.whl (140 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m140.6/140.6 KB\u001b[0m \u001b[31m12.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pyarrow>=5.0.0 in /usr/local/lib/python3.8/dist-packages (from merlin-core>=0.2.0->nvtabular) (9.0.0)\n",
            "Requirement already satisfied: tqdm>=4.0 in /usr/local/lib/python3.8/dist-packages (from merlin-core>=0.2.0->nvtabular) (4.64.1)\n",
            "Requirement already satisfied: pandas<1.4.0dev0,>=1.2.0 in /usr/local/lib/python3.8/dist-packages (from merlin-core>=0.2.0->nvtabular) (1.3.5)\n",
            "Requirement already satisfied: tensorflow-metadata>=1.2.0 in /usr/local/lib/python3.8/dist-packages (from merlin-core>=0.2.0->nvtabular) (1.12.0)\n",
            "Requirement already satisfied: numpy<1.23.0,>=1.16.5 in /usr/local/lib/python3.8/dist-packages (from scipy->nvtabular) (1.21.6)\n",
            "Collecting grpclib\n",
            "  Downloading grpclib-0.4.3.tar.gz (62 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.1/62.1 KB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting stringcase\n",
            "  Downloading stringcase-1.2.0.tar.gz (3.0 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.8/dist-packages (from dask>=2022.3.0->merlin-core>=0.2.0->nvtabular) (7.1.2)\n",
            "Requirement already satisfied: partd>=0.3.10 in /usr/local/lib/python3.8/dist-packages (from dask>=2022.3.0->merlin-core>=0.2.0->nvtabular) (1.3.0)\n",
            "Requirement already satisfied: toolz>=0.8.2 in /usr/local/lib/python3.8/dist-packages (from dask>=2022.3.0->merlin-core>=0.2.0->nvtabular) (0.12.0)\n",
            "Requirement already satisfied: cloudpickle>=1.1.1 in /usr/local/lib/python3.8/dist-packages (from dask>=2022.3.0->merlin-core>=0.2.0->nvtabular) (2.2.1)\n",
            "Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.8/dist-packages (from dask>=2022.3.0->merlin-core>=0.2.0->nvtabular) (6.0)\n",
            "Requirement already satisfied: sortedcontainers>=2.0.5 in /usr/local/lib/python3.8/dist-packages (from distributed>=2022.3.0->merlin-core>=0.2.0->nvtabular) (2.4.0)\n",
            "Requirement already satisfied: tornado>=6.0.3 in /usr/local/lib/python3.8/dist-packages (from distributed>=2022.3.0->merlin-core>=0.2.0->nvtabular) (6.0.4)\n",
            "Collecting psutil>=5.7.0\n",
            "  Downloading psutil-5.9.4-cp36-abi3-manylinux_2_12_x86_64.manylinux2010_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (280 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m280.2/280.2 KB\u001b[0m \u001b[31m28.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: zict>=2.1.0 in /usr/local/lib/python3.8/dist-packages (from distributed>=2022.3.0->merlin-core>=0.2.0->nvtabular) (2.2.0)\n",
            "Requirement already satisfied: jinja2>=2.10.3 in /usr/local/lib/python3.8/dist-packages (from distributed>=2022.3.0->merlin-core>=0.2.0->nvtabular) (2.11.3)\n",
            "Requirement already satisfied: tblib>=1.6.0 in /usr/local/lib/python3.8/dist-packages (from distributed>=2022.3.0->merlin-core>=0.2.0->nvtabular) (1.7.0)\n",
            "Requirement already satisfied: urllib3>=1.24.3 in /usr/local/lib/python3.8/dist-packages (from distributed>=2022.3.0->merlin-core>=0.2.0->nvtabular) (1.24.3)\n",
            "Requirement already satisfied: locket>=1.0.0 in /usr/local/lib/python3.8/dist-packages (from distributed>=2022.3.0->merlin-core>=0.2.0->nvtabular) (1.0.0)\n",
            "Requirement already satisfied: msgpack>=1.0.0 in /usr/local/lib/python3.8/dist-packages (from distributed>=2022.3.0->merlin-core>=0.2.0->nvtabular) (1.0.4)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.8/dist-packages (from numba>=0.54->merlin-core>=0.2.0->nvtabular) (6.0.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.8/dist-packages (from numba>=0.54->merlin-core>=0.2.0->nvtabular) (57.4.0)\n",
            "Requirement already satisfied: llvmlite<0.40,>=0.39.0dev0 in /usr/local/lib/python3.8/dist-packages (from numba>=0.54->merlin-core>=0.2.0->nvtabular) (0.39.1)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.8/dist-packages (from pandas<1.4.0dev0,>=1.2.0->merlin-core>=0.2.0->nvtabular) (2022.7.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.8/dist-packages (from pandas<1.4.0dev0,>=1.2.0->merlin-core>=0.2.0->nvtabular) (2.8.2)\n",
            "Requirement already satisfied: googleapis-common-protos<2,>=1.52.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow-metadata>=1.2.0->merlin-core>=0.2.0->nvtabular) (1.58.0)\n",
            "Requirement already satisfied: absl-py<2.0.0,>=0.9 in /usr/local/lib/python3.8/dist-packages (from tensorflow-metadata>=1.2.0->merlin-core>=0.2.0->nvtabular) (1.4.0)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.8/dist-packages (from jinja2>=2.10.3->distributed>=2022.3.0->merlin-core>=0.2.0->nvtabular) (2.0.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.8/dist-packages (from python-dateutil>=2.7.3->pandas<1.4.0dev0,>=1.2.0->merlin-core>=0.2.0->nvtabular) (1.15.0)\n",
            "Requirement already satisfied: heapdict in /usr/local/lib/python3.8/dist-packages (from zict>=2.1.0->distributed>=2022.3.0->merlin-core>=0.2.0->nvtabular) (1.0.1)\n",
            "Collecting h2<5,>=3.1.0\n",
            "  Downloading h2-4.1.0-py3-none-any.whl (57 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.5/57.5 KB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: multidict in /usr/local/lib/python3.8/dist-packages (from grpclib->betterproto<2.0.0->merlin-core>=0.2.0->nvtabular) (6.0.4)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.8/dist-packages (from importlib-metadata->numba>=0.54->merlin-core>=0.2.0->nvtabular) (3.12.0)\n",
            "Collecting hpack<5,>=4.0\n",
            "  Downloading hpack-4.0.0-py3-none-any.whl (32 kB)\n",
            "Collecting hyperframe<7,>=6.0\n",
            "  Downloading hyperframe-6.0.1-py3-none-any.whl (12 kB)\n",
            "Building wheels for collected packages: merlin-core, merlin-dataloader, betterproto, grpclib, stringcase\n",
            "  Building wheel for merlin-core (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for merlin-core: filename=merlin_core-0.10.0-py3-none-any.whl size=118957 sha256=bd973814b0f8fa766ec3695675fc99153458c00d3022845aed2424064095946f\n",
            "  Stored in directory: /root/.cache/pip/wheels/fc/61/f5/248b8e08a868d53576e56cab6d8dcad527c28a69499cf8486a\n",
            "  Building wheel for merlin-dataloader (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for merlin-dataloader: filename=merlin_dataloader-0.0.4-py3-none-any.whl size=40636 sha256=cb4206ccd2941d613511c9119eb2362860abf30b330bbb37e51210a14efd94e7\n",
            "  Stored in directory: /root/.cache/pip/wheels/19/e2/06/e3d8eefc51ce919c86894c57ed23356ff99c8194635fe60f56\n",
            "  Building wheel for betterproto (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for betterproto: filename=betterproto-1.2.5-py3-none-any.whl size=22012 sha256=3b1d1006a4f9adc33513dda9d7276ad8d5804974213d1d7520bb426af4a224d0\n",
            "  Stored in directory: /root/.cache/pip/wheels/f0/d8/2c/88deaa4bcf85c355055d31aebbc3b8e554ab38fd0823aa6f08\n",
            "  Building wheel for grpclib (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for grpclib: filename=grpclib-0.4.3-py3-none-any.whl size=77081 sha256=1ac9f5b2a3d92c873107749879dfad26afa3640013e040eaa59e8683ac323726\n",
            "  Stored in directory: /root/.cache/pip/wheels/3c/bf/37/810d98c051f7709adc84c97077afaef55a58725f879fc7f780\n",
            "  Building wheel for stringcase (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for stringcase: filename=stringcase-1.2.0-py3-none-any.whl size=3587 sha256=0926aa91e0fc2f64412405414dad63848693799c9818325c5b625b443fe9a260\n",
            "  Stored in directory: /root/.cache/pip/wheels/04/0e/31/bf265c64f2a4d24516e9923f1f6293c3bcbcde75e0d80ab47a\n",
            "Successfully built merlin-core merlin-dataloader betterproto grpclib stringcase\n",
            "Installing collected packages: stringcase, psutil, hyperframe, hpack, fsspec, h2, dask, grpclib, distributed, betterproto, merlin-core, merlin-dataloader, nvtabular\n",
            "  Attempting uninstall: psutil\n",
            "    Found existing installation: psutil 5.4.8\n",
            "    Uninstalling psutil-5.4.8:\n",
            "      Successfully uninstalled psutil-5.4.8\n",
            "  Attempting uninstall: fsspec\n",
            "    Found existing installation: fsspec 2023.1.0\n",
            "    Uninstalling fsspec-2023.1.0:\n",
            "      Successfully uninstalled fsspec-2023.1.0\n",
            "  Attempting uninstall: dask\n",
            "    Found existing installation: dask 2022.2.1\n",
            "    Uninstalling dask-2022.2.1:\n",
            "      Successfully uninstalled dask-2022.2.1\n",
            "  Attempting uninstall: distributed\n",
            "    Found existing installation: distributed 2022.2.1\n",
            "    Uninstalling distributed-2022.2.1:\n",
            "      Successfully uninstalled distributed-2022.2.1\n",
            "Successfully installed betterproto-1.2.5 dask-2023.1.1 distributed-2023.1.1 fsspec-2022.5.0 grpclib-0.4.3 h2-4.1.0 hpack-4.0.0 hyperframe-6.0.1 merlin-core-0.10.0 merlin-dataloader-0.0.4 nvtabular-1.8.1 psutil-5.9.4 stringcase-1.2.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "psutil"
                ]
              }
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting merlin\n",
            "  Downloading merlin-1.9.1-py3-none-any.whl (232 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m232.4/232.4 KB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting redis>=4.3.4\n",
            "  Downloading redis-4.4.2-py3-none-any.whl (237 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m237.8/237.8 KB\u001b[0m \u001b[31m22.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting cached-property\n",
            "  Downloading cached_property-1.5.2-py2.py3-none-any.whl (7.6 kB)\n",
            "Collecting coloredlogs\n",
            "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 KB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from merlin) (1.21.6)\n",
            "Collecting maestrowf>=1.1.9dev1\n",
            "  Downloading maestrowf-1.1.9-py3-none-any.whl (132 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m132.5/132.5 KB\u001b[0m \u001b[31m12.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting cryptography\n",
            "  Downloading cryptography-39.0.0-cp36-abi3-manylinux_2_28_x86_64.whl (4.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.2/4.2 MB\u001b[0m \u001b[31m111.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting parse\n",
            "  Downloading parse-1.19.0.tar.gz (30 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting celery[redis,sqlalchemy]>=5.0.3\n",
            "  Downloading celery-5.2.7-py3-none-any.whl (405 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m405.6/405.6 KB\u001b[0m \u001b[31m42.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tabulate in /usr/local/lib/python3.8/dist-packages (from merlin) (0.8.10)\n",
            "Requirement already satisfied: pyyaml>=5.1.2 in /usr/local/lib/python3.8/dist-packages (from merlin) (6.0)\n",
            "Requirement already satisfied: psutil>=5.1.0 in /usr/local/lib/python3.8/dist-packages (from merlin) (5.9.4)\n",
            "Collecting click-repl>=0.2.0\n",
            "  Downloading click_repl-0.2.0-py3-none-any.whl (5.2 kB)\n",
            "Collecting billiard<4.0,>=3.6.4.0\n",
            "  Downloading billiard-3.6.4.0-py3-none-any.whl (89 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m89.5/89.5 KB\u001b[0m \u001b[31m11.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting kombu<6.0,>=5.2.3\n",
            "  Downloading kombu-5.2.4-py3-none-any.whl (189 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m189.2/189.2 KB\u001b[0m \u001b[31m20.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting click-plugins>=1.1.1\n",
            "  Downloading click_plugins-1.1.1-py2.py3-none-any.whl (7.5 kB)\n",
            "Collecting vine<6.0,>=5.0.0\n",
            "  Downloading vine-5.0.0-py2.py3-none-any.whl (9.4 kB)\n",
            "Collecting click<9.0,>=8.0.3\n",
            "  Downloading click-8.1.3-py3-none-any.whl (96 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m96.6/96.6 KB\u001b[0m \u001b[31m14.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pytz>=2021.3 in /usr/local/lib/python3.8/dist-packages (from celery[redis,sqlalchemy]>=5.0.3->merlin) (2022.7.1)\n",
            "Collecting click-didyoumean>=0.0.3\n",
            "  Downloading click_didyoumean-0.3.0-py3-none-any.whl (2.7 kB)\n",
            "Requirement already satisfied: sqlalchemy in /usr/local/lib/python3.8/dist-packages (from celery[redis,sqlalchemy]>=5.0.3->merlin) (2.0.0)\n",
            "Requirement already satisfied: jsonschema>=3.2.0 in /usr/local/lib/python3.8/dist-packages (from maestrowf>=1.1.9dev1->merlin) (4.3.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from maestrowf>=1.1.9dev1->merlin) (3.9.0)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.8/dist-packages (from maestrowf>=1.1.9dev1->merlin) (0.3.6)\n",
            "Collecting rich\n",
            "  Downloading rich-13.3.1-py3-none-any.whl (239 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m239.0/239.0 KB\u001b[0m \u001b[31m26.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.8/dist-packages (from maestrowf>=1.1.9dev1->merlin) (1.15.0)\n",
            "Requirement already satisfied: async-timeout>=4.0.2 in /usr/local/lib/python3.8/dist-packages (from redis>=4.3.4->merlin) (4.0.2)\n",
            "Collecting humanfriendly>=9.1\n",
            "  Downloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 KB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.8/dist-packages (from cryptography->merlin) (1.15.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.8/dist-packages (from cffi>=1.12->cryptography->merlin) (2.21)\n",
            "Requirement already satisfied: prompt-toolkit in /usr/local/lib/python3.8/dist-packages (from click-repl>=0.2.0->celery[redis,sqlalchemy]>=5.0.3->merlin) (2.0.10)\n",
            "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /usr/local/lib/python3.8/dist-packages (from jsonschema>=3.2.0->maestrowf>=1.1.9dev1->merlin) (0.19.3)\n",
            "Requirement already satisfied: importlib-resources>=1.4.0 in /usr/local/lib/python3.8/dist-packages (from jsonschema>=3.2.0->maestrowf>=1.1.9dev1->merlin) (5.10.2)\n",
            "Requirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.8/dist-packages (from jsonschema>=3.2.0->maestrowf>=1.1.9dev1->merlin) (22.2.0)\n",
            "Collecting amqp<6.0.0,>=5.0.9\n",
            "  Downloading amqp-5.1.1-py3-none-any.whl (50 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.8/50.8 KB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pygments<3.0.0,>=2.14.0\n",
            "  Downloading Pygments-2.14.0-py3-none-any.whl (1.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m39.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting markdown-it-py<3.0.0,>=2.1.0\n",
            "  Downloading markdown_it_py-2.1.0-py3-none-any.whl (84 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.5/84.5 KB\u001b[0m \u001b[31m11.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: typing-extensions<5.0,>=4.0.0 in /usr/local/lib/python3.8/dist-packages (from rich->maestrowf>=1.1.9dev1->merlin) (4.4.0)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.8/dist-packages (from sqlalchemy->celery[redis,sqlalchemy]>=5.0.3->merlin) (2.0.2)\n",
            "Requirement already satisfied: zipp>=3.1.0 in /usr/local/lib/python3.8/dist-packages (from importlib-resources>=1.4.0->jsonschema>=3.2.0->maestrowf>=1.1.9dev1->merlin) (3.12.0)\n",
            "Collecting mdurl~=0.1\n",
            "  Downloading mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.8/dist-packages (from prompt-toolkit->click-repl>=0.2.0->celery[redis,sqlalchemy]>=5.0.3->merlin) (0.2.6)\n",
            "Building wheels for collected packages: parse\n",
            "  Building wheel for parse (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for parse: filename=parse-1.19.0-py3-none-any.whl size=24591 sha256=5a6ae98f6ff6e439d4ccb7d9b5bd376a09a7218d0020d723a9ee900bd0c74c66\n",
            "  Stored in directory: /root/.cache/pip/wheels/e5/33/1f/68392720485b3ecf125a69e700baaab7624616deedea2fa6e2\n",
            "Successfully built parse\n",
            "Installing collected packages: parse, cached-property, billiard, vine, redis, pygments, mdurl, humanfriendly, click, markdown-it-py, cryptography, coloredlogs, click-repl, click-plugins, click-didyoumean, amqp, rich, kombu, maestrowf, celery, merlin\n",
            "  Attempting uninstall: pygments\n",
            "    Found existing installation: Pygments 2.6.1\n",
            "    Uninstalling Pygments-2.6.1:\n",
            "      Successfully uninstalled Pygments-2.6.1\n",
            "  Attempting uninstall: click\n",
            "    Found existing installation: click 7.1.2\n",
            "    Uninstalling click-7.1.2:\n",
            "      Successfully uninstalled click-7.1.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "ipython 7.9.0 requires jedi>=0.10, which is not installed.\n",
            "flask 1.1.4 requires click<8.0,>=5.1, but you have click 8.1.3 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed amqp-5.1.1 billiard-3.6.4.0 cached-property-1.5.2 celery-5.2.7 click-8.1.3 click-didyoumean-0.3.0 click-plugins-1.1.1 click-repl-0.2.0 coloredlogs-15.0.1 cryptography-39.0.0 humanfriendly-10.0 kombu-5.2.4 maestrowf-1.1.9 markdown-it-py-2.1.0 mdurl-0.1.2 merlin-1.9.1 parse-1.19.0 pygments-2.14.0 redis-4.4.2 rich-13.3.1 vine-5.0.0\n"
          ]
        }
      ],
      "source": [
        "!pip install nvtabular\n",
        "!pip install merlin"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "-ESoORVlTuSK"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import time\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "import nvtabular as nvt\n",
        "from nvtabular.loader.torch import TorchAsyncItr, DLDataLoader\n",
        "from merlin.schema.tags import Tags"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "dZjmyoHyTtSG"
      },
      "outputs": [],
      "source": [
        "MOVIE_PATH = \"/content/drive/MyDrive/Colab Notebooks/Personal/MediaRec/ml-25m\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L1WYpZxYXdJe"
      },
      "source": [
        "# Preprocessing\n",
        "Skip to Data Loading if transformed datasets are already saved."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 350
        },
        "id": "kI_CLIOqkhr5",
        "outputId": "b0782cf4-b877-4149-da27-21e3e3223c0b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Unnamed: 0  Unnamed: 0.1  movieId                               title  \\\n",
              "0           0             0        1                    Toy Story (1995)   \n",
              "1           1             1        2                      Jumanji (1995)   \n",
              "2           2             2        3             Grumpier Old Men (1995)   \n",
              "3           3             3        4            Waiting to Exhale (1995)   \n",
              "4           4             4        5  Father of the Bride Part II (1995)   \n",
              "\n",
              "                                        genres  \\\n",
              "0  Adventure|Animation|Children|Comedy|Fantasy   \n",
              "1                   Adventure|Children|Fantasy   \n",
              "2                               Comedy|Romance   \n",
              "3                         Comedy|Drama|Romance   \n",
              "4                                       Comedy   \n",
              "\n",
              "                                        split_genres  \\\n",
              "0  ['Adventure', 'Animation', 'Children', 'Comedy...   \n",
              "1               ['Adventure', 'Children', 'Fantasy']   \n",
              "2                              ['Comedy', 'Romance']   \n",
              "3                     ['Comedy', 'Drama', 'Romance']   \n",
              "4                                         ['Comedy']   \n",
              "\n",
              "                                           lm_genres  num_ratings  avg_rating  \n",
              "0  [-7.62170404e-02 -7.34341815e-02  3.21774840e-...      57309.0    3.893708  \n",
              "1  [-2.23115534e-01 -3.53449345e-01  1.68107659e-...      24228.0    3.251527  \n",
              "2  [-1.22938655e-01 -1.07958302e-01  2.52478123e-...      11804.0    3.142028  \n",
              "3  [ 2.22296063e-02 -2.31470495e-01  2.30256513e-...       2523.0    2.853547  \n",
              "4  [-1.98312491e-01 -2.89419562e-01  2.86418885e-...      11714.0    3.058434  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-dd2620e0-7268-46b6-b16c-1f4984a8151c\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>Unnamed: 0.1</th>\n",
              "      <th>movieId</th>\n",
              "      <th>title</th>\n",
              "      <th>genres</th>\n",
              "      <th>split_genres</th>\n",
              "      <th>lm_genres</th>\n",
              "      <th>num_ratings</th>\n",
              "      <th>avg_rating</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>Toy Story (1995)</td>\n",
              "      <td>Adventure|Animation|Children|Comedy|Fantasy</td>\n",
              "      <td>['Adventure', 'Animation', 'Children', 'Comedy...</td>\n",
              "      <td>[-7.62170404e-02 -7.34341815e-02  3.21774840e-...</td>\n",
              "      <td>57309.0</td>\n",
              "      <td>3.893708</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>Jumanji (1995)</td>\n",
              "      <td>Adventure|Children|Fantasy</td>\n",
              "      <td>['Adventure', 'Children', 'Fantasy']</td>\n",
              "      <td>[-2.23115534e-01 -3.53449345e-01  1.68107659e-...</td>\n",
              "      <td>24228.0</td>\n",
              "      <td>3.251527</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>Grumpier Old Men (1995)</td>\n",
              "      <td>Comedy|Romance</td>\n",
              "      <td>['Comedy', 'Romance']</td>\n",
              "      <td>[-1.22938655e-01 -1.07958302e-01  2.52478123e-...</td>\n",
              "      <td>11804.0</td>\n",
              "      <td>3.142028</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>Waiting to Exhale (1995)</td>\n",
              "      <td>Comedy|Drama|Romance</td>\n",
              "      <td>['Comedy', 'Drama', 'Romance']</td>\n",
              "      <td>[ 2.22296063e-02 -2.31470495e-01  2.30256513e-...</td>\n",
              "      <td>2523.0</td>\n",
              "      <td>2.853547</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>5</td>\n",
              "      <td>Father of the Bride Part II (1995)</td>\n",
              "      <td>Comedy</td>\n",
              "      <td>['Comedy']</td>\n",
              "      <td>[-1.98312491e-01 -2.89419562e-01  2.86418885e-...</td>\n",
              "      <td>11714.0</td>\n",
              "      <td>3.058434</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-dd2620e0-7268-46b6-b16c-1f4984a8151c')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-dd2620e0-7268-46b6-b16c-1f4984a8151c button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-dd2620e0-7268-46b6-b16c-1f4984a8151c');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ],
      "source": [
        "df_movies = pd.read_csv(os.path.join(MOVIE_PATH, 'movie_features.csv'))\n",
        "df_movies.head(n=5)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_ratings_df(popular_workflow:bool = True, movie_popular_workflow:bool = False) -> pd.DataFrame:\n",
        "    '''\n",
        "\n",
        "    TODO: Needs to be updated later on but want a bias toward more popular media to start.\n",
        "\n",
        "    Args:\n",
        "      popular_workflow: Remove users with < 50 ratings and movies with < 15 ratings\n",
        "      movie_popular_workflow: Remove movies with < 5 ratings. Only applied if popular_workflow=False.\n",
        "    '''\n",
        "\n",
        "    df_ratings = pd.read_csv(os.path.join(MOVIE_PATH, 'ratings.csv'))\n",
        "    df_ratings = df_ratings.drop(columns=['timestamp'])\n",
        "\n",
        "    if popular_workflow:\n",
        "        unique_usercount = df_ratings.groupby('userId')['movieId'].nunique()\n",
        "        unique_moviecount = df_ratings.groupby('movieId')['userId'].nunique()\n",
        "        print('Number of users with 50 ratings or more: {} / {}'.format(\n",
        "            len(unique_usercount[unique_usercount >= 50]), len(np.unique(df_ratings['userId'])))\n",
        "        )\n",
        "        print('Number of movies with 15 ratings or more: {} / {}'.format(\n",
        "            np.sum(unique_moviecount >= 15), np.sum(unique_moviecount > 0))\n",
        "        )\n",
        "        df_ratings = df_ratings[df_ratings['userId'].isin(list(unique_usercount[unique_usercount >= 50].index))]\n",
        "        df_ratings = df_ratings[df_ratings['movieId'].isin(list(unique_moviecount[unique_moviecount >= 15].index))]\n",
        "\n",
        "    elif movie_popular_workflow:\n",
        "        unique_moviecount = df_ratings.groupby('movieId')['userId'].nunique()\n",
        "        print('Number of movies with 5 ratings or more: {} / {}'.format(\n",
        "            np.sum(unique_moviecount >= 5), np.sum(unique_moviecount > 0))\n",
        "        )\n",
        "        df_ratings = df_ratings[df_ratings['movieId'].isin(list(unique_moviecount[unique_moviecount >= 5].index))]\n",
        "\n",
        "    return df_ratings"
      ],
      "metadata": {
        "id": "zR46qYK6V8Og"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u1ZuSZ2hyEws",
        "outputId": "536e67ce-7b30-43c0-8197-62d6cd5070bf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "102492 162541\n",
            "20590 59047\n"
          ]
        }
      ],
      "source": [
        "df_ratings = get_ratings_df()\n",
        "df_ratings.head(n=5)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Look at the raw distribution of user ratings\n",
        "np.histogram(df_ratings.groupby('userId')['movieId'].nunique(), bins=20)"
      ],
      "metadata": {
        "id": "2yGX_fN7ropL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c22524ca-fef2-4328-e209-3709dd851ae6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([161824,    614,     84,     11,      5,      2,      0,      0,\n",
              "             0,      0,      0,      0,      0,      0,      0,      0,\n",
              "             0,      0,      0,      1]),\n",
              " array([2.00000e+01, 1.62910e+03, 3.23820e+03, 4.84730e+03, 6.45640e+03,\n",
              "        8.06550e+03, 9.67460e+03, 1.12837e+04, 1.28928e+04, 1.45019e+04,\n",
              "        1.61110e+04, 1.77201e+04, 1.93292e+04, 2.09383e+04, 2.25474e+04,\n",
              "        2.41565e+04, 2.57656e+04, 2.73747e+04, 2.89838e+04, 3.05929e+04,\n",
              "        3.22020e+04]))"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Look at the raw distribution of movie ratings\n",
        "np.histogram(df_ratings.groupby('movieId')['userId'].nunique(), bins=20)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S1axrD2P57Di",
        "outputId": "a32bdf2a-23a5-4a54-9d81-14c950ff6ba1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([31254,   712,   312,   163,    84,    57,    39,    26,    19,\n",
              "           14,    10,     5,     7,     5,     6,     1,     1,     1,\n",
              "            1,     3]),\n",
              " array([5.00000e+00, 4.07930e+03, 8.15360e+03, 1.22279e+04, 1.63022e+04,\n",
              "        2.03765e+04, 2.44508e+04, 2.85251e+04, 3.25994e+04, 3.66737e+04,\n",
              "        4.07480e+04, 4.48223e+04, 4.88966e+04, 5.29709e+04, 5.70452e+04,\n",
              "        6.11195e+04, 6.51938e+04, 6.92681e+04, 7.33424e+04, 7.74167e+04,\n",
              "        8.14910e+04]))"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_DuVaH-NYBHC"
      },
      "outputs": [],
      "source": [
        "# Split into train/val/test \n",
        "\n",
        "# In val/test we want clean (untrained on) users and unclean (trained on but not those ratings) users \n",
        "# unclean percentages are out of ratings\n",
        "# clean percentages are out of users\n",
        "p_test_unclean, p_test_clean = 0.075, 0.025\n",
        "p_val_unclean, p_val_clean = 0.075, 0.025\n",
        "\n",
        "# Grab clean users for val/test\n",
        "users = np.unique(df_ratings['userId'])\n",
        "users_clean_val = users[-int(len(users)*p_val_clean):]\n",
        "users_clean_test = users[-int(len(users)*(p_test_clean+p_val_clean)):-int(len(users)*p_val_clean)]\n",
        "users_unclean = users[:-int(len(users)*(p_test_clean+p_val_clean))]\n",
        "\n",
        "df_clean_val = df_ratings[df_ratings['userId'].isin(users_clean_val)]\n",
        "df_clean_test = df_ratings[df_ratings['userId'].isin(users_clean_test)]\n",
        "unclean = df_ratings[df_ratings['userId'].isin(users_unclean)]\n",
        "\n",
        "# Grab unclean users\n",
        "unclean_rating_idxs = np.random.permutation(len(unclean))\n",
        "unclean_rating_idxs_train = unclean_rating_idxs[:-int((p_test_unclean+p_val_unclean)*len(unclean_rating_idxs))]\n",
        "unclean_rating_idxs_val = unclean_rating_idxs[-int(p_val_unclean*len(unclean_rating_idxs)):]\n",
        "unclean_rating_idxs_test = unclean_rating_idxs[-int((p_test_unclean+p_val_unclean)*len(unclean_rating_idxs)): \n",
        "                                               -int(p_val_unclean*len(unclean_rating_idxs))]\n",
        "\n",
        "df_train = unclean.iloc[unclean_rating_idxs_train]\n",
        "df_val = unclean.iloc[unclean_rating_idxs_val]\n",
        "df_test = unclean.iloc[unclean_rating_idxs_test]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FzFOz3Zuhoz1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6fc75517-c42f-4b8b-8fee-775c8517cbb8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "154414 4063 4064\n",
            "610426 616912\n",
            "20206844 1782956 1782957\n",
            "20206844 1782956 1782957\n"
          ]
        }
      ],
      "source": [
        "# Check clean users\n",
        "print(len(users_unclean), len(users_clean_val), len(users_clean_test))\n",
        "assert np.sum(np.in1d(users_unclean, users_clean_val)) == 0\n",
        "assert np.sum(np.in1d(users_unclean, users_clean_test)) == 0\n",
        "print(len(df_clean_val), len(df_clean_test))\n",
        "\n",
        "# Check unclean\n",
        "print(len(unclean_rating_idxs_train), len(unclean_rating_idxs_val), len(unclean_rating_idxs_test))\n",
        "assert np.sum(np.in1d(unclean_rating_idxs_train, unclean_rating_idxs_val)) == 0\n",
        "assert np.sum(np.in1d(unclean_rating_idxs_train, unclean_rating_idxs_test)) == 0\n",
        "\n",
        "# Check unclean users\n",
        "print(len(df_train), len(df_val), len(df_test))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_workflow(load_path:str = None) -> nvt.Workflow:\n",
        "    ''' Loads the Workflow or creates a new one if load_path is None.'''\n",
        "    if load_path:\n",
        "        workflow = nvt.Workflow.load(load_path)\n",
        "\n",
        "    else:\n",
        "        # Categorify id's to ensure continuous inputs\n",
        "        output = ['userId', 'movieId'] >> nvt.ops.Categorify()\n",
        "        output += nvt.ColumnGroup([\"rating\"]) >> nvt.ops.NormalizeMinMax()\n",
        "        workflow = nvt.Workflow(output)\n",
        "\n",
        "    return workflow"
      ],
      "metadata": {
        "id": "KJZhjUVvY0GS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ec7KJoZIHOzf"
      },
      "outputs": [],
      "source": [
        "!unzip movie_workflow_popular.zip\n",
        "workflow_path = 'movie_workflow_popular'\n",
        "workflow = get_workflow(workflow_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 162
        },
        "id": "SB3Xe2hsk-xW",
        "outputId": "e46a8f79-28f5-4123-9f0d-35226fa91b41"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>name</th>\n",
              "      <th>tags</th>\n",
              "      <th>dtype</th>\n",
              "      <th>is_list</th>\n",
              "      <th>is_ragged</th>\n",
              "      <th>properties.num_buckets</th>\n",
              "      <th>properties.freq_threshold</th>\n",
              "      <th>properties.max_size</th>\n",
              "      <th>properties.start_index</th>\n",
              "      <th>properties.cat_path</th>\n",
              "      <th>properties.domain.min</th>\n",
              "      <th>properties.domain.max</th>\n",
              "      <th>properties.domain.name</th>\n",
              "      <th>properties.embedding_sizes.cardinality</th>\n",
              "      <th>properties.embedding_sizes.dimension</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>userId</td>\n",
              "      <td>(Tags.CATEGORICAL)</td>\n",
              "      <td>int64</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>.//categories/unique.userId.parquet</td>\n",
              "      <td>0.0</td>\n",
              "      <td>160916.0</td>\n",
              "      <td>userId</td>\n",
              "      <td>160917.0</td>\n",
              "      <td>512.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>movieId</td>\n",
              "      <td>(Tags.CATEGORICAL)</td>\n",
              "      <td>int64</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>.//categories/unique.movieId.parquet</td>\n",
              "      <td>0.0</td>\n",
              "      <td>57249.0</td>\n",
              "      <td>movieId</td>\n",
              "      <td>57250.0</td>\n",
              "      <td>512.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>rating</td>\n",
              "      <td>(Tags.CONTINUOUS)</td>\n",
              "      <td>float64</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "[{'name': 'userId', 'tags': {<Tags.CATEGORICAL: 'categorical'>}, 'properties': {'num_buckets': None, 'freq_threshold': 0, 'max_size': 0, 'start_index': 0, 'cat_path': './/categories/unique.userId.parquet', 'domain': {'min': 0, 'max': 160916, 'name': 'userId'}, 'embedding_sizes': {'cardinality': 160917, 'dimension': 512}}, 'dtype': dtype('int64'), 'is_list': False, 'is_ragged': False}, {'name': 'movieId', 'tags': {<Tags.CATEGORICAL: 'categorical'>}, 'properties': {'num_buckets': None, 'freq_threshold': 0, 'max_size': 0, 'start_index': 0, 'cat_path': './/categories/unique.movieId.parquet', 'domain': {'min': 0, 'max': 57249, 'name': 'movieId'}, 'embedding_sizes': {'cardinality': 57250, 'dimension': 512}}, 'dtype': dtype('int64'), 'is_list': False, 'is_ragged': False}, {'name': 'rating', 'tags': {<Tags.CONTINUOUS: 'continuous'>}, 'properties': {}, 'dtype': dtype('float64'), 'is_list': False, 'is_ragged': False}]"
            ]
          },
          "execution_count": 35,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "workflow.output_schema"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vYUOllnQctEQ"
      },
      "outputs": [],
      "source": [
        "# Save and zip workflow\n",
        "workflow.save('movie_workflow_popular')\n",
        "!zip -r movie_workflow_popular movie_workflow_popular"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kaq5Lk8WceMn"
      },
      "source": [
        "\n",
        "# Data Loading\n",
        "Start from here if transformed datasets are already saved."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def partition_fit_and_transform():\n",
        "    # Train file is too large so we partition into 10 datasets to fit\n",
        "    for i in range(10):\n",
        "        if i < 9:\n",
        "            ds = nvt.Dataset(df_train.iloc[i*(len(df_train)//10):(i+1)*(len(df_train)//10)])\n",
        "        else:\n",
        "            ds = nvt.Dataset(df_train.iloc[i*(len(df_train)//10):])\n",
        "        workflow.fit(ds)\n",
        "    \n",
        "    # Train file is too large so we partition into 10 datasets to transform\n",
        "    for i in range(10):\n",
        "        if i < 9:\n",
        "            ds = nvt.Dataset(df_train.iloc[i*(len(df_train)//10):(i+1)*(len(df_train)//10)])\n",
        "        else:\n",
        "            ds = nvt.Dataset(df_train.iloc[i*(len(df_train)//10):])\n",
        "        workflow.transform(ds).to_parquet('train_{}'.format(i))\n",
        "\n",
        "    # Transform val/test\n",
        "    workflow.transform(nvt.Dataset(df_val)).to_parquet('val')\n",
        "    workflow.transform(nvt.Dataset(df_test)).to_parquet('test')"
      ],
      "metadata": {
        "id": "AcA7KHzb1kI3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eqgDcSBzR5UN"
      },
      "outputs": [],
      "source": [
        "# Load in our transformed datasets and convert to torch-ready\n",
        "def load_dls(batch_size):\n",
        "    train_dls = []\n",
        "    for i in range(10):\n",
        "        train_torch = TorchAsyncItr(\n",
        "            nvt.Dataset('train_{}'.format(i), engine='parquet'),\n",
        "            batch_size=batch_size,\n",
        "            cats=['userId', 'movieId', 'split_genres'],\n",
        "            conts=[\"rating\", 'avg_rating', 'num_ratings'], \n",
        "        )\n",
        "        train_dl = DLDataLoader(\n",
        "            train_torch, batch_size=None, pin_memory=False, num_workers=0\n",
        "        )\n",
        "        train_dls.append(train_dl)\n",
        "\n",
        "\n",
        "    val_torch = TorchAsyncItr(\n",
        "        nvt.Dataset('val', engine='parquet'),\n",
        "        batch_size=batch_size,\n",
        "        cats=['userId', 'movieId', 'split_genres'],\n",
        "        conts=[\"rating\", 'avg_rating', 'num_ratings'], \n",
        "    )\n",
        "    val_dl = DLDataLoader(\n",
        "        val_torch, batch_size=None, pin_memory=False, num_workers=0\n",
        "    )\n",
        "\n",
        "    test_torch = TorchAsyncItr(\n",
        "        nvt.Dataset('test', engine='parquet'),\n",
        "        batch_size=batch_size,\n",
        "        cats=['userId', 'movieId', 'split_genres'],\n",
        "        conts=[\"rating\", 'avg_rating', 'num_ratings'], \n",
        "    )\n",
        "    test_dl = DLDataLoader(\n",
        "        test_torch, batch_size=None, pin_memory=False, num_workers=0\n",
        "    )\n",
        "    return train_dls, val_dl, test_dl\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MU-kPD4rNY8p"
      },
      "source": [
        "# Models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RdT6F3KtfdI_"
      },
      "outputs": [],
      "source": [
        "class VanillaCF(nn.Module):\n",
        "    def __init__(self, emb_size, n_users=97369, n_media=20591):\n",
        "        super().__init__()\n",
        "        self.user_emb = nn.Embedding(n_users, emb_size)\n",
        "        self.media_emb = nn.Embedding(n_media, emb_size)\n",
        "\n",
        "    def forward(self, user, media):\n",
        "        return torch.sigmoid(self.user_emb(user) @ torch.transpose(self.media_emb(media), 1, 2))\n",
        "\n",
        "\n",
        "class MLP(nn.Module):\n",
        "    def __init__(self, emb_size, hidden_dim, n_users=154415, n_media=56961):\n",
        "        super().__init__()\n",
        "        self.user_emb = nn.Embedding(n_users, emb_size)\n",
        "        self.media_emb = nn.Embedding(n_media, emb_size)\n",
        "\n",
        "        self.mlp = nn.Sequential(nn.Linear(emb_size*2, hidden_dim),\n",
        "                                  nn.LayerNorm(hidden_dim),\n",
        "                                  nn.ReLU(inplace=True),\n",
        "                                  nn.Linear(hidden_dim, hidden_dim),\n",
        "                                  nn.LayerNorm(hidden_dim),\n",
        "                                  nn.ReLU(inplace=True),\n",
        "                                  nn.Linear(hidden_dim, hidden_dim),\n",
        "                                  nn.LayerNorm(hidden_dim),\n",
        "                                  nn.ReLU(inplace=True),\n",
        "                                  nn.Linear(hidden_dim, hidden_dim),\n",
        "                                  nn.LayerNorm(hidden_dim),\n",
        "                                  nn.Linear(hidden_dim, 1))\n",
        "\n",
        "    def forward(self, user, media):\n",
        "        x = torch.cat([self.user_emb(user).transpose(1, 2), self.media_emb(media).transpose(1, 2)], axis=1).squeeze()\n",
        "        return torch.sigmoid(self.mlp(x))\n",
        "        \n",
        "\n",
        "class CFMLP(nn.Module):\n",
        "    def __init__(self, emb_size, hidden_dim, n_users=154415, n_media=56961):\n",
        "        super().__init__()\n",
        "        self.user_emb = nn.Embedding(n_users, emb_size)\n",
        "        self.media_emb = nn.Embedding(n_media, emb_size)\n",
        "\n",
        "        self.mlp = nn.Sequential(nn.Linear(emb_size, hidden_dim),\n",
        "                                 nn.ReLU(inplace=True),\n",
        "                                 nn.Linear(hidden_dim, hidden_dim),\n",
        "                                 nn.LayerNorm(hidden_dim),\n",
        "                                 nn.Linear(hidden_dim, 1))\n",
        "\n",
        "    def forward(self, user, media):\n",
        "        x = self.user_emb(user) * self.media_emb(media)\n",
        "        return self.mlp(x)\n",
        "\n",
        "\n",
        "def get_params(no_decay=[]):\n",
        "  no_decay_params, decay_params = [], []\n",
        "  for name, param in model.named_parameters():\n",
        "\n",
        "    decay_param = True\n",
        "    for s in no_decay:\n",
        "      if s in name:\n",
        "        no_decay_params.append(param)\n",
        "        decay_param = False\n",
        "        break\n",
        "\n",
        "    if decay_param:\n",
        "      decay_params.append(param)\n",
        "\n",
        "  return [{'params': no_decay_params, 'weight_decay': 0}, {'params': decay_params}]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "98iQB43UekNk"
      },
      "source": [
        "# Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wmMD49j5qstz"
      },
      "outputs": [],
      "source": [
        "def train_model(train_dls, val_dl, test_dl, model, loss_fn, opt):\n",
        "    metrics = []\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        start = time.time()\n",
        "\n",
        "        mse, rmse = train(train_dls, model, loss_fn, opt, epoch+1)\n",
        "        val_mse, val_rmse = validate(val_dl, model, loss_fn, epoch+1)\n",
        "\n",
        "        metrics.append([mse, rmse, val_mse, val_rmse])\n",
        "        print('Epoch {}/{} - completed {}M - est. remaining {}H {}M \\n'.format(\n",
        "                                                            epoch+1, epochs, \n",
        "                                                            int((time.time()-start) // 60), \n",
        "                                                            int((time.time()-start) // 60 * (epochs - epoch-1) // 60),\n",
        "                                                            int((time.time()-start) // 60 * (epochs - epoch-1) % 60)\n",
        "                                                            ))\n",
        "    \n",
        "    return metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oUSn2QgielV9"
      },
      "outputs": [],
      "source": [
        "def train(train_dls, model, loss_fn, opt, epoch):\n",
        "    losses = []\n",
        "    n_examples = 0\n",
        "    model.cuda()\n",
        "    \n",
        "    model.train()\n",
        "\n",
        "    for i, train_dl in enumerate(train_dls):\n",
        "        for j, (x, _) in enumerate(train_dl):\n",
        "            user = x['userId'].to('cuda')\n",
        "            media = x['movieId'].to('cuda')\n",
        "            y = x['rating'].to('cuda')\n",
        "\n",
        "            pred = model(user, media)\n",
        "            pred = pred.squeeze()\n",
        "\n",
        "            loss = loss_fn(pred, y)\n",
        "            \n",
        "            opt.zero_grad()\n",
        "            loss.backward()\n",
        "            opt.step()\n",
        "\n",
        "            losses += [loss.detach()*len(y)]\n",
        "            n_examples += len(y)\n",
        "\n",
        "        if (i+1) % 5 == 0:\n",
        "            print('Train: Epoch {} - dl {}/{} - loss {:.3f} - rmse {:.3f}'.format(\n",
        "                                                                    epoch, i, len(train_dls),\n",
        "                                                                    torch.tensor(losses).sum()/n_examples, \n",
        "                                                                    (torch.tensor(losses).sum()/n_examples).sqrt()))\n",
        "\n",
        "    return torch.tensor(losses).sum()/n_examples, (torch.tensor(losses).sum()/n_examples).sqrt()\n",
        "\n",
        "\n",
        "def validate(val_dl, model, loss_fn, epoch):\n",
        "    losses = []\n",
        "    n_examples = 0\n",
        "    model.cuda()\n",
        "    model.eval()\n",
        "\n",
        "    for i, (x, _) in enumerate(val_dl):\n",
        "        user = x['userId'].to('cuda')\n",
        "        media = x['movieId'].to('cuda')\n",
        "        y = x['rating'].to('cuda')\n",
        "\n",
        "        with torch.no_grad():\n",
        "            pred = model(user, media)\n",
        "            pred = pred.squeeze()\n",
        "\n",
        "            loss = loss_fn(pred, y)\n",
        "\n",
        "        losses += [loss*len(y)]\n",
        "        n_examples += len(y)\n",
        "\n",
        "    print('Eval: Epoch {} - loss {:.3f} - rmse {:.3f}'.format(\n",
        "                                                      epoch,\n",
        "                                                      torch.tensor(losses).sum()/n_examples, \n",
        "                                                      (torch.tensor(losses).sum()/n_examples).sqrt()))\n",
        "\n",
        "    return torch.tensor(losses).sum()/n_examples, (torch.tensor(losses).sum()/n_examples).sqrt()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ya8ZmnaNs1D3"
      },
      "outputs": [],
      "source": [
        "def plot(train, val, metric='loss'):        \n",
        "    epochs = range(1, len(train) + 1)\n",
        "\n",
        "    plt.plot(epochs, train, 'k', label='Train ' + metric)\n",
        "    plt.plot(epochs, train, 'b', label='Validation ' + metric)\n",
        "    plt.title('Training and Validation Loss')\n",
        "    plt.legend()\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JSyZPgwI6UXM"
      },
      "source": [
        "## Vanilla Collaborative Filtering"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uwpcHKJVe48a"
      },
      "outputs": [],
      "source": [
        "emb_size = 512\n",
        "model = VanillaCF(emb_size)\n",
        "batch_size = 8192\n",
        "train_dls, val_dl, test_dl = load_dls(batch_size)\n",
        "\n",
        "loss_fn = nn.MSELoss()\n",
        "lr = 1e-3\n",
        "decay = 5e-5\n",
        "opt = torch.optim.Adam(model.parameters(), lr, weight_decay=decay)\n",
        "\n",
        "epochs = 5\n",
        "train_model(train_dls, val_dl, test_dl, model, loss_fn, opt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uUWAjnUEqm8i",
        "outputId": "f1213a6d-047c-449a-e2d2-23de0426a5f5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/merlin/io/dataset.py:253: UserWarning: Initializing an NVTabular Dataset in CPU mode.This is an experimental feature with extremely limited support!\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train: Epoch 1 - dl 4/10 - loss 0.118 - rmse 0.344\n",
            "Train: Epoch 1 - dl 9/10 - loss 0.082 - rmse 0.286\n",
            "Eval: Epoch 1 - loss 0.041 - rmse 0.204\n",
            "Epoch 1/5 - completed 0M - est. remaining 0H 0M \n",
            "\n",
            "Train: Epoch 2 - dl 4/10 - loss 0.039 - rmse 0.197\n",
            "Train: Epoch 2 - dl 9/10 - loss 0.038 - rmse 0.195\n",
            "Eval: Epoch 2 - loss 0.038 - rmse 0.194\n",
            "Epoch 2/5 - completed 0M - est. remaining 0H 0M \n",
            "\n",
            "Train: Epoch 3 - dl 4/10 - loss 0.036 - rmse 0.189\n",
            "Train: Epoch 3 - dl 9/10 - loss 0.035 - rmse 0.187\n",
            "Eval: Epoch 3 - loss 0.036 - rmse 0.190\n",
            "Epoch 3/5 - completed 0M - est. remaining 0H 0M \n",
            "\n",
            "Train: Epoch 4 - dl 4/10 - loss 0.033 - rmse 0.183\n",
            "Train: Epoch 4 - dl 9/10 - loss 0.033 - rmse 0.182\n",
            "Eval: Epoch 4 - loss 0.035 - rmse 0.188\n",
            "Epoch 4/5 - completed 0M - est. remaining 0H 0M \n",
            "\n",
            "Train: Epoch 5 - dl 4/10 - loss 0.032 - rmse 0.179\n",
            "Train: Epoch 5 - dl 9/10 - loss 0.032 - rmse 0.178\n",
            "Eval: Epoch 5 - loss 0.035 - rmse 0.186\n",
            "Epoch 5/5 - completed 0M - est. remaining 0H 0M \n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[tensor(0.0816), tensor(0.2857), tensor(0.0415), tensor(0.2037)],\n",
              " [tensor(0.0379), tensor(0.1948), tensor(0.0375), tensor(0.1937)],\n",
              " [tensor(0.0351), tensor(0.1873), tensor(0.0362), tensor(0.1903)],\n",
              " [tensor(0.0331), tensor(0.1819), tensor(0.0352), tensor(0.1877)],\n",
              " [tensor(0.0316), tensor(0.1778), tensor(0.0347), tensor(0.1862)]]"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "# Normalize + sigmoid\n",
        "emb_size = 12\n",
        "model = VanillaCF(emb_size)\n",
        "batch_size = 8192\n",
        "train_dls, val_dl, test_dl = load_dls(batch_size)\n",
        "\n",
        "loss_fn = nn.MSELoss()\n",
        "lr = 1e-2\n",
        "decay = 0\n",
        "opt = torch.optim.Adam(model.parameters(), lr, weight_decay=decay)\n",
        "\n",
        "epochs = 5\n",
        "train_model(train_dls, val_dl, test_dl, model, loss_fn, opt)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Vanilla CF Test"
      ],
      "metadata": {
        "id": "L0tnnUtttaE4"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mdhrhClu6fnX",
        "outputId": "be24e182-739f-4da3-8f09-65ff327bf453"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(0, device='cuda:0')\n",
            "tensor(0, device='cuda:0')\n",
            "tensor(0, device='cuda:0')\n",
            "tensor(0, device='cuda:0')\n",
            "tensor(0, device='cuda:0')\n",
            "tensor(0, device='cuda:0')\n",
            "tensor(0, device='cuda:0')\n",
            "tensor(0, device='cuda:0')\n",
            "tensor(0, device='cuda:0')\n",
            "tensor(0, device='cuda:0')\n",
            "tensor(0, device='cuda:0')\n",
            "tensor(0, device='cuda:0')\n",
            "tensor(0, device='cuda:0')\n",
            "tensor(0, device='cuda:0')\n",
            "tensor(0, device='cuda:0')\n",
            "tensor(0, device='cuda:0')\n",
            "tensor(0, device='cuda:0')\n",
            "tensor(0, device='cuda:0')\n",
            "tensor(0, device='cuda:0')\n",
            "tensor(0, device='cuda:0')\n",
            "tensor(0, device='cuda:0')\n",
            "tensor(0, device='cuda:0')\n",
            "tensor(0, device='cuda:0')\n",
            "tensor(0, device='cuda:0')\n",
            "tensor(0, device='cuda:0')\n",
            "tensor(0, device='cuda:0')\n",
            "tensor(0, device='cuda:0')\n",
            "tensor(0, device='cuda:0')\n",
            "tensor(0, device='cuda:0')\n",
            "tensor(0, device='cuda:0')\n",
            "tensor(0, device='cuda:0')\n",
            "tensor(0, device='cuda:0')\n",
            "Eval: Epoch -1 - loss 0.159 - rmse 0.399\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor(0.1590), tensor(0.3988))"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ],
      "source": [
        "# Extract user (not necessary but it works)\n",
        "# model = VanillaCF(emb_size=12)\n",
        "# model.load_state_dict(torch.load('CF-test.pt'))\n",
        "model = torch.jit.load('cf_12emb_1e-2lradam_0d_5e_prodavg-0--01_23_25.pt')\n",
        "# user_emb = extract_prod_user_emb(model.user_emb.weight.detach(), 0, 0)[1:]\n",
        "# test_model = ProdVanillaCF(user_emb, model.media_emb.weight.detach())\n",
        "loss_fn = nn.MSELoss()\n",
        "validate(dl, model, loss_fn, -1)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Gather top predictions for the model - use with same user\n",
        "\n",
        "preds = []\n",
        "\n",
        "model.cuda()\n",
        "model.eval()\n",
        "for i, (x, _) in enumerate(dl):\n",
        "    user = x['userId'].to('cuda')\n",
        "    media = x['movieId'].to('cuda')\n",
        "    y = x['rating'].to('cuda')\n",
        "\n",
        "    with torch.no_grad():\n",
        "        pred = model(user, media)\n",
        "        pred = pred.squeeze().cpu()\n",
        "        preds.extend(pred)\n",
        "\n",
        "print(sorted(zip(preds, movie_ids), key=lambda x: x[0], reverse=True)[:2])\n",
        "\n",
        "sorted_preds = sorted(zip(preds, movie_ids), key=lambda x: x[0], reverse=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a5mirMV0hTgi",
        "outputId": "fa91ac38-45f3-43f2-d1f4-3cac38729d50"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[(tensor(0.9639), 193972), (tensor(0.9548), 191219)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bjk3yM1r9xgN"
      },
      "source": [
        "### Vanilla CF Default Embedding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z8Wo4kKZHHxs"
      },
      "outputs": [],
      "source": [
        "model = torch.jit.load('cf_12emb_1e-2lradam_0d_5e--01_23_23.pt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AOEFN47lANWO"
      },
      "outputs": [],
      "source": [
        "def get_test_clean_dl(batch_size):\n",
        "    workflow.transform(nvt.Dataset(df_clean_test)).to_parquet('test_clean')\n",
        "\n",
        "    test_clean_torch = TorchAsyncItr(\n",
        "        nvt.Dataset('test_clean', engine='parquet'),\n",
        "        batch_size=batch_size,\n",
        "        cats=['userId', 'movieId'],\n",
        "        conts=[\"rating\"], \n",
        "    )\n",
        "    test_clean_dl = DLDataLoader(\n",
        "        test_clean_torch, batch_size=None, pin_memory=False, num_workers=0\n",
        "    )\n",
        "    return test_clean_dl"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8IZ9QEbx94fI",
        "outputId": "09818bfd-99ab-4d3c-9be3-47a59d35f642"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/merlin/io/dataset.py:253: UserWarning: Initializing an NVTabular Dataset in CPU mode.This is an experimental feature with extremely limited support!\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Eval: Epoch -1 - loss 0.061 - rmse 0.246\n",
            "tensor([[ 0.6119, -0.2610,  0.0553,  0.0755,  0.2839,  0.3865, -0.4928, -0.3124,\n",
            "         -0.5280, -0.4311,  0.7406, -0.8080]], grad_fn=<MeanBackward1>)\n"
          ]
        }
      ],
      "source": [
        "batch_size = 8192\n",
        "# Clean DL will return 0 for all users not in train set, used for default embedding indexing\n",
        "test_clean_dl = get_test_clean_dl(batch_size)\n",
        "\n",
        "# Create a model with the default embedding\n",
        "default_user_emb = extract_prod_user_emb(model.user_emb.weight, None)\n",
        "test_model = ProdVanillaCF(default_user_emb, model.media_emb.weight)\n",
        "loss_fn = nn.MSELoss()\n",
        "\n",
        "validate(test_clean_dl, test_model, loss_fn, -1)\n",
        "print(default_user_emb)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9XYZ2rTPB5jE",
        "outputId": "46f93062-3aa2-402e-f0f5-cc8a6292bdd5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Eval: Epoch -1 - loss 0.143 - rmse 0.378\n",
            "Eval: Epoch -1 - loss 0.104 - rmse 0.322\n",
            "Eval: Epoch -1 - loss 0.101 - rmse 0.317\n",
            "Eval: Epoch -1 - loss 0.100 - rmse 0.316\n",
            "Eval: Epoch -1 - loss 0.089 - rmse 0.298\n",
            "tensor([[0.7563, 0.5770, 0.6027, 0.8225, 0.2251, 0.4534, 0.1591, 0.7922, 0.6104,\n",
            "         0.8541, 0.9666, 0.1963]])\n"
          ]
        }
      ],
      "source": [
        "# Compare against random embedding\n",
        "for _ in range(5):\n",
        "  rand_user_emb = torch.rand(default_user_emb.shape)\n",
        "  test_model = ProdVanillaCF(rand_user_emb, model.media_emb.weight)\n",
        "  loss_fn = nn.MSELoss()\n",
        "\n",
        "  validate(test_clean_dl, test_model, loss_fn, -1)\n",
        "\n",
        "print(rand_user_emb)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0rMmZKqWCOPD",
        "outputId": "13d5b568-2b92-4930-b15b-e175e164fb0e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Eval: Epoch -1 - loss 0.131 - rmse 0.362\n",
            "tensor([[ 0.1073,  0.1002, -0.7492, -1.2399, -0.7762,  0.8408,  0.1552,  1.1782,\n",
            "          0.2896,  0.3582, -0.7630, -0.1411]], grad_fn=<SliceBackward0>)\n"
          ]
        }
      ],
      "source": [
        "# Compare against train user with most ratings\n",
        "rand_user_emb = extract_prod_user_emb(model.user_emb.weight, 0, 0)[1:]\n",
        "test_model = ProdVanillaCF(rand_user_emb, model.media_emb.weight)\n",
        "loss_fn = nn.MSELoss()\n",
        "\n",
        "validate(test_clean_dl, test_model, loss_fn, -1)\n",
        "print(rand_user_emb)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5oafQfAkDg-u",
        "outputId": "8e6a229f-8e7d-4dda-b422-d5efaa244ad4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Eval: Epoch -1 - loss 0.090 - rmse 0.299\n",
            "tensor([[ 0.3702, -0.4307,  0.8475,  0.8027,  1.0449,  0.9877, -2.0126,  0.1729,\n",
            "         -2.8120, -0.2979, -0.6038, -0.9882]], grad_fn=<SliceBackward0>)\n"
          ]
        }
      ],
      "source": [
        "# Compare against train user with least number of ratings\n",
        "rand_user_emb = extract_prod_user_emb(model.user_emb.weight, len(model.user_emb.weight)-1)[1:]\n",
        "test_model = ProdVanillaCF(rand_user_emb, model.media_emb.weight)\n",
        "loss_fn = nn.MSELoss()\n",
        "\n",
        "validate(test_clean_dl, test_model, loss_fn, -1)\n",
        "print(rand_user_emb)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Popular workflow\n",
        "\n",
        "batch_size = 8192\n",
        "# Clean DL will return 0 for all users not in train set, used for default embedding indexing\n",
        "test_clean_dl = get_test_clean_dl(batch_size)\n",
        "\n",
        "# Create a model with the default embedding\n",
        "default_user_emb = extract_prod_user_emb(model.user_emb.weight.detach(), None)\n",
        "test_model = ProdVanillaCF(default_user_emb, model.media_emb.weight.detach())\n",
        "loss_fn = nn.MSELoss()\n",
        "\n",
        "validate(test_clean_dl, test_model, loss_fn, -1)\n",
        "print(default_user_emb)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WMN-HiuVl4p4",
        "outputId": "b7aea391-2c14-4bb4-c394-b776a77cdcaf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/merlin/io/dataset.py:253: UserWarning: Initializing an NVTabular Dataset in CPU mode.This is an experimental feature with extremely limited support!\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Eval: Epoch -1 - loss 0.112 - rmse 0.334\n",
            "tensor([[ 0.1018, -0.1648, -0.1807,  0.1837, -0.0041, -0.1732,  0.2080,  0.2014,\n",
            "          0.1216, -0.1376,  0.2017,  0.1804,  0.0525,  0.0952, -0.1720, -0.1523,\n",
            "         -0.1762, -0.0531, -0.1906, -0.1839,  0.0982,  0.1332, -0.1660, -0.1585,\n",
            "          0.1614, -0.0271,  0.2090, -0.1279, -0.0298, -0.1832,  0.1484, -0.1825]],\n",
            "       device='cuda:0')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Compare against train user with most ratings\n",
        "rand_user_emb = extract_prod_user_emb(model.user_emb.weight.detach(), 0, 0)[1:]\n",
        "test_model = ProdVanillaCF(rand_user_emb, model.media_emb.weight.detach())\n",
        "loss_fn = nn.MSELoss()\n",
        "\n",
        "validate(test_clean_dl, test_model, loss_fn, -1)\n",
        "print(rand_user_emb)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NtU8j41gmPE7",
        "outputId": "3dbe3647-2d0a-4ab2-fb75-b8e36ac14cc7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Eval: Epoch -1 - loss 0.241 - rmse 0.491\n",
            "tensor([[ 1.7919, -1.4220,  1.3872, -1.5669,  1.1848, -2.9955, -1.6835,  1.7565,\n",
            "         -0.4023,  0.8385,  0.3827, -0.4870,  0.0804, -0.6995,  1.3069, -0.0675,\n",
            "          1.1975,  0.8706,  1.4000, -2.0117, -0.1000, -1.5764, -1.1599, -3.1551,\n",
            "         -1.4080, -0.8436,  0.4175, -0.4022,  0.6902,  0.2238,  1.0015, -0.2927]],\n",
            "       device='cuda:0')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## MLP"
      ],
      "metadata": {
        "id": "aQ8ltA2PbdC0"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OLzPLGd12OAr"
      },
      "outputs": [],
      "source": [
        "# Normalize + sigmoid\n",
        "emb_size = 32\n",
        "model = MLP(emb_size, emb_size*2)\n",
        "batch_size = 8192\n",
        "train_dls, val_dl, test_dl = load_dls(batch_size)\n",
        "\n",
        "loss_fn = nn.MSELoss()\n",
        "lr = 1e-3\n",
        "decay = 0\n",
        "opt = torch.optim.Adam(model.parameters(), lr, weight_decay=decay)\n",
        "\n",
        "epochs = 5\n",
        "train_model(train_dls, val_dl, test_dl, model, loss_fn, opt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "F7zg1BFn_M8S",
        "outputId": "be1ffa4f-4e18-4b6b-9915-b6bd8ca59f70"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train: Epoch 1 - dl 0/10 - loss 1.201 - rmse 1.096\n",
            "Train: Epoch 1 - dl 3/10 - loss 0.932 - rmse 0.966\n",
            "Train: Epoch 1 - dl 6/10 - loss 0.862 - rmse 0.928\n",
            "Train: Epoch 1 - dl 9/10 - loss 0.827 - rmse 0.909\n",
            "Eval: Epoch 1 - loss 0.741 - rmse 0.861\n",
            "Epoch 0/20 - completed 1M - est. remaining 0H 19M \n",
            "\n",
            "Train: Epoch 2 - dl 0/10 - loss 0.735 - rmse 0.857\n",
            "Train: Epoch 2 - dl 3/10 - loss 0.729 - rmse 0.854\n",
            "Train: Epoch 2 - dl 6/10 - loss 0.724 - rmse 0.851\n",
            "Train: Epoch 2 - dl 9/10 - loss 0.721 - rmse 0.849\n",
            "Eval: Epoch 2 - loss 0.721 - rmse 0.849\n",
            "Epoch 1/20 - completed 1M - est. remaining 0H 18M \n",
            "\n",
            "Train: Epoch 3 - dl 0/10 - loss 0.707 - rmse 0.841\n",
            "Train: Epoch 3 - dl 3/10 - loss 0.703 - rmse 0.839\n",
            "Train: Epoch 3 - dl 6/10 - loss 0.700 - rmse 0.836\n",
            "Train: Epoch 3 - dl 9/10 - loss 0.697 - rmse 0.835\n",
            "Eval: Epoch 3 - loss 0.705 - rmse 0.840\n",
            "Epoch 2/20 - completed 1M - est. remaining 0H 17M \n",
            "\n",
            "Train: Epoch 4 - dl 0/10 - loss 0.686 - rmse 0.828\n",
            "Train: Epoch 4 - dl 3/10 - loss 0.683 - rmse 0.827\n",
            "Train: Epoch 4 - dl 6/10 - loss 0.680 - rmse 0.825\n",
            "Train: Epoch 4 - dl 9/10 - loss 0.678 - rmse 0.824\n",
            "Eval: Epoch 4 - loss 0.694 - rmse 0.833\n",
            "Epoch 3/20 - completed 1M - est. remaining 0H 16M \n",
            "\n",
            "Train: Epoch 5 - dl 0/10 - loss 0.670 - rmse 0.819\n",
            "Train: Epoch 5 - dl 3/10 - loss 0.668 - rmse 0.817\n",
            "Train: Epoch 5 - dl 6/10 - loss 0.665 - rmse 0.816\n",
            "Train: Epoch 5 - dl 9/10 - loss 0.664 - rmse 0.815\n",
            "Eval: Epoch 5 - loss 0.688 - rmse 0.829\n",
            "Epoch 4/20 - completed 1M - est. remaining 0H 15M \n",
            "\n",
            "Train: Epoch 6 - dl 0/10 - loss 0.657 - rmse 0.811\n",
            "Train: Epoch 6 - dl 3/10 - loss 0.655 - rmse 0.809\n",
            "Train: Epoch 6 - dl 6/10 - loss 0.653 - rmse 0.808\n",
            "Train: Epoch 6 - dl 9/10 - loss 0.652 - rmse 0.807\n",
            "Eval: Epoch 6 - loss 0.685 - rmse 0.828\n",
            "Epoch 5/20 - completed 1M - est. remaining 0H 14M \n",
            "\n",
            "Train: Epoch 7 - dl 0/10 - loss 0.646 - rmse 0.804\n",
            "Train: Epoch 7 - dl 3/10 - loss 0.644 - rmse 0.802\n",
            "Train: Epoch 7 - dl 6/10 - loss 0.642 - rmse 0.801\n",
            "Train: Epoch 7 - dl 9/10 - loss 0.640 - rmse 0.800\n",
            "Eval: Epoch 7 - loss 0.684 - rmse 0.827\n",
            "Epoch 6/20 - completed 1M - est. remaining 0H 13M \n",
            "\n",
            "Train: Epoch 8 - dl 0/10 - loss 0.635 - rmse 0.797\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-40-818fad720eea>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m20\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_dl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_dl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-39-7c23ce798b68>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(train_dls, val_dl, test_dl, model, loss_fn, opt)\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m         \u001b[0mmse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrmse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m         \u001b[0mval_mse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_rmse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalidate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_dl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-37-a5b351d81d58>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(train_dls, model, loss_fn, opt, epoch)\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_dl\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m             \u001b[0muser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'userId'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'cuda'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m             \u001b[0mmedia\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'movieId'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'cuda'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m             \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'cuda'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "emb_size = 256\n",
        "model = MLP(emb_size, emb_size*2)\n",
        "batch_size = 8192\n",
        "train_dls, val_dl, test_dl = load_dls(batch_size)\n",
        "\n",
        "loss_fn = nn.MSELoss()\n",
        "lr = 1e-3\n",
        "decay = 0\n",
        "opt = torch.optim.Adam(model.parameters(), lr, weight_decay=decay)\n",
        "\n",
        "epochs = 20\n",
        "train_model(train_dls, val_dl, test_dl, model, loss_fn, opt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z9mgqTUVMAG4",
        "outputId": "577b7b73-0650-4da2-a5f0-a7c0912d3cc4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train: Epoch 1 - dl 0/10 - loss 1.239 - rmse 1.113\n",
            "Train: Epoch 1 - dl 3/10 - loss 1.000 - rmse 1.000\n",
            "Train: Epoch 1 - dl 6/10 - loss 0.940 - rmse 0.969\n",
            "Train: Epoch 1 - dl 9/10 - loss 0.904 - rmse 0.951\n",
            "Eval: Epoch 1 - loss 0.806 - rmse 0.898\n",
            "Epoch 0/10 - completed 1M - est. remaining 0H 9M \n",
            "\n",
            "Train: Epoch 2 - dl 0/10 - loss 0.801 - rmse 0.895\n",
            "Train: Epoch 2 - dl 3/10 - loss 0.790 - rmse 0.889\n",
            "Train: Epoch 2 - dl 6/10 - loss 0.779 - rmse 0.883\n",
            "Train: Epoch 2 - dl 9/10 - loss 0.769 - rmse 0.877\n",
            "Eval: Epoch 2 - loss 0.734 - rmse 0.857\n",
            "Epoch 1/10 - completed 1M - est. remaining 0H 8M \n",
            "\n",
            "Train: Epoch 3 - dl 0/10 - loss 0.726 - rmse 0.852\n",
            "Train: Epoch 3 - dl 3/10 - loss 0.713 - rmse 0.844\n",
            "Train: Epoch 3 - dl 6/10 - loss 0.702 - rmse 0.838\n",
            "Train: Epoch 3 - dl 9/10 - loss 0.693 - rmse 0.833\n",
            "Eval: Epoch 3 - loss 0.671 - rmse 0.819\n",
            "Epoch 2/10 - completed 1M - est. remaining 0H 7M \n",
            "\n",
            "Train: Epoch 4 - dl 0/10 - loss 0.665 - rmse 0.815\n",
            "Train: Epoch 4 - dl 3/10 - loss 0.660 - rmse 0.813\n",
            "Train: Epoch 4 - dl 6/10 - loss 0.655 - rmse 0.810\n",
            "Train: Epoch 4 - dl 9/10 - loss 0.651 - rmse 0.807\n",
            "Eval: Epoch 4 - loss 0.646 - rmse 0.804\n",
            "Epoch 3/10 - completed 1M - est. remaining 0H 6M \n",
            "\n",
            "Train: Epoch 5 - dl 0/10 - loss 0.638 - rmse 0.798\n",
            "Train: Epoch 5 - dl 3/10 - loss 0.635 - rmse 0.797\n",
            "Train: Epoch 5 - dl 6/10 - loss 0.633 - rmse 0.795\n",
            "Train: Epoch 5 - dl 9/10 - loss 0.630 - rmse 0.794\n",
            "Eval: Epoch 5 - loss 0.634 - rmse 0.796\n",
            "Epoch 4/10 - completed 1M - est. remaining 0H 5M \n",
            "\n",
            "Train: Epoch 6 - dl 0/10 - loss 0.622 - rmse 0.789\n",
            "Train: Epoch 6 - dl 3/10 - loss 0.622 - rmse 0.789\n",
            "Train: Epoch 6 - dl 6/10 - loss 0.620 - rmse 0.787\n",
            "Train: Epoch 6 - dl 9/10 - loss 0.619 - rmse 0.786\n",
            "Eval: Epoch 6 - loss 0.629 - rmse 0.793\n",
            "Epoch 5/10 - completed 1M - est. remaining 0H 4M \n",
            "\n",
            "Train: Epoch 7 - dl 0/10 - loss 0.614 - rmse 0.783\n",
            "Train: Epoch 7 - dl 3/10 - loss 0.614 - rmse 0.783\n",
            "Train: Epoch 7 - dl 6/10 - loss 0.612 - rmse 0.782\n",
            "Train: Epoch 7 - dl 9/10 - loss 0.611 - rmse 0.782\n",
            "Eval: Epoch 7 - loss 0.626 - rmse 0.791\n",
            "Epoch 6/10 - completed 1M - est. remaining 0H 3M \n",
            "\n",
            "Train: Epoch 8 - dl 0/10 - loss 0.608 - rmse 0.780\n",
            "Train: Epoch 8 - dl 3/10 - loss 0.608 - rmse 0.780\n",
            "Train: Epoch 8 - dl 6/10 - loss 0.607 - rmse 0.779\n",
            "Train: Epoch 8 - dl 9/10 - loss 0.607 - rmse 0.779\n",
            "Eval: Epoch 8 - loss 0.623 - rmse 0.789\n",
            "Epoch 7/10 - completed 1M - est. remaining 0H 2M \n",
            "\n",
            "Train: Epoch 9 - dl 0/10 - loss 0.604 - rmse 0.777\n",
            "Train: Epoch 9 - dl 3/10 - loss 0.605 - rmse 0.778\n",
            "Train: Epoch 9 - dl 6/10 - loss 0.604 - rmse 0.777\n",
            "Train: Epoch 9 - dl 9/10 - loss 0.603 - rmse 0.777\n",
            "Eval: Epoch 9 - loss 0.622 - rmse 0.788\n",
            "Epoch 8/10 - completed 1M - est. remaining 0H 1M \n",
            "\n",
            "Train: Epoch 10 - dl 0/10 - loss 0.601 - rmse 0.776\n",
            "Train: Epoch 10 - dl 3/10 - loss 0.602 - rmse 0.776\n",
            "Train: Epoch 10 - dl 6/10 - loss 0.601 - rmse 0.775\n",
            "Train: Epoch 10 - dl 9/10 - loss 0.601 - rmse 0.775\n",
            "Eval: Epoch 10 - loss 0.621 - rmse 0.788\n",
            "Epoch 9/10 - completed 1M - est. remaining 0H 0M \n",
            "\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[[tensor(0.9035), tensor(0.9505), tensor(0.8062), tensor(0.8979)],\n",
              " [tensor(0.7685), tensor(0.8767), tensor(0.7338), tensor(0.8566)],\n",
              " [tensor(0.6934), tensor(0.8327), tensor(0.6710), tensor(0.8191)],\n",
              " [tensor(0.6514), tensor(0.8071), tensor(0.6462), tensor(0.8039)],\n",
              " [tensor(0.6304), tensor(0.7940), tensor(0.6339), tensor(0.7962)],\n",
              " [tensor(0.6185), tensor(0.7865), tensor(0.6288), tensor(0.7930)],\n",
              " [tensor(0.6113), tensor(0.7818), tensor(0.6257), tensor(0.7910)],\n",
              " [tensor(0.6066), tensor(0.7788), tensor(0.6233), tensor(0.7895)],\n",
              " [tensor(0.6032), tensor(0.7767), tensor(0.6216), tensor(0.7884)],\n",
              " [tensor(0.6007), tensor(0.7751), tensor(0.6207), tensor(0.7878)]]"
            ]
          },
          "execution_count": 47,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "emb_size = 256\n",
        "model = MLP(emb_size, emb_size*2)\n",
        "batch_size = 8192\n",
        "train_dls, val_dl, test_dl = load_dls(batch_size)\n",
        "\n",
        "loss_fn = nn.MSELoss()\n",
        "lr = 1e-3\n",
        "decay = 5e-5\n",
        "opt = torch.optim.Adam(model.parameters(), lr, weight_decay=decay)\n",
        "\n",
        "epochs = 10\n",
        "train_model(train_dls, val_dl, test_dl, model, loss_fn, opt)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Popular Workflow"
      ],
      "metadata": {
        "id": "YDyQ-FL1mKSs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Normalize + sigmoid + Popular workflow\n",
        "emb_size = 32\n",
        "model = MLP(emb_size, 128, n_users=97369, n_media=20591)\n",
        "batch_size = 8192\n",
        "train_dls, val_dl, test_dl = load_dls(batch_size)\n",
        "\n",
        "loss_fn = nn.MSELoss()\n",
        "lr = 1e-2\n",
        "decay = 0\n",
        "opt = torch.optim.Adam(model.parameters(), lr, weight_decay=decay)\n",
        "\n",
        "epochs = 5\n",
        "train_model(train_dls, val_dl, test_dl, model, loss_fn, opt)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XBVQEKFuy-q6",
        "outputId": "a1ba2cf3-dd5c-4f5c-e209-37526d1f0d4f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train: Epoch 1 - dl 4/10 - loss 0.042 - rmse 0.204\n",
            "Train: Epoch 1 - dl 9/10 - loss 0.038 - rmse 0.196\n",
            "Eval: Epoch 1 - loss 0.035 - rmse 0.186\n",
            "Epoch 1/5 - completed 0M - est. remaining 0H 0M \n",
            "\n",
            "Train: Epoch 2 - dl 4/10 - loss 0.034 - rmse 0.185\n",
            "Train: Epoch 2 - dl 9/10 - loss 0.034 - rmse 0.184\n",
            "Eval: Epoch 2 - loss 0.033 - rmse 0.183\n",
            "Epoch 2/5 - completed 0M - est. remaining 0H 0M \n",
            "\n",
            "Train: Epoch 3 - dl 4/10 - loss 0.033 - rmse 0.181\n",
            "Train: Epoch 3 - dl 9/10 - loss 0.033 - rmse 0.181\n",
            "Eval: Epoch 3 - loss 0.033 - rmse 0.182\n",
            "Epoch 3/5 - completed 0M - est. remaining 0H 0M \n",
            "\n",
            "Train: Epoch 4 - dl 4/10 - loss 0.032 - rmse 0.179\n",
            "Train: Epoch 4 - dl 9/10 - loss 0.032 - rmse 0.179\n",
            "Eval: Epoch 4 - loss 0.033 - rmse 0.181\n",
            "Epoch 4/5 - completed 0M - est. remaining 0H 0M \n",
            "\n",
            "Train: Epoch 5 - dl 4/10 - loss 0.032 - rmse 0.178\n",
            "Train: Epoch 5 - dl 9/10 - loss 0.032 - rmse 0.178\n",
            "Eval: Epoch 5 - loss 0.033 - rmse 0.181\n",
            "Epoch 5/5 - completed 0M - est. remaining 0H 0M \n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[tensor(0.0384), tensor(0.1959), tensor(0.0346), tensor(0.1861)],\n",
              " [tensor(0.0338), tensor(0.1839), tensor(0.0334), tensor(0.1828)],\n",
              " [tensor(0.0327), tensor(0.1807), tensor(0.0330), tensor(0.1815)],\n",
              " [tensor(0.0321), tensor(0.1791), tensor(0.0328), tensor(0.1811)],\n",
              " [tensor(0.0315), tensor(0.1776), tensor(0.0326), tensor(0.1806)]]"
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Popular Workflow Test"
      ],
      "metadata": {
        "id": "7OHxxxN7nPIc"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-XAqN-be7tYC"
      },
      "outputs": [],
      "source": [
        "# Create DL to test specific user\n",
        "movie_ids = np.unique(df_ratings['movieId'])\n",
        "user_df = pd.DataFrame({'userId': [0]*len(movie_ids), 'movieId': movie_ids, 'rating': [0.]*len(movie_ids)})\n",
        "\n",
        "# user_df = df_ratings[df_ratings['userId'] == 72315]\n",
        "user_ds = nvt.Dataset(user_df)\n",
        "\n",
        "torch_ds = TorchAsyncItr(\n",
        "    workflow.transform(user_ds),\n",
        "    batch_size=1024,\n",
        "    cats=['userId', 'movieId'],\n",
        "    conts=[\"rating\"], \n",
        ")\n",
        "dl = DLDataLoader(torch_ds, batch_size=None, pin_memory=False, num_workers=0)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = torch.jit.load('mlp_4l_32emb_1e-2lradam_0d_5e--01_27_23.pt')"
      ],
      "metadata": {
        "id": "jSUcNMoEp3TQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss_fn = nn.MSELoss()\n",
        "validate(dl, model, loss_fn, -1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "69z7qBJuj3G-",
        "outputId": "8e5833ed-f344-4417-caa5-b5a58c624f08"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Eval: Epoch -1 - loss 0.015 - rmse 0.124\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor(0.0154), tensor(0.1242))"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "preds = []\n",
        "\n",
        "model.cuda()\n",
        "model.eval()\n",
        "for i, (x, _) in enumerate(dl):\n",
        "    user = x['userId'].to('cuda')\n",
        "    media = x['movieId'].to('cuda')\n",
        "    y = x['rating'].to('cuda')\n",
        "\n",
        "    with torch.no_grad():\n",
        "        pred = model(user, media)\n",
        "        pred = pred.squeeze().cpu()\n",
        "        preds.extend(pred)\n",
        "\n",
        "print(sorted(zip(preds, movie_ids), key=lambda x: x[0], reverse=True)[:2])\n",
        "\n",
        "sorted_preds = sorted(zip(preds, movie_ids), key=lambda x: x[0], reverse=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8N1FyrEHkkfl",
        "outputId": "28edd495-b023-4233-9563-2fd474dc243f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[(tensor(0.9066), 26082), (tensor(0.9032), 171011)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "user_ratings = df_ratings[df_ratings['userId'] == 72315]\n",
        "user_ratings[user_ratings['movieId'] == 171011]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        },
        "id": "j_dNBwXli2xZ",
        "outputId": "699cbe6c-f187-4f91-ec64-f07731a29d97"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "          userId  movieId  rating\n",
              "11144765   72315   171011     4.5"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-2fb9ed81-395c-46bd-a3d7-0248cba71535\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>userId</th>\n",
              "      <th>movieId</th>\n",
              "      <th>rating</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>11144765</th>\n",
              "      <td>72315</td>\n",
              "      <td>171011</td>\n",
              "      <td>4.5</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2fb9ed81-395c-46bd-a3d7-0248cba71535')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-2fb9ed81-395c-46bd-a3d7-0248cba71535 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-2fb9ed81-395c-46bd-a3d7-0248cba71535');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_movies[df_movies['movieId'] == 171011]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        },
        "id": "9PUosdxplcSw",
        "outputId": "ef3afcda-7750-4df7-af07-f7a9b435b759"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       Unnamed: 0  movieId                   title       genres  \\\n",
              "45741       45741   171011  Planet Earth II (2016)  Documentary   \n",
              "\n",
              "                                            split_genres  \\\n",
              "45741  ['\"Planet Earth II (2016)\" is a Documentary mo...   \n",
              "\n",
              "                                               lm_genres  num_ratings  \\\n",
              "45741  [ 5.58925644e-02 -2.13906199e-01  1.76731706e-...       1124.0   \n",
              "\n",
              "       avg_rating  \n",
              "45741    4.483096  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-d03d1b57-aa36-4111-b583-6d4e65925926\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>movieId</th>\n",
              "      <th>title</th>\n",
              "      <th>genres</th>\n",
              "      <th>split_genres</th>\n",
              "      <th>lm_genres</th>\n",
              "      <th>num_ratings</th>\n",
              "      <th>avg_rating</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>45741</th>\n",
              "      <td>45741</td>\n",
              "      <td>171011</td>\n",
              "      <td>Planet Earth II (2016)</td>\n",
              "      <td>Documentary</td>\n",
              "      <td>['\"Planet Earth II (2016)\" is a Documentary mo...</td>\n",
              "      <td>[ 5.58925644e-02 -2.13906199e-01  1.76731706e-...</td>\n",
              "      <td>1124.0</td>\n",
              "      <td>4.483096</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d03d1b57-aa36-4111-b583-6d4e65925926')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-d03d1b57-aa36-4111-b583-6d4e65925926 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-d03d1b57-aa36-4111-b583-6d4e65925926');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_movies[df_movies['movieId'] == 79800]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        },
        "id": "zh99HSrIm6qA",
        "outputId": "0b64fe8a-7cad-40a1-a39f-0b996c5d4806"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       Unnamed: 0  movieId                       title        genres  \\\n",
              "15077       15077    79800  Life During Wartime (2009)  Comedy|Drama   \n",
              "\n",
              "              split_genres                                          lm_genres  \\\n",
              "15077  ['Comedy', 'Drama']  [-1.01838388e-01 -1.60389721e-01  1.15125656e-...   \n",
              "\n",
              "       num_ratings  avg_rating  \n",
              "15077         95.0    3.184211  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-6c8e51e5-bdcf-43f5-b0e7-45045b37e7fa\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>movieId</th>\n",
              "      <th>title</th>\n",
              "      <th>genres</th>\n",
              "      <th>split_genres</th>\n",
              "      <th>lm_genres</th>\n",
              "      <th>num_ratings</th>\n",
              "      <th>avg_rating</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>15077</th>\n",
              "      <td>15077</td>\n",
              "      <td>79800</td>\n",
              "      <td>Life During Wartime (2009)</td>\n",
              "      <td>Comedy|Drama</td>\n",
              "      <td>['Comedy', 'Drama']</td>\n",
              "      <td>[-1.01838388e-01 -1.60389721e-01  1.15125656e-...</td>\n",
              "      <td>95.0</td>\n",
              "      <td>3.184211</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6c8e51e5-bdcf-43f5-b0e7-45045b37e7fa')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-6c8e51e5-bdcf-43f5-b0e7-45045b37e7fa button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-6c8e51e5-bdcf-43f5-b0e7-45045b37e7fa');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Test against default embedding\n",
        "default_user_emb = extract_prod_user_emb(model.user_emb.weight.detach(), None)\n",
        "test_model = ProdVanillaCF(default_user_emb, model.media_emb.weight.detach())\n",
        "\n",
        "preds = []\n",
        "\n",
        "test_model.cuda()\n",
        "test_model.eval()\n",
        "for i, (x, _) in enumerate(dl):\n",
        "    user = x['userId'].to('cuda')\n",
        "    media = x['movieId'].to('cuda')\n",
        "    y = x['rating'].to('cuda')\n",
        "\n",
        "    with torch.no_grad():\n",
        "        pred = test_model(user, media)\n",
        "        pred = pred.squeeze().cpu()\n",
        "        preds.extend(pred)\n",
        "\n",
        "print(sorted(zip(preds, movie_ids), key=lambda x: x[0], reverse=True)[:5])\n",
        "\n",
        "sorted_preds = sorted(zip(preds, movie_ids), key=lambda x: x[0], reverse=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e8vzjMo7miyj",
        "outputId": "084ecea5-e9e9-4526-8e77-ced908c62c41"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[(tensor(0.9925), 165969), (tensor(0.9914), 79800), (tensor(0.9908), 7091), (tensor(0.9908), 112495), (tensor(0.9907), 42584)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XCnkhrgc9vP9"
      },
      "source": [
        "# Production\n",
        "\n",
        "TODO: Need new workflow or take second workflow.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ACIUxmQoVVcn"
      },
      "outputs": [],
      "source": [
        "# Trace the model\n",
        "model.to('cpu')\n",
        "model.eval()\n",
        "\n",
        "inp = (torch.randint(1, 10000, (16,1)), \n",
        "       torch.randint(1, 10000, (16,1)))\n",
        "traced_model = torch.jit.trace(model, inp)\n",
        "traced_model.save('mlp_4l_32emb_1e-2lradam_0d_5e--01_27_23.pt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DZaXFK_NkPDg"
      },
      "outputs": [],
      "source": [
        "model = torch.jit.load('cf_12emb_1e-2lradam_0d_5e--01_23_23.pt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M8GuQ0V0-k1k"
      },
      "outputs": [],
      "source": [
        "# Production models from trained models/embeddings\n",
        "import copy\n",
        "\n",
        "class ProdVanillaCF(nn.Module):\n",
        "    def __init__(self, prod_user_emb, train_media_emb):\n",
        "        super().__init__()\n",
        "        self.user_emb = nn.Embedding.from_pretrained(prod_user_emb, freeze=True)\n",
        "        self.media_emb = nn.Embedding.from_pretrained(train_media_emb, freeze=True)\n",
        "\n",
        "    def forward(self, user, media):\n",
        "        return torch.sigmoid(self.user_emb(user) @ torch.transpose(self.media_emb(media), 1, 2))\n",
        "\n",
        "\n",
        "def prodMLPGenresMH(model, prod_user_emb, train_media_emb):\n",
        "    prod_model = copy.deepcopy(model)\n",
        "    prod_model.user_emb = nn.Embedding.from_pretrained(prod_user_emb, freeze=True)\n",
        "    prod_model.media_emb = nn.Embedding.from_pretrained(train_media_emb, freeze=True)\n",
        "    return prod_model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ywhZ2n2W3BOp"
      },
      "outputs": [],
      "source": [
        "def extract_prod_user_emb(train_emb: torch.Tensor, start_idx: int, end_idx: int=None) -> torch.Tensor:\n",
        "    ''' Extracts the default user embedding and real user embedding for use in production.\n",
        "        The default embedding is taken as the average embedding of real and train users \n",
        "        (for the time being).\n",
        "    \n",
        "    Args:\n",
        "      train_emb: the embedding tensor from the trained model.\n",
        "      start_idx: the start idx in the train_emb of the real users. \n",
        "        If none then just extract default.\n",
        "      end_idx: the end idx in the train_emb of the real users.\n",
        "        If none then use up through last idx.\n",
        "\n",
        "    Returns:\n",
        "      The concatenated [default embedding, real user embedding]\n",
        "    '''\n",
        "    default_emb = torch.mean(train_emb, dim=0, keepdim=True)\n",
        "    if start_idx is None:\n",
        "      return default_emb\n",
        "    emb = train_emb[start_idx:end_idx+1] if end_idx is not None else train_emb[start_idx:]\n",
        "    return torch.cat([default_emb, emb], axis=0)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gSIyzlflFdU9"
      },
      "outputs": [],
      "source": [
        "# Trace the production model\n",
        "prod_user_emb = extract_prod_user_emb(model.user_emb.weight, 0, 0)\n",
        "test_model = ProdVanillaCF(prod_user_emb, model.media_emb.weight)\n",
        "model.eval()\n",
        "\n",
        "inp = (torch.randint(1, 10000, (16,1)), \n",
        "       torch.randint(1, 10000, (16,1)))\n",
        "traced_model = torch.jit.trace(model, inp)\n",
        "traced_model.save('cf_12emb_1e-2lradam_0d_5e_prodavg-0--01_23_25.pt')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Extra Features"
      ],
      "metadata": {
        "id": "VcI9kn0_m0z1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Compute average rating and rating counts and add to movie df\n",
        "\n",
        "moviecount = df_ratings.groupby('movieId')['userId'].nunique()\n",
        "df = pd.merge(df_movies, moviecount, how='left', on='movieId')\n",
        "\n",
        "avgrating = df_ratings.groupby('movieId')['rating'].mean()\n",
        "df = pd.merge(df, avgrating, how='left', on='movieId')\n",
        "\n",
        "df = df.rename(columns={'userId': 'num_ratings', 'rating': 'avg_rating'})\n",
        "\n",
        "df.to_csv(os.path.join(MOVIE_PATH, 'movie_features.csv'))"
      ],
      "metadata": {
        "id": "vwuIbeKbm2nq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Updated Models"
      ],
      "metadata": {
        "id": "uGIiSphW0XDt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MultiHotEmbedding(torch.nn.Module):\n",
        "    \"\"\"Map multiple categorical variables to concatenated embeddings.\n",
        "    Args:\n",
        "        embedding_dict_shapes: A dictionary mapping column names to\n",
        "            (cardinality, embedding_size) tuples.\n",
        "        dropout: A float.\n",
        "    Inputs:\n",
        "        x: A dictionary with multi-hot column name as keys and a tuple\n",
        "           containing the column values and offsets as values.\n",
        "    Outputs:\n",
        "        A Float Tensor with shape [batch_size, embedding_size_after_concat].\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, shape, dropout=0.0, mode=\"sum\"):\n",
        "        super().__init__()\n",
        "        self.emb = torch.nn.EmbeddingBag(*shape, mode=mode)\n",
        "        self.dropout = torch.nn.Dropout(p=dropout)\n",
        "\n",
        "    def forward(self, x):\n",
        "        values, offsets = x\n",
        "        values = torch.squeeze(values, -1)\n",
        "        # for the case where only one value in values\n",
        "        if len(values.shape) == 0:\n",
        "            values = values.unsqueeze(0)\n",
        "        x = self.emb(values, offsets[:, 0])\n",
        "        x = self.dropout(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "class MLPGenreMH(nn.Module):\n",
        "    def __init__(self, emb_size, hidden_dim, genre_emb_shape, n_users=154415, n_media=56961, n_extra_feats=0):\n",
        "        super().__init__()\n",
        "        \n",
        "        self.user_emb = nn.Embedding(n_users, emb_size)\n",
        "        self.media_emb = nn.Embedding(n_media, emb_size)\n",
        "        self.genre_emb = MultiHotEmbedding(genre_emb_shape)\n",
        "\n",
        "        self.n_extra_feats = n_extra_feats\n",
        "\n",
        "        self.mlp = nn.Sequential(nn.Linear(emb_size*2+n_extra_feats+genre_emb_shape[1], hidden_dim),\n",
        "                                #  nn.Linear(512+405+n_extra_feats+genre_emb_shape[1], hidden_dim),\n",
        "                                  nn.LayerNorm(hidden_dim),\n",
        "                                  nn.ReLU(inplace=True),\n",
        "                                  nn.Linear(hidden_dim, hidden_dim),\n",
        "                                  nn.LayerNorm(hidden_dim),\n",
        "                                  nn.ReLU(inplace=True),\n",
        "                                  nn.Linear(hidden_dim, hidden_dim),\n",
        "                                  nn.LayerNorm(hidden_dim),\n",
        "                                  nn.ReLU(inplace=True),\n",
        "                                  nn.Linear(hidden_dim, hidden_dim),\n",
        "                                  nn.LayerNorm(hidden_dim),\n",
        "                                  nn.Linear(hidden_dim, 1))\n",
        "\n",
        "\n",
        "    def forward(self, user, media, genres, extra_feats=[]):\n",
        "        x = torch.cat([self.user_emb(user).squeeze(), \n",
        "                       self.media_emb(media).squeeze(),\n",
        "                       self.genre_emb(genres), \n",
        "                       *extra_feats], axis=1)\n",
        "        return torch.sigmoid(self.mlp(x))\n",
        "\n",
        "\n",
        "# class MLPGenreMHCluster(nn.Module):\n",
        "#     def __init__(self, emb_size, hidden_dim, genre_emb_shape, n_users=154415, n_media=56961, n_extra_feats=0):\n",
        "#         super().__init__()\n",
        "        \n",
        "#         self.user_emb = nn.Embedding(n_users, emb_size)\n",
        "#         self.media_emb = nn.Embedding(n_media, emb_size)\n",
        "#         self.genre_emb = MultiHotEmbedding(genre_emb_shape)\n",
        "\n",
        "#         self.n_extra_feats = n_extra_feats\n",
        "\n",
        "#         self.mlp = nn.Sequential(nn.Linear(emb_size*2+n_extra_feats+genre_emb_shape[1], hidden_dim),\n",
        "#                                 #  nn.Linear(512+405+n_extra_feats+genre_emb_shape[1], hidden_dim),\n",
        "#                                   nn.LayerNorm(hidden_dim),\n",
        "#                                   nn.ReLU(inplace=True),\n",
        "#                                   nn.Linear(hidden_dim, hidden_dim),\n",
        "#                                   nn.LayerNorm(hidden_dim),\n",
        "#                                   nn.ReLU(inplace=True),\n",
        "#                                   nn.Linear(hidden_dim, hidden_dim),\n",
        "#                                   nn.LayerNorm(hidden_dim),\n",
        "#                                   nn.ReLU(inplace=True),\n",
        "#                                   nn.Linear(hidden_dim, hidden_dim),\n",
        "#                                   nn.LayerNorm(hidden_dim),\n",
        "#                                   nn.Linear(hidden_dim, 1))\n",
        "\n",
        "#     def forward(self, user_weights, media, genres, extra_feats=[]):\n",
        "#         x = torch.cat([user_weights, \n",
        "#                        self.media_emb(media).squeeze(),\n",
        "#                        self.genre_emb(genres), \n",
        "#                        *extra_feats], axis=1)\n",
        "#         return torch.sigmoid(self.mlp(x))"
      ],
      "metadata": {
        "id": "JtKUUtUO5EMQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wxElXHyeW8Ro"
      },
      "source": [
        "## BERT Embeddings\n",
        "In progress feature. Comparing BERT embeddings of the genres to one-hot encoding"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install transformers"
      ],
      "metadata": {
        "id": "6pFC5WuXVvHQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# from transformers import BertTokenizer, BertModel\n",
        "# tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "# model = BertModel.from_pretrained(\"bert-base-uncased\")\n",
        "\n",
        "from transformers import DistilBertTokenizer, DistilBertModel\n",
        "tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')\n",
        "model = DistilBertModel.from_pretrained(\"distilbert-base-uncased\")"
      ],
      "metadata": {
        "id": "D-33mM_1GAyE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BBqjPzDtXJXY"
      },
      "outputs": [],
      "source": [
        "# Non batch version\n",
        "\n",
        "def get_lm_embedding(texts=[], combine_texts=False, title=None, media_type='movie'):\n",
        "    '''\n",
        "    texts ([str]): the texts to embed\n",
        "    combine_texts (bool): pass in the texts as a single string 'text1, text2, ..., and textn'\n",
        "    title (str (optional)): the media title string. \n",
        "        combine_texts (regardless of combine_texts value) and prepends the movie title.\n",
        "        Final string is of the form: '\"title\" is a text1, text2, ..., and textn media_type.'\n",
        "    media_type (str): the media_type inserted into title. e.g. book, movie, etc.\n",
        "    '''\n",
        "    if len(texts) > 1 and (combine_texts or title):\n",
        "      if len(texts) > 2:\n",
        "          # 'text1, text2, ..., and textn'\n",
        "          texts = ['{}, and {}'.format(', '.join(texts[:-1]), texts[-1])]\n",
        "          # texts = [', and '.join([', '.join(texts[:-1]) texts[-1]])]\n",
        "      else:\n",
        "          texts = ['{} and {}'.format(*texts)]\n",
        "\n",
        "      if title:\n",
        "          texts[0] = '\"{}\" is a {} {}.'.format(title, texts[0], media_type)\n",
        "\n",
        "    outputs = []\n",
        "    for text in texts:\n",
        "        with torch.no_grad():\n",
        "            # Tokenize text\n",
        "            encoded_input = tokenizer(text, return_tensors='pt')\n",
        "            # Forward pass and grab hidden states\n",
        "            output = model(**encoded_input).last_hidden_state\n",
        "            # Average hidden states across words\n",
        "            outputs += [torch.mean(output, dim=(0,1))]\n",
        "    \n",
        "    # Average over all words if not combine_text\n",
        "    final_output = torch.mean(torch.stack(outputs), dim=(0), keepdim=True)\n",
        "\n",
        "    return final_output\n",
        "\n",
        "# add empty genres column\n",
        "df_ratings['genres'] = np.nan\n",
        "# df_ratings['genres_lmavg'] = np.nan\n",
        "# df_ratings['genres_lmcomb'] = np.nan\n",
        "df_ratings['genres_lmtitle'] = np.nan\n",
        "\n",
        "# Add the genres to each movie to df_ratings\n",
        "# Don't like iterating rows in pandas so zip up lists to iterate instead\n",
        "movie_genres = zip(list(df_movies['movieId']), list(df_movies['title']), list(df_movies['genres']))\n",
        "for mid, title, genres in movie_genres:\n",
        "    split_genres = genres.split('|')\n",
        "    # Gather embeddings\n",
        "    # lmavg = get_lm_embedding(split_genres)\n",
        "    # lmcomb = get_lm_embedding(split_genres, combine_texts=True)\n",
        "    lmtitle = get_lm_embedding(split_genres, title=title)\n",
        "\n",
        "    # Add to df\n",
        "    indexes = df_ratings.index[df_ratings['movieId'] == mid]\n",
        "    df_ratings.loc[indexes, 'genres'] = pd.Series([split_genres]*len(df_ratings.loc[indexes]), index=indexes)\n",
        "    # df_ratings.loc[indexes, 'genres_lmavg'] = pd.Series([lmavg]*len(df_ratings.loc[indexes]), index=indexes)\n",
        "    # df_ratings.loc[indexes, 'genres_lmcomb'] = pd.Series([lmcomb]*len(df_ratings.loc[indexes]), index=indexes)\n",
        "    df_ratings.loc[indexes, 'genres_lmtitle'] = pd.Series([lmtitle]*len(df_ratings.loc[indexes]), index=indexes)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Batched version\n",
        "\n",
        "def get_lm_embedding_batch(batch_texts=[[]], titles=None, media_type='movie'):\n",
        "    '''\n",
        "    batch_texts ([[str]]): batch of the texts to embed\n",
        "    titles ([str] (optional)): the media title string. \n",
        "        combine_texts (regardless of combine_texts value) and prepends the movie title.\n",
        "        Final string is of the form: '\"title\" is a text1, text2, ..., and textn media_type.'\n",
        "        Otherwise defaults to: 'text1, text2, ..., and textn'\n",
        "    media_type (str): the media_type inserted into title. e.g. book, movie, etc.\n",
        "    '''\n",
        "    if titles:\n",
        "        assert len(titles) == len(batch_texts)\n",
        "\n",
        "    texts = []\n",
        "    for i in range(len(batch_texts)):\n",
        "        texts.append(list(batch_texts[i]))\n",
        "        if len(texts[i]) > 1:\n",
        "            if len(texts[i]) > 2:\n",
        "                # 'text1, text2, ..., and textn'\n",
        "                texts[i] = ['{}, and {}'.format(', '.join(batch_texts[i][:-1]), batch_texts[i][-1])]\n",
        "            else:\n",
        "                texts[i] = ['{} and {}'.format(*batch_texts[i])]\n",
        "\n",
        "        if titles:\n",
        "            texts[i][0] = '\"{}\" is a {} {}.'.format(titles[i], batch_texts[i][0], media_type)\n",
        "        \n",
        "        texts[i] = texts[i][0]\n",
        "\n",
        "    with torch.no_grad():\n",
        "        # Tokenize text\n",
        "        encoded_input = tokenizer(texts, return_tensors='pt', padding=True)\n",
        "        # Forward pass and grab hidden states\n",
        "        output = model(**encoded_input).last_hidden_state\n",
        "        # Average hidden states across words\n",
        "        outputs = torch.mean(output, dim=(1))\n",
        "\n",
        "    return outputs\n",
        "\n",
        "\n",
        "split_genres_all = []\n",
        "lmtitle_all = []\n",
        "\n",
        "# Don't like iterating rows in pandas so zip up lists to iterate instead\n",
        "movie_genres = list(zip(list(df_movies['movieId']), list(df_movies['title']), list(df_movies['genres'])))\n",
        "title_batch = []\n",
        "split_genres_batch = []\n",
        "\n",
        "for i in range(0, len(movie_genres), 64):\n",
        "    j = i+64 if i+64 <= len(movie_genres) else len(movie_genres)\n",
        "    for mid, title, genres in movie_genres[i:j]:\n",
        "        split_genres_batch.append(genres.split('|'))\n",
        "        title_batch.append(title)\n",
        "\n",
        "    split_genres_all.extend(split_genres_batch)\n",
        "    # # Gather embeddings\n",
        "    lmtitle = get_lm_embedding_batch(split_genres_batch, titles=title_batch)\n",
        "    lmtitle_all.append(lmtitle)\n",
        "    split_genres_batch = []\n",
        "    title_batch = []\n",
        "    \n",
        "    print(i)\n",
        "\n"
      ],
      "metadata": {
        "id": "TM0O3MIVFcT_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.save(os.path.join(MOVIE_PATH, 'lm_emb'), torch.cat(lmtitle_all, axis=0).numpy())"
      ],
      "metadata": {
        "id": "f9gb28JYPuuw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_movies['split_genres'] = split_genres_all\n",
        "df_movies.to_csv(os.path.join(MOVIE_PATH, 'movie_genres.csv'))"
      ],
      "metadata": {
        "id": "9tztimCwRP96"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lm_genres = np.load(os.path.join(MOVIE_PATH, 'lm_emb'))\n",
        "df_movies['lm_genres'] = [x for x in lm_genres]"
      ],
      "metadata": {
        "id": "fd2g5Rc6RqK7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Learned Genre Multi-Hot Embeddings\n",
        "Added on to the Popular Workflow"
      ],
      "metadata": {
        "id": "tA1D1sbzvODU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data Loading"
      ],
      "metadata": {
        "id": "aE81CsM2u67D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from ast import literal_eval\n",
        "df_movies.split_genres = df_movies.split_genres.apply(literal_eval)\n",
        "df_movies = df_movies.drop(columns=['Unnamed: 0', 'Unnamed: 0.1', 'title', 'genres', 'lm_genres', 'num_ratings', 'avg_rating'])\n",
        "df_movies.head(n=5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "YPyfLdNFu9Bh",
        "outputId": "8f713ac5-818f-4552-9bed-236e1580550f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   movieId                                       split_genres\n",
              "0        1  [Adventure, Animation, Children, Comedy, Fantasy]\n",
              "1        2                     [Adventure, Children, Fantasy]\n",
              "2        3                                  [Comedy, Romance]\n",
              "3        4                           [Comedy, Drama, Romance]\n",
              "4        5                                           [Comedy]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-2b34cb76-aa88-4799-aa87-859e39c3b340\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>movieId</th>\n",
              "      <th>split_genres</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>[Adventure, Animation, Children, Comedy, Fantasy]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>[Adventure, Children, Fantasy]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>[Comedy, Romance]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>[Comedy, Drama, Romance]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>[Comedy]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2b34cb76-aa88-4799-aa87-859e39c3b340')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-2b34cb76-aa88-4799-aa87-859e39c3b340 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-2b34cb76-aa88-4799-aa87-859e39c3b340');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_workflow(load_path:str = None) -> nvt.Workflow:\n",
        "    ''' Loads the Workflow or creates a new one if load_path is None.'''\n",
        "    if load_path:\n",
        "        workflow = nvt.Workflow.load(load_path)\n",
        "\n",
        "    else:\n",
        "        joined = [\"userId\", \"movieId\"] >> nvt.ops.JoinExternal(df_movies, on=[\"movieId\"])\n",
        "        output = joined >> nvt.ops.Categorify()\n",
        "        output += nvt.ColumnGroup([\"rating\"]) >> nvt.ops.NormalizeMinMax()\n",
        "        workflow = nvt.Workflow(output)\n",
        "\n",
        "    return workflow\n",
        "\n",
        "\n",
        "workflow = get_workflow()\n",
        "partition_fit_and_transform()"
      ],
      "metadata": {
        "id": "ZKWevCbKwFow"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "workflow.save('movie_workflow_popular_onehotgenres')\n",
        "!zip -r movie_workflow_popular_onehotgenres movie_workflow_popular_onehotgenres"
      ],
      "metadata": {
        "id": "2nhqOmR4z6Lc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nvt.Dataset('val', engine='parquet').schema"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 193
        },
        "id": "GxDVQYK-0dbO",
        "outputId": "bedf6f9a-8a63-4f0b-e0be-f437e5672ba8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'name': 'userId', 'tags': {<Tags.CATEGORICAL: 'categorical'>}, 'properties': {'embedding_sizes': {'dimension': 512.0, 'cardinality': 97235.0}, 'max_size': 0.0, 'freq_threshold': 0.0, 'start_index': 0.0, 'cat_path': './/categories/unique.userId.parquet', 'num_buckets': None, 'domain': {'min': 0, 'max': 97234, 'name': 'userId'}}, 'dtype': dtype('int64'), 'is_list': False, 'is_ragged': False}, {'name': 'movieId', 'tags': {<Tags.CATEGORICAL: 'categorical'>}, 'properties': {'freq_threshold': 0.0, 'start_index': 0.0, 'cat_path': './/categories/unique.movieId.parquet', 'num_buckets': None, 'embedding_sizes': {'dimension': 405.0, 'cardinality': 19557.0}, 'max_size': 0.0, 'domain': {'min': 0, 'max': 19556, 'name': 'movieId'}}, 'dtype': dtype('int64'), 'is_list': False, 'is_ragged': False}, {'name': 'split_genres', 'tags': {<Tags.CATEGORICAL: 'categorical'>}, 'properties': {'num_buckets': None, 'freq_threshold': 0.0, 'start_index': 0.0, 'max_size': 0.0, 'cat_path': './/categories/unique.split_genres.parquet', 'embedding_sizes': {'cardinality': 21.0, 'dimension': 16.0}, 'domain': {'min': 0, 'max': 20, 'name': 'split_genres'}}, 'dtype': dtype('int64'), 'is_list': True, 'is_ragged': True}, {'name': 'rating', 'tags': {<Tags.CONTINUOUS: 'continuous'>}, 'properties': {}, 'dtype': dtype('float64'), 'is_list': False, 'is_ragged': False}]"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>name</th>\n",
              "      <th>tags</th>\n",
              "      <th>dtype</th>\n",
              "      <th>is_list</th>\n",
              "      <th>is_ragged</th>\n",
              "      <th>properties.embedding_sizes.dimension</th>\n",
              "      <th>properties.embedding_sizes.cardinality</th>\n",
              "      <th>properties.max_size</th>\n",
              "      <th>properties.freq_threshold</th>\n",
              "      <th>properties.start_index</th>\n",
              "      <th>properties.cat_path</th>\n",
              "      <th>properties.num_buckets</th>\n",
              "      <th>properties.domain.min</th>\n",
              "      <th>properties.domain.max</th>\n",
              "      <th>properties.domain.name</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>userId</td>\n",
              "      <td>(Tags.CATEGORICAL)</td>\n",
              "      <td>int64</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>512.0</td>\n",
              "      <td>97235.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>.//categories/unique.userId.parquet</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "      <td>97234.0</td>\n",
              "      <td>userId</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>movieId</td>\n",
              "      <td>(Tags.CATEGORICAL)</td>\n",
              "      <td>int64</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>405.0</td>\n",
              "      <td>19557.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>.//categories/unique.movieId.parquet</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "      <td>19556.0</td>\n",
              "      <td>movieId</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>split_genres</td>\n",
              "      <td>(Tags.CATEGORICAL)</td>\n",
              "      <td>int64</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>16.0</td>\n",
              "      <td>21.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>.//categories/unique.split_genres.parquet</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "      <td>20.0</td>\n",
              "      <td>split_genres</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>rating</td>\n",
              "      <td>(Tags.CONTINUOUS)</td>\n",
              "      <td>float64</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Training"
      ],
      "metadata": {
        "id": "JvC0AOkFirPO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train(train_dls, model, loss_fn, opt, epoch):\n",
        "    losses = []\n",
        "    n_examples = 0\n",
        "    model.cuda()\n",
        "    \n",
        "    model.train()\n",
        "\n",
        "    for i, train_dl in enumerate(train_dls):\n",
        "        for j, (x, _) in enumerate(train_dl):\n",
        "            user = x['userId'].to('cuda')\n",
        "            media = x['movieId'].to('cuda')\n",
        "            genres = [x['split_genres'][0].to('cuda'),\n",
        "                      x['split_genres'][1].to('cuda')]\n",
        "\n",
        "            y = x['rating'].to('cuda')\n",
        "\n",
        "            pred = model(user, media, genres)\n",
        "            pred = pred.squeeze()\n",
        "\n",
        "            loss = loss_fn(pred, y)\n",
        "            \n",
        "            opt.zero_grad()\n",
        "            loss.backward()\n",
        "            opt.step()\n",
        "\n",
        "            losses += [loss.detach()*len(y)]\n",
        "            n_examples += len(y)\n",
        "\n",
        "        if (i+1) % 5 == 0:\n",
        "            print('Train: Epoch {} - dl {}/{} - loss {:.3f} - rmse {:.3f}'.format(\n",
        "                                                                    epoch, i, len(train_dls),\n",
        "                                                                    torch.tensor(losses).sum()/n_examples, \n",
        "                                                                    (torch.tensor(losses).sum()/n_examples).sqrt()))\n",
        "\n",
        "    return torch.tensor(losses).sum()/n_examples, (torch.tensor(losses).sum()/n_examples).sqrt()\n",
        "\n",
        "\n",
        "def validate(val_dl, model, loss_fn, epoch):\n",
        "    losses = []\n",
        "    n_examples = 0\n",
        "    model.cuda()\n",
        "    model.eval()\n",
        "\n",
        "    for i, (x, _) in enumerate(val_dl):\n",
        "        user = x['userId'].to('cuda')\n",
        "        media = x['movieId'].to('cuda')\n",
        "        genres = [x['split_genres'][0].to('cuda'),\n",
        "                  x['split_genres'][1].to('cuda')]\n",
        "        y = x['rating'].to('cuda')\n",
        "\n",
        "        with torch.no_grad():\n",
        "            pred = model(user, media, genres)\n",
        "            pred = pred.squeeze()\n",
        "\n",
        "            loss = loss_fn(pred, y)\n",
        "\n",
        "        losses += [loss*len(y)]\n",
        "        n_examples += len(y)\n",
        "\n",
        "    print('Eval: Epoch {} - loss {:.3f} - rmse {:.3f}'.format(\n",
        "                                                      epoch,\n",
        "                                                      torch.tensor(losses).sum()/n_examples, \n",
        "                                                      (torch.tensor(losses).sum()/n_examples).sqrt()))\n",
        "\n",
        "    return torch.tensor(losses).sum()/n_examples, (torch.tensor(losses).sum()/n_examples).sqrt()"
      ],
      "metadata": {
        "id": "XwjX0prtisY6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Same model as popular workflow\n",
        "\n",
        "emb_size, hidden_dim = 32, 128\n",
        "cat_emb_shape, genre_emb_shape = nvt.ops.get_embedding_sizes(workflow)\n",
        "model = MLPGenreMH(emb_size, hidden_dim, genre_emb_shape['split_genres'], \n",
        "                   n_users=cat_emb_shape['userId'][0], \n",
        "                   n_media=cat_emb_shape['movieId'][0])\n",
        "\n",
        "batch_size = 8192\n",
        "train_dls, val_dl, test_dl = load_dls(batch_size)\n",
        "\n",
        "loss_fn = nn.MSELoss()\n",
        "lr = 1e-2\n",
        "decay = 0\n",
        "opt = torch.optim.Adam(model.parameters(), lr, weight_decay=decay)\n",
        "\n",
        "epochs = 5\n",
        "train_model(train_dls, val_dl, test_dl, model, loss_fn, opt)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-VFF7gXwkLNd",
        "outputId": "81b4174e-095e-44e6-de16-1e80c56b03a4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/merlin/io/dataset.py:253: UserWarning: Initializing an NVTabular Dataset in CPU mode.This is an experimental feature with extremely limited support!\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train: Epoch 1 - dl 4/10 - loss 0.040 - rmse 0.200\n",
            "Train: Epoch 1 - dl 9/10 - loss 0.037 - rmse 0.193\n",
            "Eval: Epoch 1 - loss 0.034 - rmse 0.184\n",
            "Epoch 1/5 - completed 1M - est. remaining 0H 4M \n",
            "\n",
            "Train: Epoch 2 - dl 4/10 - loss 0.033 - rmse 0.183\n",
            "Train: Epoch 2 - dl 9/10 - loss 0.033 - rmse 0.182\n",
            "Eval: Epoch 2 - loss 0.033 - rmse 0.181\n",
            "Epoch 2/5 - completed 1M - est. remaining 0H 3M \n",
            "\n",
            "Train: Epoch 3 - dl 4/10 - loss 0.032 - rmse 0.179\n",
            "Train: Epoch 3 - dl 9/10 - loss 0.032 - rmse 0.178\n",
            "Eval: Epoch 3 - loss 0.032 - rmse 0.178\n",
            "Epoch 3/5 - completed 1M - est. remaining 0H 2M \n",
            "\n",
            "Train: Epoch 4 - dl 4/10 - loss 0.031 - rmse 0.175\n",
            "Train: Epoch 4 - dl 9/10 - loss 0.030 - rmse 0.174\n",
            "Eval: Epoch 4 - loss 0.031 - rmse 0.177\n",
            "Epoch 4/5 - completed 1M - est. remaining 0H 1M \n",
            "\n",
            "Train: Epoch 5 - dl 4/10 - loss 0.030 - rmse 0.172\n",
            "Train: Epoch 5 - dl 9/10 - loss 0.029 - rmse 0.171\n",
            "Eval: Epoch 5 - loss 0.031 - rmse 0.176\n",
            "Epoch 5/5 - completed 1M - est. remaining 0H 0M \n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[tensor(0.0374), tensor(0.1935), tensor(0.0340), tensor(0.1843)],\n",
              " [tensor(0.0331), tensor(0.1819), tensor(0.0327), tensor(0.1809)],\n",
              " [tensor(0.0316), tensor(0.1778), tensor(0.0318), tensor(0.1783)],\n",
              " [tensor(0.0303), tensor(0.1740), tensor(0.0313), tensor(0.1768)],\n",
              " [tensor(0.0293), tensor(0.1712), tensor(0.0309), tensor(0.1759)]]"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Avg Rating and Number of Watches\n",
        "Used alongside on to the Genre Multi-Hot Embedding Model"
      ],
      "metadata": {
        "id": "pLwH3yIxnXLe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data Loading"
      ],
      "metadata": {
        "id": "3boE032Vnco3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from ast import literal_eval\n",
        "df_movies.split_genres = df_movies.split_genres.apply(literal_eval)\n",
        "df_movies = df_movies.drop(columns=['Unnamed: 0', 'Unnamed: 0.1', 'title', 'genres', 'lm_genres'])\n",
        "# Since we are using the popular workflow these will get ignored either way. \n",
        "# TODO: Should 0 out in the future since production is 0's.\n",
        "df_movies = df_movies.dropna()\n",
        "df_movies.head(n=5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "OWDKzifjnbte",
        "outputId": "84aa4ed0-310e-4469-e156-8a4b99485514"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   movieId                                       split_genres  num_ratings  \\\n",
              "0        1  [Adventure, Animation, Children, Comedy, Fantasy]      57309.0   \n",
              "1        2                     [Adventure, Children, Fantasy]      24228.0   \n",
              "2        3                                  [Comedy, Romance]      11804.0   \n",
              "3        4                           [Comedy, Drama, Romance]       2523.0   \n",
              "4        5                                           [Comedy]      11714.0   \n",
              "\n",
              "   avg_rating  \n",
              "0    3.893708  \n",
              "1    3.251527  \n",
              "2    3.142028  \n",
              "3    2.853547  \n",
              "4    3.058434  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-12299434-f92f-4926-b191-b3edceefcba5\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>movieId</th>\n",
              "      <th>split_genres</th>\n",
              "      <th>num_ratings</th>\n",
              "      <th>avg_rating</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>[Adventure, Animation, Children, Comedy, Fantasy]</td>\n",
              "      <td>57309.0</td>\n",
              "      <td>3.893708</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>[Adventure, Children, Fantasy]</td>\n",
              "      <td>24228.0</td>\n",
              "      <td>3.251527</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>[Comedy, Romance]</td>\n",
              "      <td>11804.0</td>\n",
              "      <td>3.142028</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>[Comedy, Drama, Romance]</td>\n",
              "      <td>2523.0</td>\n",
              "      <td>2.853547</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>[Comedy]</td>\n",
              "      <td>11714.0</td>\n",
              "      <td>3.058434</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-12299434-f92f-4926-b191-b3edceefcba5')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-12299434-f92f-4926-b191-b3edceefcba5 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-12299434-f92f-4926-b191-b3edceefcba5');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Look at distribution of num_ratings\n",
        "# Very skewed - log transform\n",
        "print(np.histogram(df_movies['num_ratings'], bins=20))\n",
        "print(np.histogram(np.log(df_movies['num_ratings']), bins=20))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hh8h4XUSoTtD",
        "outputId": "8b3d7421-efa2-4210-da23-ffe6560d149b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(array([57579,   714,   312,   163,    84,    57,    39,    26,    19,\n",
            "          14,    10,     5,     7,     5,     6,     1,     1,     1,\n",
            "           1,     3]), array([1.00000e+00, 4.07550e+03, 8.15000e+03, 1.22245e+04, 1.62990e+04,\n",
            "       2.03735e+04, 2.44480e+04, 2.85225e+04, 3.25970e+04, 3.66715e+04,\n",
            "       4.07460e+04, 4.48205e+04, 4.88950e+04, 5.29695e+04, 5.70440e+04,\n",
            "       6.11185e+04, 6.51930e+04, 6.92675e+04, 7.33420e+04, 7.74165e+04,\n",
            "       8.14910e+04]))\n",
            "(array([10298, 12556,  5986,  5877,  4762,  3653,  3004,  2320,  1944,\n",
            "        1712,  1566,  1324,  1161,   926,   698,   543,   396,   201,\n",
            "          90,    30]), array([ 0.        ,  0.56541239,  1.13082479,  1.69623718,  2.26164957,\n",
            "        2.82706197,  3.39247436,  3.95788675,  4.52329915,  5.08871154,\n",
            "        5.65412393,  6.21953633,  6.78494872,  7.35036111,  7.9157735 ,\n",
            "        8.4811859 ,  9.04659829,  9.61201068, 10.17742308, 10.74283547,\n",
            "       11.30824786]))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Look at distribution of avg_rating\n",
        "# Follows a normal distribution - standardize\n",
        "avg_rating = np.array(df_movies['avg_rating'])\n",
        "print(np.histogram(avg_rating, bins=20))\n",
        "print(np.histogram((avg_rating - np.mean(avg_rating)) / np.std(avg_rating), bins=20))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T1Ykf7spsJaU",
        "outputId": "8196eae9-07d7-4fab-d3d6-0e401343e992"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(array([ 568,  112,  665,  326,  943,  932, 2299, 1867, 4798, 3019, 5679,\n",
            "       9917, 7940, 8963, 5179, 3434,  773,  702,   72,  859]), array([0.5  , 0.725, 0.95 , 1.175, 1.4  , 1.625, 1.85 , 2.075, 2.3  ,\n",
            "       2.525, 2.75 , 2.975, 3.2  , 3.425, 3.65 , 3.875, 4.1  , 4.325,\n",
            "       4.55 , 4.775, 5.   ]))\n",
            "(array([ 568,  112,  665,  326,  943,  932, 2299, 1867, 4798, 3019, 5679,\n",
            "       9917, 7935, 8968, 5179, 3434,  773,  702,   72,  859]), array([-3.47561105, -3.17148862, -2.86736619, -2.56324376, -2.25912133,\n",
            "       -1.9549989 , -1.65087647, -1.34675404, -1.04263161, -0.73850918,\n",
            "       -0.43438675, -0.13026432,  0.17385811,  0.47798054,  0.78210297,\n",
            "        1.08622541,  1.39034784,  1.69447027,  1.9985927 ,  2.30271513,\n",
            "        2.60683756]))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_workflow(load_path:str = None) -> nvt.Workflow:\n",
        "    ''' Loads the Workflow or creates a new one if load_path is None.'''\n",
        "    if load_path:\n",
        "        workflow = nvt.Workflow.load(load_path)\n",
        "\n",
        "    else:\n",
        "        joined = [\"userId\", \"movieId\"] >> nvt.ops.JoinExternal(df_movies, on=[\"movieId\"])\n",
        "        output = joined['userId', 'movieId', 'split_genres'] >> nvt.ops.Categorify()\n",
        "        output += joined[\"num_ratings\"] >> nvt.ops.LogOp()\n",
        "        output += joined[\"avg_rating\"] >> nvt.ops.Normalize()\n",
        "        output += nvt.ColumnGroup([\"rating\"]) >> nvt.ops.NormalizeMinMax()\n",
        "        workflow = nvt.Workflow(output)\n",
        "\n",
        "    return workflow\n",
        "\n",
        "\n",
        "workflow = get_workflow()\n",
        "partition_fit_and_transform()"
      ],
      "metadata": {
        "id": "4wHwiM6JnnIN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "workflow.save('movie_workflow_genres_avgrating')\n",
        "!zip -r movie_workflow_genres_avgrating movie_workflow_genres_avgrating"
      ],
      "metadata": {
        "id": "pcVm0E0kLdk4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Training"
      ],
      "metadata": {
        "id": "ADuAr4_u2Yxp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train(train_dls, model, loss_fn, opt, epoch):\n",
        "    losses = []\n",
        "    n_examples = 0\n",
        "    model.cuda()\n",
        "    \n",
        "    model.train()\n",
        "\n",
        "    for i, train_dl in enumerate(train_dls):\n",
        "        for j, (x, _) in enumerate(train_dl):\n",
        "            user = x['userId'].to('cuda')\n",
        "            media = x['movieId'].to('cuda')\n",
        "            genres = [x['split_genres'][0].to('cuda'),\n",
        "                      x['split_genres'][1].to('cuda')]\n",
        "            extra_feats = [x['avg_rating'].to('cuda'), x['num_ratings'].to('cuda')]\n",
        "            y = x['rating'].to('cuda')\n",
        "\n",
        "            pred = model(user, media, genres, extra_feats)\n",
        "            # pred = pred.squeeze()\n",
        "\n",
        "            loss = loss_fn(pred, y)\n",
        "            \n",
        "            opt.zero_grad()\n",
        "            loss.backward()\n",
        "            opt.step()\n",
        "\n",
        "            losses += [loss.detach()*len(y)]\n",
        "            n_examples += len(y)\n",
        "\n",
        "        if (i+1) % 5 == 0:\n",
        "            print('Train: Epoch {} - dl {}/{} - loss {:.3f} - rmse {:.3f}'.format(\n",
        "                                                                    epoch, i, len(train_dls),\n",
        "                                                                    torch.tensor(losses).sum()/n_examples, \n",
        "                                                                    (torch.tensor(losses).sum()/n_examples).sqrt()))\n",
        "\n",
        "    return torch.tensor(losses).sum()/n_examples, (torch.tensor(losses).sum()/n_examples).sqrt()\n",
        "\n",
        "\n",
        "def validate(val_dl, model, loss_fn, epoch):\n",
        "    losses = []\n",
        "    n_examples = 0\n",
        "    model.cuda()\n",
        "    model.eval()\n",
        "\n",
        "    for i, (x, _) in enumerate(val_dl):\n",
        "        user = x['userId'].to('cuda')\n",
        "        media = x['movieId'].to('cuda')\n",
        "        genres = [x['split_genres'][0].to('cuda'),\n",
        "                  x['split_genres'][1].to('cuda')]\n",
        "        extra_feats = [x['avg_rating'].to('cuda'), x['num_ratings'].to('cuda')]\n",
        "        y = x['rating'].to('cuda')\n",
        "\n",
        "        with torch.no_grad():\n",
        "            pred = model(user, media, genres, extra_feats)\n",
        "            # pred = pred.squeeze()\n",
        "\n",
        "            loss = loss_fn(pred, y)\n",
        "\n",
        "        losses += [loss*len(y)]\n",
        "        n_examples += len(y)\n",
        "\n",
        "    print('Eval: Epoch {} - loss {:.3f} - rmse {:.3f}'.format(\n",
        "                                                      epoch,\n",
        "                                                      torch.tensor(losses).sum()/n_examples, \n",
        "                                                      (torch.tensor(losses).sum()/n_examples).sqrt()))\n",
        "\n",
        "    return torch.tensor(losses).sum()/n_examples, (torch.tensor(losses).sum()/n_examples).sqrt()"
      ],
      "metadata": {
        "id": "7MGHSYdPvkIU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Same model as popular workflow\n",
        "\n",
        "emb_size, hidden_dim = 32, 128\n",
        "cat_emb_shape, genre_emb_shape = nvt.ops.get_embedding_sizes(workflow)\n",
        "model = MLPGenreMH(emb_size, hidden_dim, \n",
        "                   genre_emb_shape['split_genres'], \n",
        "                   n_users=cat_emb_shape['userId'][0], \n",
        "                   n_media=cat_emb_shape['movieId'][0],\n",
        "                   n_extra_feats=2)\n",
        "\n",
        "batch_size = 8192\n",
        "train_dls, val_dl, test_dl = load_dls(batch_size)\n",
        "\n",
        "loss_fn = nn.MSELoss()\n",
        "lr = 1e-2\n",
        "decay = 0\n",
        "opt = torch.optim.Adam(model.parameters(), lr, weight_decay=decay)\n",
        "\n",
        "epochs = 5\n",
        "train_model(train_dls, val_dl, test_dl, model, loss_fn, opt)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CNlpnJu2KecM",
        "outputId": "12ca7630-f43f-428c-ebee-4ef10ff01876"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train: Epoch 1 - dl 4/10 - loss 0.039 - rmse 0.199\n",
            "Train: Epoch 1 - dl 9/10 - loss 0.037 - rmse 0.192\n",
            "Eval: Epoch 1 - loss 0.034 - rmse 0.184\n",
            "Epoch 1/5 - completed 1M - est. remaining 0H 4M \n",
            "\n",
            "Train: Epoch 2 - dl 4/10 - loss 0.033 - rmse 0.182\n",
            "Train: Epoch 2 - dl 9/10 - loss 0.033 - rmse 0.181\n",
            "Eval: Epoch 2 - loss 0.033 - rmse 0.181\n",
            "Epoch 2/5 - completed 1M - est. remaining 0H 3M \n",
            "\n",
            "Train: Epoch 3 - dl 4/10 - loss 0.032 - rmse 0.178\n",
            "Train: Epoch 3 - dl 9/10 - loss 0.032 - rmse 0.178\n",
            "Eval: Epoch 3 - loss 0.032 - rmse 0.178\n",
            "Epoch 3/5 - completed 1M - est. remaining 0H 2M \n",
            "\n",
            "Train: Epoch 4 - dl 4/10 - loss 0.031 - rmse 0.175\n",
            "Train: Epoch 4 - dl 9/10 - loss 0.030 - rmse 0.174\n",
            "Eval: Epoch 4 - loss 0.032 - rmse 0.178\n",
            "Epoch 4/5 - completed 1M - est. remaining 0H 1M \n",
            "\n",
            "Train: Epoch 5 - dl 4/10 - loss 0.029 - rmse 0.172\n",
            "Train: Epoch 5 - dl 9/10 - loss 0.029 - rmse 0.171\n",
            "Eval: Epoch 5 - loss 0.031 - rmse 0.177\n",
            "Epoch 5/5 - completed 1M - est. remaining 0H 0M \n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[tensor(0.0370), tensor(0.1923), tensor(0.0339), tensor(0.1842)],\n",
              " [tensor(0.0329), tensor(0.1814), tensor(0.0326), tensor(0.1807)],\n",
              " [tensor(0.0315), tensor(0.1775), tensor(0.0319), tensor(0.1785)],\n",
              " [tensor(0.0303), tensor(0.1740), tensor(0.0315), tensor(0.1776)],\n",
              " [tensor(0.0293), tensor(0.1710), tensor(0.0312), tensor(0.1766)]]"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Trace Model\n",
        "# Grab possible genres - could just use the example instead of random but it works\n",
        "batch_size = 8\n",
        "train_dls, val_dl, test_dl = load_dls(batch_size)\n",
        "tmp_genres = next(iter(train_dls[0]))[0]['split_genres']\n",
        "\n",
        "model.to('cpu')\n",
        "model.eval()\n",
        "\n",
        "inp = (torch.randint(1, 10000, (8,1)), \n",
        "       torch.randint(1, 10000, (8,1)),\n",
        "       [tmp_genres[0], tmp_genres[1]],\n",
        "       [torch.rand((8,1)), torch.rand((8,1))],)\n",
        "traced_model = torch.jit.trace(model, inp)\n",
        "traced_model.save('mlpgenre_4l128_32emb_1e-2lradam_0d_5e--02_02_23.pt')"
      ],
      "metadata": {
        "id": "qBeObbBKLbO4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Same model as popular workflow\n",
        "\n",
        "emb_size, hidden_dim = 32, 128\n",
        "cat_emb_shape, genre_emb_shape = nvt.ops.get_embedding_sizes(workflow)\n",
        "model = MLPGenreMH(emb_size, hidden_dim, \n",
        "                   genre_emb_shape['split_genres'], \n",
        "                   n_users=cat_emb_shape['userId'][0], \n",
        "                   n_media=cat_emb_shape['movieId'][0],\n",
        "                   n_extra_feats=2)\n",
        "\n",
        "batch_size = 8192\n",
        "train_dls, val_dl, test_dl = load_dls(batch_size)\n",
        "\n",
        "loss_fn = nn.MSELoss()\n",
        "lr = 1e-2\n",
        "decay = 0\n",
        "opt = torch.optim.Adam(model.parameters(), lr, weight_decay=decay)\n",
        "\n",
        "epochs = 5\n",
        "train_model(train_dls, val_dl, test_dl, model, loss_fn, opt)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c_O_CfUe7lGT",
        "outputId": "6a6e396d-8aa9-494c-f5cf-7669c16af181"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train: Epoch 1 - dl 4/10 - loss 0.040 - rmse 0.201\n",
            "Train: Epoch 1 - dl 9/10 - loss 0.037 - rmse 0.193\n",
            "Eval: Epoch 1 - loss 0.034 - rmse 0.184\n",
            "Epoch 1/5 - completed 1M - est. remaining 0H 4M \n",
            "\n",
            "Train: Epoch 2 - dl 4/10 - loss 0.033 - rmse 0.183\n",
            "Train: Epoch 2 - dl 9/10 - loss 0.033 - rmse 0.182\n",
            "Eval: Epoch 2 - loss 0.033 - rmse 0.181\n",
            "Epoch 2/5 - completed 1M - est. remaining 0H 3M \n",
            "\n",
            "Train: Epoch 3 - dl 4/10 - loss 0.032 - rmse 0.179\n",
            "Train: Epoch 3 - dl 9/10 - loss 0.032 - rmse 0.178\n",
            "Eval: Epoch 3 - loss 0.032 - rmse 0.179\n",
            "Epoch 3/5 - completed 1M - est. remaining 0H 2M \n",
            "\n",
            "Train: Epoch 4 - dl 4/10 - loss 0.031 - rmse 0.175\n",
            "Train: Epoch 4 - dl 9/10 - loss 0.030 - rmse 0.175\n",
            "Eval: Epoch 4 - loss 0.031 - rmse 0.177\n",
            "Epoch 4/5 - completed 1M - est. remaining 0H 1M \n",
            "\n",
            "Train: Epoch 5 - dl 4/10 - loss 0.030 - rmse 0.172\n",
            "Train: Epoch 5 - dl 9/10 - loss 0.029 - rmse 0.171\n",
            "Eval: Epoch 5 - loss 0.031 - rmse 0.177\n",
            "Epoch 5/5 - completed 1M - est. remaining 0H 0M \n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[tensor(0.0374), tensor(0.1933), tensor(0.0339), tensor(0.1841)],\n",
              " [tensor(0.0330), tensor(0.1817), tensor(0.0329), tensor(0.1815)],\n",
              " [tensor(0.0318), tensor(0.1782), tensor(0.0321), tensor(0.1793)],\n",
              " [tensor(0.0305), tensor(0.1745), tensor(0.0315), tensor(0.1774)],\n",
              " [tensor(0.0293), tensor(0.1712), tensor(0.0312), tensor(0.1765)]]"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Same model as popular workflow - normalize min/max avg_rating\n",
        "\n",
        "emb_size, hidden_dim = 32, 128\n",
        "cat_emb_shape, genre_emb_shape = nvt.ops.get_embedding_sizes(workflow)\n",
        "model = MLPGenreMH(emb_size, hidden_dim, \n",
        "                   genre_emb_shape['split_genres'], \n",
        "                   n_users=cat_emb_shape['userId'][0], \n",
        "                   n_media=cat_emb_shape['movieId'][0],\n",
        "                   n_extra_feats=2)\n",
        "\n",
        "batch_size = 8192\n",
        "train_dls, val_dl, test_dl = load_dls(batch_size)\n",
        "\n",
        "loss_fn = nn.MSELoss()\n",
        "lr = 1e-2\n",
        "decay = 0\n",
        "opt = torch.optim.Adam(model.parameters(), lr, weight_decay=decay)\n",
        "\n",
        "epochs = 5\n",
        "train_model(train_dls, val_dl, test_dl, model, loss_fn, opt)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MwFyBTrA9mLH",
        "outputId": "b3748b95-0985-422a-e971-3232308f44e1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train: Epoch 1 - dl 4/10 - loss 0.040 - rmse 0.201\n",
            "Train: Epoch 1 - dl 9/10 - loss 0.038 - rmse 0.194\n",
            "Eval: Epoch 1 - loss 0.034 - rmse 0.185\n",
            "Epoch 1/5 - completed 1M - est. remaining 0H 4M \n",
            "\n",
            "Train: Epoch 2 - dl 4/10 - loss 0.033 - rmse 0.183\n",
            "Train: Epoch 2 - dl 9/10 - loss 0.033 - rmse 0.182\n",
            "Eval: Epoch 2 - loss 0.033 - rmse 0.182\n",
            "Epoch 2/5 - completed 1M - est. remaining 0H 3M \n",
            "\n",
            "Train: Epoch 3 - dl 4/10 - loss 0.032 - rmse 0.179\n",
            "Train: Epoch 3 - dl 9/10 - loss 0.032 - rmse 0.178\n",
            "Eval: Epoch 3 - loss 0.032 - rmse 0.179\n",
            "Epoch 3/5 - completed 1M - est. remaining 0H 2M \n",
            "\n",
            "Train: Epoch 4 - dl 4/10 - loss 0.031 - rmse 0.176\n",
            "Train: Epoch 4 - dl 9/10 - loss 0.031 - rmse 0.175\n",
            "Eval: Epoch 4 - loss 0.031 - rmse 0.177\n",
            "Epoch 4/5 - completed 1M - est. remaining 0H 1M \n",
            "\n",
            "Train: Epoch 5 - dl 4/10 - loss 0.030 - rmse 0.172\n",
            "Train: Epoch 5 - dl 9/10 - loss 0.029 - rmse 0.172\n",
            "Eval: Epoch 5 - loss 0.031 - rmse 0.176\n",
            "Epoch 5/5 - completed 1M - est. remaining 0H 0M \n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[tensor(0.0375), tensor(0.1938), tensor(0.0342), tensor(0.1849)],\n",
              " [tensor(0.0331), tensor(0.1821), tensor(0.0330), tensor(0.1815)],\n",
              " [tensor(0.0318), tensor(0.1784), tensor(0.0320), tensor(0.1789)],\n",
              " [tensor(0.0305), tensor(0.1747), tensor(0.0313), tensor(0.1769)],\n",
              " [tensor(0.0295), tensor(0.1716), tensor(0.0310), tensor(0.1760)]]"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Same model as popular workflow - normalize min/max avg_rating - double embedding and model width\n",
        "emb_size, hidden_dim = 64, 256\n",
        "cat_emb_shape, genre_emb_shape = nvt.ops.get_embedding_sizes(workflow)\n",
        "model = MLPGenreMH(emb_size, hidden_dim, \n",
        "                   genre_emb_shape['split_genres'], \n",
        "                   n_users=cat_emb_shape['userId'][0], \n",
        "                   n_media=cat_emb_shape['movieId'][0],\n",
        "                   n_extra_feats=2)\n",
        "\n",
        "batch_size = 8192\n",
        "train_dls, val_dl, test_dl = load_dls(batch_size)\n",
        "\n",
        "loss_fn = nn.MSELoss()\n",
        "lr = 1e-2\n",
        "decay = 0\n",
        "opt = torch.optim.Adam(model.parameters(), lr, weight_decay=decay)\n",
        "\n",
        "epochs = 5\n",
        "train_model(train_dls, val_dl, test_dl, model, loss_fn, opt)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dXTGPL62RRSu",
        "outputId": "df67399b-6d46-4d03-897c-48c968a58957"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train: Epoch 1 - dl 4/10 - loss 0.041 - rmse 0.202\n",
            "Train: Epoch 1 - dl 9/10 - loss 0.038 - rmse 0.194\n",
            "Eval: Epoch 1 - loss 0.034 - rmse 0.184\n",
            "Epoch 1/5 - completed 1M - est. remaining 0H 4M \n",
            "\n",
            "Train: Epoch 2 - dl 4/10 - loss 0.033 - rmse 0.182\n",
            "Train: Epoch 2 - dl 9/10 - loss 0.033 - rmse 0.181\n",
            "Eval: Epoch 2 - loss 0.032 - rmse 0.180\n",
            "Epoch 2/5 - completed 1M - est. remaining 0H 3M \n",
            "\n",
            "Train: Epoch 3 - dl 4/10 - loss 0.031 - rmse 0.177\n",
            "Train: Epoch 3 - dl 9/10 - loss 0.031 - rmse 0.176\n",
            "Eval: Epoch 3 - loss 0.031 - rmse 0.177\n",
            "Epoch 3/5 - completed 1M - est. remaining 0H 2M \n",
            "\n",
            "Train: Epoch 4 - dl 4/10 - loss 0.030 - rmse 0.172\n",
            "Train: Epoch 4 - dl 9/10 - loss 0.029 - rmse 0.171\n",
            "Eval: Epoch 4 - loss 0.031 - rmse 0.176\n",
            "Epoch 4/5 - completed 1M - est. remaining 0H 1M \n",
            "\n",
            "Train: Epoch 5 - dl 4/10 - loss 0.028 - rmse 0.168\n",
            "Train: Epoch 5 - dl 9/10 - loss 0.028 - rmse 0.168\n",
            "Eval: Epoch 5 - loss 0.031 - rmse 0.175\n",
            "Epoch 5/5 - completed 1M - est. remaining 0H 0M \n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[tensor(0.0375), tensor(0.1937), tensor(0.0338), tensor(0.1838)],\n",
              " [tensor(0.0327), tensor(0.1807), tensor(0.0323), tensor(0.1797)],\n",
              " [tensor(0.0308), tensor(0.1756), tensor(0.0313), tensor(0.1770)],\n",
              " [tensor(0.0294), tensor(0.1713), tensor(0.0310), tensor(0.1760)],\n",
              " [tensor(0.0281), tensor(0.1677), tensor(0.0308), tensor(0.1754)]]"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Same model as popular workflow - normalize min/max avg_rating - NVT embedding sizes (512 user, 405 movie)\n",
        "\n",
        "emb_size, hidden_dim = 512, 256\n",
        "cat_emb_shape, genre_emb_shape = nvt.ops.get_embedding_sizes(workflow)\n",
        "model = MLPGenreMH(emb_size, hidden_dim, \n",
        "                   genre_emb_shape['split_genres'], \n",
        "                   n_users=cat_emb_shape['userId'][0], \n",
        "                   n_media=cat_emb_shape['movieId'][0],\n",
        "                   n_extra_feats=2)\n",
        "\n",
        "batch_size = 8192 // 2\n",
        "train_dls, val_dl, test_dl = load_dls(batch_size)\n",
        "\n",
        "loss_fn = nn.MSELoss()\n",
        "lr = 1e-2\n",
        "decay = 0\n",
        "opt = torch.optim.Adam(model.parameters(), lr, weight_decay=decay)\n",
        "\n",
        "epochs = 5\n",
        "train_model(train_dls, val_dl, test_dl, model, loss_fn, opt)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w11fgl2WDd-7",
        "outputId": "8d574df0-cfb8-4538-d3aa-e6e9fb76e6d3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train: Epoch 1 - dl 4/10 - loss 0.039 - rmse 0.197\n",
            "Train: Epoch 1 - dl 9/10 - loss 0.036 - rmse 0.190\n",
            "Eval: Epoch 1 - loss 0.033 - rmse 0.181\n",
            "Epoch 1/5 - completed 3M - est. remaining 0H 12M \n",
            "\n",
            "Train: Epoch 2 - dl 4/10 - loss 0.031 - rmse 0.177\n",
            "Train: Epoch 2 - dl 9/10 - loss 0.031 - rmse 0.175\n",
            "Eval: Epoch 2 - loss 0.031 - rmse 0.176\n",
            "Epoch 2/5 - completed 3M - est. remaining 0H 9M \n",
            "\n",
            "Train: Epoch 3 - dl 4/10 - loss 0.028 - rmse 0.169\n",
            "Train: Epoch 3 - dl 9/10 - loss 0.028 - rmse 0.167\n",
            "Eval: Epoch 3 - loss 0.031 - rmse 0.177\n",
            "Epoch 3/5 - completed 3M - est. remaining 0H 6M \n",
            "\n",
            "Train: Epoch 4 - dl 4/10 - loss 0.025 - rmse 0.159\n",
            "Train: Epoch 4 - dl 9/10 - loss 0.025 - rmse 0.159\n",
            "Eval: Epoch 4 - loss 0.033 - rmse 0.181\n",
            "Epoch 4/5 - completed 3M - est. remaining 0H 3M \n",
            "\n",
            "Train: Epoch 5 - dl 4/10 - loss 0.023 - rmse 0.152\n",
            "Train: Epoch 5 - dl 9/10 - loss 0.023 - rmse 0.152\n",
            "Eval: Epoch 5 - loss 0.033 - rmse 0.182\n",
            "Epoch 5/5 - completed 3M - est. remaining 0H 0M \n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[tensor(0.0361), tensor(0.1900), tensor(0.0326), tensor(0.1805)],\n",
              " [tensor(0.0308), tensor(0.1754), tensor(0.0311), tensor(0.1765)],\n",
              " [tensor(0.0280), tensor(0.1672), tensor(0.0313), tensor(0.1768)],\n",
              " [tensor(0.0252), tensor(0.1586), tensor(0.0327), tensor(0.1809)],\n",
              " [tensor(0.0230), tensor(0.1517), tensor(0.0331), tensor(0.1820)]]"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Not popular model\n",
        "\n",
        "emb_size, hidden_dim = 32, 128\n",
        "cat_emb_shape, genre_emb_shape = nvt.ops.get_embedding_sizes(workflow)\n",
        "model = MLPGenreMH(emb_size, hidden_dim, \n",
        "                   genre_emb_shape['split_genres'], \n",
        "                   n_users=cat_emb_shape['userId'][0], \n",
        "                   n_media=cat_emb_shape['movieId'][0],\n",
        "                   n_extra_feats=2)\n",
        "\n",
        "batch_size = 8192\n",
        "train_dls, val_dl, test_dl = load_dls(batch_size)\n",
        "\n",
        "loss_fn = nn.MSELoss()\n",
        "lr = 1e-2\n",
        "decay = 0\n",
        "opt = torch.optim.Adam(model.parameters(), lr, weight_decay=decay)\n",
        "\n",
        "epochs = 5\n",
        "train_model(train_dls, val_dl, test_dl, model, loss_fn, opt)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M5bm_vpRr21i",
        "outputId": "501cf1cd-bab7-4bc3-f554-4f711ea31b87"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train: Epoch 1 - dl 4/10 - loss 0.041 - rmse 0.202\n",
            "Train: Epoch 1 - dl 9/10 - loss 0.038 - rmse 0.195\n",
            "Eval: Epoch 1 - loss 0.034 - rmse 0.185\n",
            "Epoch 1/5 - completed 1M - est. remaining 0H 4M \n",
            "\n",
            "Train: Epoch 2 - dl 4/10 - loss 0.034 - rmse 0.184\n",
            "Train: Epoch 2 - dl 9/10 - loss 0.033 - rmse 0.183\n",
            "Eval: Epoch 2 - loss 0.033 - rmse 0.182\n",
            "Epoch 2/5 - completed 1M - est. remaining 0H 3M \n",
            "\n",
            "Train: Epoch 3 - dl 4/10 - loss 0.032 - rmse 0.179\n",
            "Train: Epoch 3 - dl 9/10 - loss 0.032 - rmse 0.178\n",
            "Eval: Epoch 3 - loss 0.032 - rmse 0.180\n",
            "Epoch 3/5 - completed 1M - est. remaining 0H 2M \n",
            "\n",
            "Train: Epoch 4 - dl 4/10 - loss 0.031 - rmse 0.176\n",
            "Train: Epoch 4 - dl 9/10 - loss 0.031 - rmse 0.175\n",
            "Eval: Epoch 4 - loss 0.032 - rmse 0.179\n",
            "Epoch 4/5 - completed 1M - est. remaining 0H 1M \n",
            "\n",
            "Train: Epoch 5 - dl 4/10 - loss 0.030 - rmse 0.172\n",
            "Train: Epoch 5 - dl 9/10 - loss 0.029 - rmse 0.172\n",
            "Eval: Epoch 5 - loss 0.032 - rmse 0.178\n",
            "Epoch 5/5 - completed 1M - est. remaining 0H 0M \n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[tensor(0.0379), tensor(0.1946), tensor(0.0343), tensor(0.1853)],\n",
              " [tensor(0.0333), tensor(0.1826), tensor(0.0332), tensor(0.1823)],\n",
              " [tensor(0.0318), tensor(0.1784), tensor(0.0324), tensor(0.1800)],\n",
              " [tensor(0.0305), tensor(0.1747), tensor(0.0320), tensor(0.1788)],\n",
              " [tensor(0.0295), tensor(0.1716), tensor(0.0318), tensor(0.1784)]]"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Movie popular model\n",
        "\n",
        "emb_size, hidden_dim = 32, 128\n",
        "cat_emb_shape, genre_emb_shape = nvt.ops.get_embedding_sizes(workflow)\n",
        "model = MLPGenreMH(emb_size, hidden_dim, \n",
        "                   genre_emb_shape['split_genres'], \n",
        "                   n_users=cat_emb_shape['userId'][0], \n",
        "                   n_media=cat_emb_shape['movieId'][0],\n",
        "                   n_extra_feats=2)\n",
        "\n",
        "batch_size = 8192\n",
        "train_dls, val_dl, test_dl = load_dls(batch_size)\n",
        "\n",
        "loss_fn = nn.MSELoss()\n",
        "lr = 1e-2\n",
        "decay = 0\n",
        "opt = torch.optim.Adam(model.parameters(), lr, weight_decay=decay)\n",
        "\n",
        "epochs = 5\n",
        "train_model(train_dls, val_dl, test_dl, model, loss_fn, opt)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d2twCjffvrZ7",
        "outputId": "7111f2ba-73d9-442a-8759-3e14e8477724"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train: Epoch 1 - dl 4/10 - loss 0.040 - rmse 0.199\n",
            "Train: Epoch 1 - dl 9/10 - loss 0.037 - rmse 0.193\n",
            "Eval: Epoch 1 - loss 0.034 - rmse 0.185\n",
            "Epoch 1/5 - completed 1M - est. remaining 0H 4M \n",
            "\n",
            "Train: Epoch 2 - dl 4/10 - loss 0.034 - rmse 0.184\n",
            "Train: Epoch 2 - dl 9/10 - loss 0.033 - rmse 0.183\n",
            "Eval: Epoch 2 - loss 0.033 - rmse 0.182\n",
            "Epoch 2/5 - completed 1M - est. remaining 0H 3M \n",
            "\n",
            "Train: Epoch 3 - dl 4/10 - loss 0.032 - rmse 0.180\n",
            "Train: Epoch 3 - dl 9/10 - loss 0.032 - rmse 0.179\n",
            "Eval: Epoch 3 - loss 0.033 - rmse 0.181\n",
            "Epoch 3/5 - completed 1M - est. remaining 0H 2M \n",
            "\n",
            "Train: Epoch 4 - dl 4/10 - loss 0.031 - rmse 0.176\n",
            "Train: Epoch 4 - dl 9/10 - loss 0.031 - rmse 0.175\n",
            "Eval: Epoch 4 - loss 0.032 - rmse 0.179\n",
            "Epoch 4/5 - completed 1M - est. remaining 0H 1M \n",
            "\n",
            "Train: Epoch 5 - dl 4/10 - loss 0.030 - rmse 0.173\n",
            "Train: Epoch 5 - dl 9/10 - loss 0.030 - rmse 0.172\n",
            "Eval: Epoch 5 - loss 0.032 - rmse 0.179\n",
            "Epoch 5/5 - completed 1M - est. remaining 0H 0M \n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[tensor(0.0373), tensor(0.1932), tensor(0.0343), tensor(0.1853)],\n",
              " [tensor(0.0333), tensor(0.1825), tensor(0.0332), tensor(0.1823)],\n",
              " [tensor(0.0319), tensor(0.1786), tensor(0.0327), tensor(0.1808)],\n",
              " [tensor(0.0306), tensor(0.1750), tensor(0.0322), tensor(0.1795)],\n",
              " [tensor(0.0295), tensor(0.1718), tensor(0.0321), tensor(0.1791)]]"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Movie popular model - large\n",
        "\n",
        "emb_size, hidden_dim = 128, 256\n",
        "cat_emb_shape, genre_emb_shape = nvt.ops.get_embedding_sizes(workflow)\n",
        "model = MLPGenreMH(emb_size, hidden_dim, \n",
        "                   genre_emb_shape['split_genres'], \n",
        "                   n_users=cat_emb_shape['userId'][0], \n",
        "                   n_media=cat_emb_shape['movieId'][0],\n",
        "                   n_extra_feats=2)\n",
        "\n",
        "batch_size = 8192\n",
        "train_dls, val_dl, test_dl = load_dls(batch_size)\n",
        "\n",
        "loss_fn = nn.MSELoss()\n",
        "lr = 1e-2\n",
        "decay = 0\n",
        "opt = torch.optim.Adam(model.parameters(), lr, weight_decay=decay)\n",
        "\n",
        "epochs = 5\n",
        "train_model(train_dls, val_dl, test_dl, model, loss_fn, opt)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zNksaSRo_THG",
        "outputId": "de76ee62-6620-40d0-ffa6-0add54d55b6f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train: Epoch 1 - dl 4/10 - loss 0.041 - rmse 0.202\n",
            "Train: Epoch 1 - dl 9/10 - loss 0.038 - rmse 0.194\n",
            "Eval: Epoch 1 - loss 0.034 - rmse 0.185\n",
            "Epoch 1/5 - completed 1M - est. remaining 0H 4M \n",
            "\n",
            "Train: Epoch 2 - dl 4/10 - loss 0.033 - rmse 0.182\n",
            "Train: Epoch 2 - dl 9/10 - loss 0.032 - rmse 0.180\n",
            "Eval: Epoch 2 - loss 0.032 - rmse 0.180\n",
            "Epoch 2/5 - completed 1M - est. remaining 0H 3M \n",
            "\n",
            "Train: Epoch 3 - dl 4/10 - loss 0.031 - rmse 0.175\n",
            "Train: Epoch 3 - dl 9/10 - loss 0.030 - rmse 0.173\n",
            "Eval: Epoch 3 - loss 0.032 - rmse 0.179\n",
            "Epoch 3/5 - completed 1M - est. remaining 0H 2M \n",
            "\n",
            "Train: Epoch 4 - dl 4/10 - loss 0.029 - rmse 0.169\n",
            "Train: Epoch 4 - dl 9/10 - loss 0.028 - rmse 0.168\n",
            "Eval: Epoch 4 - loss 0.032 - rmse 0.179\n",
            "Epoch 4/5 - completed 1M - est. remaining 0H 1M \n",
            "\n",
            "Train: Epoch 5 - dl 4/10 - loss 0.027 - rmse 0.164\n",
            "Train: Epoch 5 - dl 9/10 - loss 0.026 - rmse 0.162\n",
            "Eval: Epoch 5 - loss 0.033 - rmse 0.181\n",
            "Epoch 5/5 - completed 1M - est. remaining 0H 0M \n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[tensor(0.0378), tensor(0.1944), tensor(0.0341), tensor(0.1846)],\n",
              " [tensor(0.0324), tensor(0.1799), tensor(0.0322), tensor(0.1795)],\n",
              " [tensor(0.0301), tensor(0.1734), tensor(0.0319), tensor(0.1786)],\n",
              " [tensor(0.0282), tensor(0.1680), tensor(0.0320), tensor(0.1790)],\n",
              " [tensor(0.0264), tensor(0.1624), tensor(0.0327), tensor(0.1807)]]"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Test"
      ],
      "metadata": {
        "id": "EX3kSdfRRNIY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create DL to test specific user\n",
        "movie_ids = np.unique(df_ratings['movieId'])\n",
        "user_df = pd.DataFrame({'userId': [0]*len(movie_ids), 'movieId': movie_ids, 'rating': [0.]*len(movie_ids)})\n",
        "\n",
        "# user_df = df_ratings[df_ratings['userId'] == 72315]\n",
        "# user_df = df_test[df_test['userId'] == 72315]\n",
        "user_ds = nvt.Dataset(user_df)\n",
        "\n",
        "torch_ds = TorchAsyncItr(\n",
        "    workflow.transform(user_ds),\n",
        "    batch_size=1024,\n",
        "    cats=['userId', 'movieId', 'split_genres'],\n",
        "    conts=[\"rating\", 'avg_rating', 'num_ratings'], \n",
        ")\n",
        "dl = DLDataLoader(torch_ds, batch_size=None, pin_memory=False, num_workers=0)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sq9_lq72RQC7",
        "outputId": "a6064a37-ba66-4162-ec62-8a3fbf671264"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/merlin/io/dataset.py:253: UserWarning: Initializing an NVTabular Dataset in CPU mode.This is an experimental feature with extremely limited support!\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss_fn = nn.MSELoss()\n",
        "validate(dl, model, loss_fn, -1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MWBdE_WhGc8C",
        "outputId": "402400f2-3820-4b31-a980-2168298aab9e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Eval: Epoch -1 - loss 0.015 - rmse 0.124\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor(0.0153), tensor(0.1238))"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# df_test\n",
        "loss_fn = nn.MSELoss()\n",
        "validate(dl, model, loss_fn, -1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ccjugZoQHTEG",
        "outputId": "e3342714-264a-42d3-9773-d484dcbe1226"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Eval: Epoch -1 - loss 0.017 - rmse 0.129\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor(0.0167), tensor(0.1291))"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# User with most ratings\n",
        "preds = []\n",
        "\n",
        "model.cuda()\n",
        "model.eval()\n",
        "for i, (x, _) in enumerate(dl):\n",
        "    user = x['userId'].to('cuda')\n",
        "    media = x['movieId'].to('cuda')\n",
        "    genres = [x['split_genres'][0].to('cuda'),\n",
        "              x['split_genres'][1].to('cuda')]\n",
        "    extra_feats = [x['avg_rating'].to('cuda'), x['num_ratings'].to('cuda')]\n",
        "\n",
        "    with torch.no_grad():\n",
        "        pred = model(user, media, genres, extra_feats)\n",
        "        pred = pred.squeeze().cpu()\n",
        "        preds.extend(pred)\n",
        "\n",
        "print(sorted(zip(preds, movie_ids), key=lambda x: x[0], reverse=True)[:5])\n",
        "\n",
        "sorted_preds = sorted(zip(preds, movie_ids), key=lambda x: x[0], reverse=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1u5nolA2Hixl",
        "outputId": "2ce90417-d971-42b1-adc0-2f6bb810f9b6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[(tensor(0.9530), 858), (tensor(0.9391), 1221), (tensor(0.9356), 296), (tensor(0.9113), 527), (tensor(0.9102), 26587)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Test against default embedding\n",
        "default_user_emb = extract_prod_user_emb(model.user_emb.weight.detach(), None)\n",
        "test_model = prodMLPGenresMH(model, default_user_emb, model.media_emb.weight.detach())\n",
        "\n",
        "preds = []\n",
        "\n",
        "test_model.cuda()\n",
        "test_model.eval()\n",
        "for i, (x, _) in enumerate(dl):\n",
        "    user = x['userId'].to('cuda')\n",
        "    media = x['movieId'].to('cuda')\n",
        "    genres = [x['split_genres'][0].to('cuda'),\n",
        "              x['split_genres'][1].to('cuda')]\n",
        "    extra_feats = [x['avg_rating'].to('cuda'), x['num_ratings'].to('cuda')]\n",
        "\n",
        "    with torch.no_grad():\n",
        "        pred = test_model(user, media, genres, extra_feats)\n",
        "        pred = pred.squeeze().cpu()\n",
        "        preds.extend(pred)\n",
        "\n",
        "print(sorted(zip(preds, movie_ids), key=lambda x: x[0], reverse=True)[:5])\n",
        "\n",
        "sorted_preds = sorted(zip(preds, movie_ids), key=lambda x: x[0], reverse=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0h1-p0OvH8eI",
        "outputId": "9cd26639-df9e-4a62-e21a-ec88354f1889"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[(tensor(0.9756), 171011), (tensor(0.9734), 179135), (tensor(0.9719), 318), (tensor(0.9700), 159817), (tensor(0.9695), 171495)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# User with most ratings\n",
        "preds = []\n",
        "\n",
        "model.cuda()\n",
        "model.eval()\n",
        "for i, (x, _) in enumerate(dl):\n",
        "    user = x['userId'].to('cuda')\n",
        "    media = x['movieId'].to('cuda')\n",
        "    genres = [x['split_genres'][0].to('cuda'),\n",
        "              x['split_genres'][1].to('cuda')]\n",
        "    extra_feats = [x['avg_rating'].to('cuda'), x['num_ratings'].to('cuda')]\n",
        "\n",
        "    with torch.no_grad():\n",
        "        pred = model(user, media, genres, extra_feats)\n",
        "        pred = pred.squeeze().cpu()\n",
        "        preds.extend(pred)\n",
        "\n",
        "print(sorted(zip(preds, movie_ids), key=lambda x: x[0], reverse=True)[:5])\n",
        "\n",
        "sorted_preds = sorted(zip(preds, movie_ids), key=lambda x: x[0], reverse=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G9-WU3_MSlCt",
        "outputId": "a3bc3982-a657-4e43-dfbe-a1aa086eb1a1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[(tensor(0.8950), 858), (tensor(0.8779), 1221), (tensor(0.8746), 26082), (tensor(0.8659), 1204), (tensor(0.8629), 912)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Test against default embedding\n",
        "default_user_emb = extract_prod_user_emb(model.user_emb.weight.detach(), None)\n",
        "test_model = prodMLPGenresMH(model, default_user_emb, model.media_emb.weight.detach())\n",
        "\n",
        "preds = []\n",
        "\n",
        "test_model.cuda()\n",
        "test_model.eval()\n",
        "for i, (x, _) in enumerate(dl):\n",
        "    user = x['userId'].to('cuda')\n",
        "    media = x['movieId'].to('cuda')\n",
        "    genres = [x['split_genres'][0].to('cuda'),\n",
        "              x['split_genres'][1].to('cuda')]\n",
        "    extra_feats = [x['avg_rating'].to('cuda'), x['num_ratings'].to('cuda')]\n",
        "\n",
        "    with torch.no_grad():\n",
        "        pred = test_model(user, media, genres, extra_feats)\n",
        "        pred = pred.squeeze().cpu()\n",
        "        preds.extend(pred)\n",
        "\n",
        "print(sorted(zip(preds, movie_ids), key=lambda x: x[0], reverse=True)[:5])\n",
        "\n",
        "sorted_preds = sorted(zip(preds, movie_ids), key=lambda x: x[0], reverse=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L5gRzjjGSERC",
        "outputId": "fab5e889-18c1-431e-eeb8-809ded1f567b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[(tensor(0.9793), 527), (tensor(0.9784), 858), (tensor(0.9745), 318), (tensor(0.9729), 94969), (tensor(0.9711), 1221)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Grab possible genres - could just use the example instead of random but it works\n",
        "batch_size = 8\n",
        "train_dls, val_dl, test_dl = load_dls(batch_size)\n",
        "tmp_genres = next(iter(train_dls[0]))[0]['split_genres']\n",
        "\n",
        "test_model.to('cpu')\n",
        "test_model.eval()\n",
        "\n",
        "inp = (torch.zeros((8,1), dtype=int), \n",
        "       torch.randint(1, 100, (8,1)),\n",
        "       [tmp_genres[0], tmp_genres[1]],\n",
        "       [torch.rand((8,1)), torch.rand((8,1))],)\n",
        "traced_model = torch.jit.trace(test_model, inp)\n",
        "traced_model.save('mlpgenre_4l128_32emb_1e-2lradam_0d_5e_prodavg0--01_30_23.pt')"
      ],
      "metadata": {
        "id": "tvkZla0sVYFf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Not popular\n",
        "loss_fn = nn.MSELoss()\n",
        "validate(dl, model, loss_fn, -1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uH88QhFjwdz_",
        "outputId": "9ce4359b-0f4a-4de1-fa2c-d5b634ec0730"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Eval: Epoch -1 - loss 0.015 - rmse 0.123\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor(0.0150), tensor(0.1226))"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# User with most ratings - Not popular\n",
        "preds = []\n",
        "\n",
        "model.cuda()\n",
        "model.eval()\n",
        "for i, (x, _) in enumerate(dl):\n",
        "    user = x['userId'].to('cuda')\n",
        "    media = x['movieId'].to('cuda')\n",
        "    genres = [x['split_genres'][0].to('cuda'),\n",
        "              x['split_genres'][1].to('cuda')]\n",
        "    extra_feats = [x['avg_rating'].to('cuda'), x['num_ratings'].to('cuda')]\n",
        "\n",
        "    with torch.no_grad():\n",
        "        pred = model(user, media, genres, extra_feats)\n",
        "        pred = pred.squeeze().cpu()\n",
        "        preds.extend(pred)\n",
        "\n",
        "print(sorted(zip(preds, movie_ids), key=lambda x: x[0], reverse=True)[:5])\n",
        "\n",
        "sorted_preds = sorted(zip(preds, movie_ids), key=lambda x: x[0], reverse=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qy0-w8UBwp3o",
        "outputId": "dba31c81-b90d-44c7-b72a-bdb18f0b0f61"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[(tensor(0.9244), 193972), (tensor(0.9223), 179731), (tensor(0.9219), 137521), (tensor(0.9146), 115795), (tensor(0.9114), 858)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Test against default embedding - Not popular\n",
        "default_user_emb = extract_prod_user_emb(model.user_emb.weight.detach(), None)\n",
        "test_model = prodMLPGenresMH(model, default_user_emb, model.media_emb.weight.detach())\n",
        "\n",
        "preds = []\n",
        "\n",
        "test_model.cuda()\n",
        "test_model.eval()\n",
        "for i, (x, _) in enumerate(dl):\n",
        "    user = x['userId'].to('cuda')\n",
        "    media = x['movieId'].to('cuda')\n",
        "    genres = [x['split_genres'][0].to('cuda'),\n",
        "              x['split_genres'][1].to('cuda')]\n",
        "    extra_feats = [x['avg_rating'].to('cuda'), x['num_ratings'].to('cuda')]\n",
        "\n",
        "    with torch.no_grad():\n",
        "        pred = test_model(user, media, genres, extra_feats)\n",
        "        pred = pred.squeeze().cpu()\n",
        "        preds.extend(pred)\n",
        "\n",
        "print(sorted(zip(preds, movie_ids), key=lambda x: x[0], reverse=True)[:5])\n",
        "\n",
        "sorted_preds = sorted(zip(preds, movie_ids), key=lambda x: x[0], reverse=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y8VwcKOaw48P",
        "outputId": "3fc82789-d012-49f7-e298-cb888a5fe8d9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[(tensor(0.9862), 171495), (tensor(0.9853), 191043), (tensor(0.9843), 179731), (tensor(0.9832), 154270), (tensor(0.9808), 120311)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Test against default embedding of most rated 5000 users - Not popular\n",
        "default_user_emb = extract_prod_user_emb(model.user_emb.weight.detach().clone(), None)\n",
        "test_model = prodMLPGenresMH(model, default_user_emb, model.media_emb.weight.detach().clone())\n",
        "\n",
        "preds = []\n",
        "\n",
        "test_model.cuda()\n",
        "test_model.eval()\n",
        "for i, (x, _) in enumerate(dl):\n",
        "    user = x['userId'].to('cuda')\n",
        "    media = x['movieId'].to('cuda')\n",
        "    genres = [x['split_genres'][0].to('cuda'),\n",
        "              x['split_genres'][1].to('cuda')]\n",
        "    extra_feats = [x['avg_rating'].to('cuda'), x['num_ratings'].to('cuda')]\n",
        "\n",
        "    with torch.no_grad():\n",
        "        pred = test_model(user, media, genres, extra_feats)\n",
        "        pred = pred.squeeze().cpu()\n",
        "        preds.extend(pred)\n",
        "\n",
        "print(sorted(zip(preds, movie_ids), key=lambda x: x[0], reverse=True)[:5])\n",
        "\n",
        "sorted_preds = sorted(zip(preds, movie_ids), key=lambda x: x[0], reverse=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qpO73pDtx2Q9",
        "outputId": "be326664-8442-4422-c0c9-b2a14341e6f2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[(tensor(0.9244), 193972), (tensor(0.9223), 179731), (tensor(0.9219), 137521), (tensor(0.9146), 115795), (tensor(0.9114), 858)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Look at distribution of the norms of user embedding\n",
        "model.cpu()\n",
        "norm = torch.norm(model.user_emb.weight.detach().clone(), dim=1)\n",
        "print(np.histogram(norm, bins=20))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TvEHXR3I1KiL",
        "outputId": "4824b080-93de-4238-a5b2-fe0620ba12cf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(array([   29,  1096,  8298, 24157, 35675, 33074, 22476, 12880,  6614,\n",
            "        3251,  1379,   582,   224,    84,    34,     7,     1,     3,\n",
            "           0,     1]), array([ 2.707641 ,  3.6335409,  4.559441 ,  5.485341 ,  6.411241 ,\n",
            "        7.337141 ,  8.263041 ,  9.188941 , 10.114841 , 11.040741 ,\n",
            "       11.966641 , 12.892541 , 13.818441 , 14.744341 , 15.670241 ,\n",
            "       16.596142 , 17.522041 , 18.44794  , 19.37384  , 20.299742 ,\n",
            "       21.225641 ], dtype=float32))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Movie popular\n",
        "loss_fn = nn.MSELoss()\n",
        "validate(dl, model, loss_fn, -1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xeh4BQk3DHTG",
        "outputId": "e887dd34-e10d-48a3-f10d-2719b5fb239e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Eval: Epoch -1 - loss 0.016 - rmse 0.126\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor(0.0158), tensor(0.1259))"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Cluster Embeddings\n",
        "An efficient way to adjust to the user's preferences early on before we have enough training data for the user. \\\\\n",
        "We first cluster the user embeddings of the model. We then take the average ratings for each cluster and map \\\\\n",
        "the user to the closest cluster by their ratings. We use this cluster's embedding for the user. Each time the user  \\\\\n",
        "rates something new the embedding can be adjusted as needed without training."
      ],
      "metadata": {
        "id": "M97FoXcsfAZi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from sklearn.cluster import MiniBatchKMeans\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "DhdmMCuOfCma"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = torch.jit.load('mlpgenre_4l128_32emb_1e-2lradam_0d_5e--02_02_23.pt')\n",
        "user_embs = model.user_emb.weight.clone().detach().numpy()"
      ],
      "metadata": {
        "id": "2gFFtp1Bfkj9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "user_embs.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yKvmY17TgE7u",
        "outputId": "1ab5b61b-b482-404a-c96a-c2ada99884aa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(97233, 32)"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ssd = []\n",
        "cluster_sizes = [10,20,50,100,150,200,500,1000,2000,5000,10000]\n",
        "for n_clusters in cluster_sizes:\n",
        "    kmeans = MiniBatchKMeans(n_clusters=n_clusters).fit(user_embs)\n",
        "    ssd.append(kmeans.inertia_)\n",
        "    print(n_clusters, kmeans.inertia_)"
      ],
      "metadata": {
        "id": "-5j8UFIFSZDK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(cluster_sizes, ssd)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 293
        },
        "id": "5pjlNRjSTMNj",
        "outputId": "b87e3bc2-41ae-41cb-fc7c-c27edb8ea168"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f1044517d30>]"
            ]
          },
          "metadata": {},
          "execution_count": 11
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "n_clusters = 1000"
      ],
      "metadata": {
        "id": "pD3XtTZ9K7WZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "kmeans = MiniBatchKMeans(n_clusters=n_clusters).fit(user_embs)\n",
        "kmeans.labels_"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0Re7UYerfw81",
        "outputId": "8a6c4f04-310a-449f-e049-188c04073fed"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 89,  15, 220, ..., 493, 104,  86], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(np.histogram(kmeans.labels_, bins=20))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1U8bpWTc4LKM",
        "outputId": "be1000d8-0934-4e57-91b4-2c40c69064c0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(array([5911, 5720, 5352, 5918, 5413, 4810, 4705, 4936, 4320, 4740, 4711,\n",
            "       5406, 4838, 4486, 4400, 4181, 4298, 4311, 4254, 4523]), array([  0.  ,  49.95,  99.9 , 149.85, 199.8 , 249.75, 299.7 , 349.65,\n",
            "       399.6 , 449.55, 499.5 , 549.45, 599.4 , 649.35, 699.3 , 749.25,\n",
            "       799.2 , 849.15, 899.1 , 949.05, 999.  ]))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "kmeans.cluster_centers_"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k5U9MjWBinDa",
        "outputId": "d2a7d85f-c38b-4814-e3f6-41ad4dac326d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-0.55388075, -0.03160688,  1.1516001 , ..., -0.23080535,\n",
              "        -0.42420956, -0.22103257],\n",
              "       [-0.15448466, -0.76033527, -0.10164347, ...,  0.9592681 ,\n",
              "        -0.3265443 ,  0.19375402],\n",
              "       [-0.14779067, -0.84787697, -0.30765805, ...,  0.8550373 ,\n",
              "         0.1111447 ,  0.8669913 ],\n",
              "       ...,\n",
              "       [ 0.29968092, -0.89609957, -1.5683019 , ...,  0.7103771 ,\n",
              "        -0.4938326 , -0.18194115],\n",
              "       [-0.16549657, -1.2329925 ,  0.1927891 , ..., -1.0756308 ,\n",
              "        -0.7662767 , -0.09816051],\n",
              "       [-0.60798025, -0.02336087,  0.1487505 , ..., -0.7299217 ,\n",
              "        -0.30159888, -0.12653391]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "norm = torch.norm(torch.tensor(kmeans.cluster_centers_), dim=1)\n",
        "print(np.histogram(norm, bins=20))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-_LybwRF2ws4",
        "outputId": "2302cfd9-c79b-4169-cc05-d488d2c8d14f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(array([ 14,  66, 138, 167, 174, 127,  89,  83,  48,  34,  17,  15,  11,\n",
            "         6,   4,   2,   3,   0,   1,   1]), array([ 2.5297244,  3.1154573,  3.7011905,  4.2869234,  4.8726563,\n",
            "        5.4583893,  6.0441227,  6.6298556,  7.2155886,  7.8013215,\n",
            "        8.387054 ,  8.972788 ,  9.55852  , 10.144254 , 10.729986 ,\n",
            "       11.31572  , 11.901453 , 12.4871855, 13.072919 , 13.658651 ,\n",
            "       14.244385 ], dtype=float32))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip movie_workflow_genres_avgrating\n",
        "workflow = nvt.Workflow.load('movie_workflow_genres_avgrating')\n",
        "# workflow = nvt.Workflow.load('movie_workflow_nopop_genres_avgrating')"
      ],
      "metadata": {
        "id": "4fi2lTMKkYv4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ea9207d2-1266-4586-847a-5710a4d0b8c2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  movie_workflow_genres_avgrating.zip\n",
            "   creating: movie_workflow_genres_avgrating/\n",
            "  inflating: movie_workflow_genres_avgrating/workflow.pkl  \n",
            "  inflating: movie_workflow_genres_avgrating/metadata.json  \n",
            "   creating: movie_workflow_genres_avgrating/categories/\n",
            "  inflating: movie_workflow_genres_avgrating/categories/unique.userId.parquet  \n",
            "  inflating: movie_workflow_genres_avgrating/categories/unique.movieId.parquet  \n",
            "  inflating: movie_workflow_genres_avgrating/categories/unique.split_genres.parquet  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 1024\n",
        "\n",
        "# File is too large so we partition into 10 datasets to fit\n",
        "for i in range(10):\n",
        "    if i < 9:\n",
        "        ds = nvt.Dataset(df_ratings.iloc[i*(len(df_ratings)//10):(i+1)*(len(df_ratings)//10)])\n",
        "    else:\n",
        "        ds = nvt.Dataset(df_ratings.iloc[i*(len(df_ratings)//10):])\n",
        "    workflow.fit(ds)\n",
        "\n",
        "# File is too large so we partition into 10 datasets to transform\n",
        "for i in range(10):\n",
        "    if i < 9:\n",
        "        ds = nvt.Dataset(df_ratings.iloc[i*(len(df_ratings)//10):(i+1)*(len(df_ratings)//10)])\n",
        "    else:\n",
        "        ds = nvt.Dataset(df_ratings.iloc[i*(len(df_ratings)//10):])\n",
        "    workflow.transform(ds).to_parquet('ds_{}'.format(i))\n",
        "\n",
        "dls = []\n",
        "for i in range(10):\n",
        "    torch_ds = TorchAsyncItr(\n",
        "        nvt.Dataset('ds_{}'.format(i), engine='parquet'),\n",
        "        batch_size=batch_size,\n",
        "        cats=['userId', 'movieId', 'split_genres'],\n",
        "        conts=[\"rating\", 'avg_rating', 'num_ratings'], \n",
        "    )\n",
        "    dl = DLDataLoader(\n",
        "        torch_ds, batch_size=None, pin_memory=False, num_workers=0\n",
        "    )\n",
        "    dls.append(dl)"
      ],
      "metadata": {
        "id": "YWbLNBPbk6a6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cat_emb_shape, genre_emb_shape = nvt.ops.get_embedding_sizes(workflow)\n",
        "n_users = cat_emb_shape['userId'][0]\n",
        "n_media = cat_emb_shape['movieId'][0]\n",
        "\n",
        "ratings = np.zeros((n_clusters, n_media))\n",
        "counts = np.zeros((n_clusters, n_media))\n",
        "\n",
        "for dl in dls:\n",
        "    for x, _ in dl:\n",
        "        user = x['userId'].numpy().squeeze()\n",
        "        cluster = kmeans.labels_[user]\n",
        "        media = x['movieId'].numpy().squeeze()\n",
        "        y = x['rating'].numpy().squeeze()\n",
        "        \n",
        "        for i in range(len(user)):\n",
        "            if user[i] == 0: continue\n",
        "            ratings[cluster[i], media[i]] += y[i]\n",
        "            counts[cluster[i], media[i]] += 1.\n",
        "\n",
        "ratings *= 5"
      ],
      "metadata": {
        "id": "w2PfoxqMmHgL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ratings /= counts\n",
        "ratings[np.isnan(ratings)] = 0."
      ],
      "metadata": {
        "id": "ED0RwPg9MEfD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "173daedc-5445-4c99-d951-a97ad2ca7c6e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-24-caeec7312dcf>:1: RuntimeWarning: invalid value encountered in true_divide\n",
            "  ratings /= counts\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.save('cluster_ratings_1000--02_02_23', ratings)\n",
        "np.save('cluster_centroids_1000--02_02_23', kmeans.cluster_centers_)"
      ],
      "metadata": {
        "id": "nuVuZtn3PreV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_workflow_ratings_vector(user_ratings, n_media):\n",
        "    ''' Computes the ratings vector from original ratings for use in clustering.\n",
        "\n",
        "    Args:\n",
        "      user_ratings: [{'movieId': int, 'rating': float}]\n",
        "      n_media: int. Length of rating vectors in clusters\n",
        "    '''\n",
        "    ratings_vector = np.zeros(n_media)\n",
        "    movie_ids = [r['movieId'] for r in user_ratings]\n",
        "    movie_ratings = [r['rating'] for r in user_ratings]\n",
        "    df = pd.DataFrame({'userId': [0]*len(movie_ids), 'movieId': movie_ids, 'rating': movie_ratings})\n",
        "    # Throw away values for join\n",
        "    df_movies = pd.DataFrame({'movieId': movie_ids, \n",
        "                              'split_genres': [[\"Adventure\", \"Animation\"]]*len(movie_ids), \n",
        "                              'num_ratings': [0]*len(movie_ids),\n",
        "                              'avg_rating': [3.0]*len(movie_ids)})\n",
        "\n",
        "    ds = nvt.Dataset(df)\n",
        "    torch_ds = TorchAsyncItr(\n",
        "        workflow.transform(ds),\n",
        "        batch_size=1,\n",
        "        cats=['userId', 'movieId', 'split_genres'],\n",
        "        conts=[\"rating\", 'avg_rating', 'num_ratings'], \n",
        "    )\n",
        "    dl = DLDataLoader(torch_ds, batch_size=None, pin_memory=False, num_workers=0)\n",
        "    for x, _ in dl:\n",
        "        media = x['movieId']\n",
        "        y = x['rating']\n",
        "        ratings_vector[media] = y*5\n",
        "    \n",
        "    return ratings_vector\n",
        "    \n",
        "\n",
        "def find_closest_cluster(user_ratings, cluster_ratings):\n",
        "    diff = np.linalg.norm(cluster_ratings*(user_ratings>0) - user_ratings, axis=1)\n",
        "    cluster = np.argmin(diff)\n",
        "    return cluster"
      ],
      "metadata": {
        "id": "1albh9wSP-Xs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cat_emb_shape, genre_emb_shape = nvt.ops.get_embedding_sizes(workflow)\n",
        "n_media = cat_emb_shape['movieId'][0]\n",
        "# r = [{'movieId': 858, 'rating': 5.}, {'movieId': 2028, 'rating': 5.}, \n",
        "#      {'movieId': 296, 'rating': 5.}, {'movieId': 3578, 'rating': 5.}]\n",
        "r = [{'movieId': 1721, 'rating': 5.}, {'movieId': 1265, 'rating': 4.}, \n",
        "     {'movieId': 1197, 'rating': 5.}]\n",
        "\n",
        "ratings_vector = get_workflow_ratings_vector(r, n_media)\n",
        "cluster = find_closest_cluster(ratings_vector, np.load('cluster_ratings.npy'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ftK6EQTlVB0e",
        "outputId": "2dbcd016-c551-4e6c-a833-9df3d6f306a5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/merlin/io/dataset.py:253: UserWarning: Initializing an NVTabular Dataset in CPU mode.This is an experimental feature with extremely limited support!\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2.47483045 2.71455696 1.31619486 1.96018637 1.80717977 1.64749587\n",
            " 2.1961146  2.90950301 2.74732014 4.22308871 2.86740217 1.54032659\n",
            " 1.70993812 1.24933405 1.90556724 0.93365325 2.50786645 1.49360581\n",
            " 4.08563911 2.51738737 1.46503286 2.42325    1.18067159 3.15033146\n",
            " 1.93207535 1.61742169 2.32026395 1.4348003  2.07314348 1.33140109\n",
            " 2.71576965 0.99047863 1.45526455 2.024105   2.1534526  3.13786629\n",
            " 1.56184663 2.34157773 2.71107739 2.37811166 2.85583068 1.47409684\n",
            " 2.25385944 3.57349533 2.06330298 1.26947487 1.63396602 1.34315965\n",
            " 1.70346825 2.84049119 1.75916458 1.52214187 2.57021718 0.8549567\n",
            " 2.68304462 1.93076843 2.14993056 1.90399819 3.02933526 1.67266705\n",
            " 2.26307609 0.99995003 2.10121346 1.63230118 2.54179835 2.83576062\n",
            " 2.31903047 1.824231   1.56439308 2.33788755 2.21792366 2.43030837\n",
            " 2.3137525  1.5236189  2.06025369 3.64640006 1.56172582 2.64812447\n",
            " 3.44476889 2.10949855 3.0085252  1.46644577 1.879134   3.54543277\n",
            " 2.32739817 3.93353224 3.45334601 1.91656976 2.40264168 1.89585648\n",
            " 1.14046266 1.65560988 2.0639078  1.99062594 2.38475768 1.51519325\n",
            " 1.6188599  1.87365937 3.23724439 1.82663584]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cluster_ratings = np.load('cluster_ratings.npy')"
      ],
      "metadata": {
        "id": "Kgxm-N2wnx1q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# (cluster_ratings*(ratings_vector>0))[cluster][cluster_ratings[cluster] * ratings_vector > 0]\n",
        "cluster_ratings[cluster][cluster_ratings[cluster] * ratings_vector > 0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1T-MX-4grC0t",
        "outputId": "6b3afbc5-9e63-4838-afe1-75cfced1db31"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([4.23907324, 4.34294875, 4.57975542])"
            ]
          },
          "metadata": {},
          "execution_count": 83
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cluster"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BW_ReKBsnqkr",
        "outputId": "35cd4eae-7fdb-4819-b5b0-10352120c661"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "53"
            ]
          },
          "metadata": {},
          "execution_count": 82
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Can't reassign to torchscript models so load state dict from ts model into new model\n",
        "ts_model = model\n",
        "emb_size, hidden_dim = 32, 128\n",
        "cat_emb_shape, genre_emb_shape = nvt.ops.get_embedding_sizes(workflow)\n",
        "model = MLPGenreMH(emb_size, hidden_dim, \n",
        "                   genre_emb_shape['split_genres'], \n",
        "                   n_users=cat_emb_shape['userId'][0], \n",
        "                   n_media=cat_emb_shape['movieId'][0],\n",
        "                   n_extra_feats=2)\n",
        "model.load_state_dict(ts_model.state_dict())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7aM2xhUQkEpL",
        "outputId": "9b688a8b-9b00-4f06-ae13-ce4f6c33afd7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Concatenate default (avg) with clusters\n",
        "default_user_emb = extract_prod_user_emb(model.user_emb.weight.detach(), None)\n",
        "centroids = torch.tensor(np.load('cluster_centroids.npy'))\n",
        "\n",
        "test_model = prodMLPGenresMH(model, torch.cat([default_user_emb, centroids], axis=0), model.media_emb.weight.detach())"
      ],
      "metadata": {
        "id": "a_POEAH1h7iF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create DL to test specific user\n",
        "movie_ids = np.unique(df_ratings['movieId'])\n",
        "user_df = pd.DataFrame({'userId': [0]*len(movie_ids), 'movieId': movie_ids, 'rating': [0.]*len(movie_ids)})\n",
        "\n",
        "user_ds = nvt.Dataset(user_df)\n",
        "\n",
        "torch_ds = TorchAsyncItr(\n",
        "    workflow.transform(user_ds),\n",
        "    batch_size=1024,\n",
        "    cats=['userId', 'movieId', 'split_genres'],\n",
        "    conts=[\"rating\", 'avg_rating', 'num_ratings'], \n",
        ")\n",
        "dl = DLDataLoader(torch_ds, batch_size=None, pin_memory=False, num_workers=0)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "igeWeDwplCpU",
        "outputId": "dabb9201-ac7e-43a5-c8cc-dbdfe29085eb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/merlin/io/dataset.py:253: UserWarning: Initializing an NVTabular Dataset in CPU mode.This is an experimental feature with extremely limited support!\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "preds = []\n",
        "\n",
        "# model.cuda()\n",
        "model.eval()\n",
        "for i, (x, _) in enumerate(dl):\n",
        "    user = x['userId'] #.to('cuda')\n",
        "    user += cluster +  1\n",
        "    media = x['movieId'] #.to('cuda')\n",
        "    genres = [x['split_genres'][0], #.to('cuda'),\n",
        "              x['split_genres'][1]] #.to('cuda')]\n",
        "    extra_feats = [x['avg_rating'], #.to('cuda'), \n",
        "                   x['num_ratings']] #.to('cuda')]\n",
        "\n",
        "    with torch.no_grad():\n",
        "        pred = model(user, media, genres, extra_feats)\n",
        "        pred = pred.squeeze().cpu()\n",
        "        preds.extend(pred)\n",
        "\n",
        "print(sorted(zip(preds, movie_ids), key=lambda x: x[0], reverse=True)[:5])\n",
        "\n",
        "sorted_preds = sorted(zip(preds, movie_ids), key=lambda x: x[0], reverse=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FI88SpBclZN9",
        "outputId": "c2841984-a000-46e3-c291-9ae8f4683f01"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[(tensor(0.9686), 149879), (tensor(0.9686), 166231), (tensor(0.9686), 179625), (tensor(0.9686), 179627), (tensor(0.9686), 179629)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tmp_genres = next(iter(dl))[0]['split_genres']\n",
        "\n",
        "model.to('cpu')\n",
        "model.eval()\n",
        "\n",
        "inp = (torch.zeros((1024,1), dtype=int), \n",
        "       torch.randint(1, 10000, (1024,1)),\n",
        "       [tmp_genres[0], tmp_genres[1]],\n",
        "       [torch.rand((1024,1)), torch.rand((1024,1))],)\n",
        "traced_model = torch.jit.trace(model, inp)\n",
        "traced_model.save('mlpgenre_cluster_4l128_32emb_1e-2lradam_0d_5e--02_02_23.pt')"
      ],
      "metadata": {
        "id": "BMJMtv13vnHj"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "collapsed_sections": [
        "JSyZPgwI6UXM",
        "bjk3yM1r9xgN",
        "aQ8ltA2PbdC0",
        "YDyQ-FL1mKSs",
        "7OHxxxN7nPIc",
        "XCnkhrgc9vP9",
        "uGIiSphW0XDt",
        "wxElXHyeW8Ro"
      ],
      "mount_file_id": "1cFeoVF5Bvk6bmRMZa1ry5OLm_tavCgWL",
      "authorship_tag": "ABX9TyO7Lwsw8OO8YuGRHE8rZtL5",
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}